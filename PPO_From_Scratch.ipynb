{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMdIhOAnyMKiclh4d7kwNkl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Will-est/PPO-From-Scratch/blob/main/PPO_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.5\n",
        "# !pip install --upgrade numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "hR-QA8eyl9_Z",
        "outputId": "63a15ae4-45bf-42ce-eff9-91e94c203d9e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "geopandas 1.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "scipy 1.16.0 requires numpy<2.6,>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.24.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 2.11.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "72231ea8bf414f2bbe081d07cee46641"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import statments\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions.categorical import Categorical"
      ],
      "metadata": {
        "id": "FdjPZTbIRfDK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VBNaB4Ng0tis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1446612-a7e5-4585-8598-1bbbdab82695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Policy 751 Mean Loss: -0.004443145473487675\n",
            "Entropy 751 Mean Loss: 0.6908140033483505\n",
            "Value 751 Mean Loss: 5.00711864233017\n",
            "dones: tensor(28.)\n",
            "Policy 752 Mean Loss: -0.01233701064484194\n",
            "Entropy 752 Mean Loss: 0.690772145986557\n",
            "Value 752 Mean Loss: 5.070312172174454\n",
            "dones: tensor(21.)\n",
            "Policy 753 Mean Loss: -0.00559625425375998\n",
            "Entropy 753 Mean Loss: 0.6908226534724236\n",
            "Value 753 Mean Loss: 4.090002611279488\n",
            "dones: tensor(24.)\n",
            "Policy 754 Mean Loss: -0.00680064270272851\n",
            "Entropy 754 Mean Loss: 0.6909222826361656\n",
            "Value 754 Mean Loss: 4.421047925949097\n",
            "dones: tensor(20.)\n",
            "Policy 755 Mean Loss: -0.007149259676225483\n",
            "Entropy 755 Mean Loss: 0.6909564808011055\n",
            "Value 755 Mean Loss: 4.367427170276642\n",
            "dones: tensor(21.)\n",
            "Policy 756 Mean Loss: -0.00970211229287088\n",
            "Entropy 756 Mean Loss: 0.6910747326910496\n",
            "Value 756 Mean Loss: 4.51322577893734\n",
            "dones: tensor(18.)\n",
            "Policy 757 Mean Loss: -0.008344755042344332\n",
            "Entropy 757 Mean Loss: 0.6908507496118546\n",
            "Value 757 Mean Loss: 5.13527849316597\n",
            "dones: tensor(26.)\n",
            "Policy 758 Mean Loss: -0.00963326939381659\n",
            "Entropy 758 Mean Loss: 0.690761785954237\n",
            "Value 758 Mean Loss: 5.275692105293274\n",
            "dones: tensor(19.)\n",
            "Policy 759 Mean Loss: -0.010827888327185065\n",
            "Entropy 759 Mean Loss: 0.6901801601052284\n",
            "Value 759 Mean Loss: 4.616887405514717\n",
            "dones: tensor(20.)\n",
            "Policy 760 Mean Loss: -0.004971396236214787\n",
            "Entropy 760 Mean Loss: 0.6900839805603027\n",
            "Value 760 Mean Loss: 4.157657697796822\n",
            "dones: tensor(23.)\n",
            "Policy 761 Mean Loss: -0.008805395162198693\n",
            "Entropy 761 Mean Loss: 0.6907711997628212\n",
            "Value 761 Mean Loss: 5.350473195314407\n",
            "dones: tensor(23.)\n",
            "Policy 762 Mean Loss: -0.009180361754260957\n",
            "Entropy 762 Mean Loss: 0.6902892254292965\n",
            "Value 762 Mean Loss: 4.544294163584709\n",
            "dones: tensor(21.)\n",
            "Policy 763 Mean Loss: -0.005144606227986515\n",
            "Entropy 763 Mean Loss: 0.690362423658371\n",
            "Value 763 Mean Loss: 3.8397558480501175\n",
            "dones: tensor(26.)\n",
            "Policy 764 Mean Loss: -0.010065299575217068\n",
            "Entropy 764 Mean Loss: 0.6905827187001705\n",
            "Value 764 Mean Loss: 4.871783524751663\n",
            "dones: tensor(25.)\n",
            "Policy 765 Mean Loss: -0.010332491772715002\n",
            "Entropy 765 Mean Loss: 0.6907062493264675\n",
            "Value 765 Mean Loss: 4.63521184027195\n",
            "dones: tensor(24.)\n",
            "Policy 766 Mean Loss: -0.011291661532595754\n",
            "Entropy 766 Mean Loss: 0.6901480816304684\n",
            "Value 766 Mean Loss: 5.131732940673828\n",
            "dones: tensor(24.)\n",
            "Policy 767 Mean Loss: -0.011356129369232804\n",
            "Entropy 767 Mean Loss: 0.6902773752808571\n",
            "Value 767 Mean Loss: 4.115822598338127\n",
            "dones: tensor(28.)\n",
            "Policy 768 Mean Loss: -0.009884353319648653\n",
            "Entropy 768 Mean Loss: 0.6902604028582573\n",
            "Value 768 Mean Loss: 5.141619503498077\n",
            "dones: tensor(26.)\n",
            "Policy 769 Mean Loss: -0.005298825446516275\n",
            "Entropy 769 Mean Loss: 0.6904786713421345\n",
            "Value 769 Mean Loss: 4.561542898416519\n",
            "dones: tensor(19.)\n",
            "Policy 770 Mean Loss: -0.013398977695032954\n",
            "Entropy 770 Mean Loss: 0.6895407810807228\n",
            "Value 770 Mean Loss: 3.6884954273700714\n",
            "dones: tensor(19.)\n",
            "Policy 771 Mean Loss: -0.006520290859043598\n",
            "Entropy 771 Mean Loss: 0.6900201626121998\n",
            "Value 771 Mean Loss: 5.278237521648407\n",
            "dones: tensor(19.)\n",
            "Policy 772 Mean Loss: -0.007308254833333194\n",
            "Entropy 772 Mean Loss: 0.6897255256772041\n",
            "Value 772 Mean Loss: 4.255096763372421\n",
            "dones: tensor(16.)\n",
            "Policy 773 Mean Loss: -0.007983215095009655\n",
            "Entropy 773 Mean Loss: 0.6907454766333103\n",
            "Value 773 Mean Loss: 4.614883631467819\n",
            "dones: tensor(25.)\n",
            "Policy 774 Mean Loss: -0.0091109256609343\n",
            "Entropy 774 Mean Loss: 0.6911090984940529\n",
            "Value 774 Mean Loss: 5.657967150211334\n",
            "dones: tensor(22.)\n",
            "Policy 775 Mean Loss: -0.007651535794138908\n",
            "Entropy 775 Mean Loss: 0.6903111524879932\n",
            "Value 775 Mean Loss: 4.79217666387558\n",
            "dones: tensor(23.)\n",
            "Policy 776 Mean Loss: -0.006278224638663232\n",
            "Entropy 776 Mean Loss: 0.6903239116072655\n",
            "Value 776 Mean Loss: 4.460733309388161\n",
            "dones: tensor(25.)\n",
            "Policy 777 Mean Loss: -0.009059227304533124\n",
            "Entropy 777 Mean Loss: 0.6904664151370525\n",
            "Value 777 Mean Loss: 5.071860611438751\n",
            "dones: tensor(25.)\n",
            "Policy 778 Mean Loss: -0.005803981912322342\n",
            "Entropy 778 Mean Loss: 0.690908920019865\n",
            "Value 778 Mean Loss: 4.964980334043503\n",
            "dones: tensor(20.)\n",
            "Policy 779 Mean Loss: -0.004139418713748455\n",
            "Entropy 779 Mean Loss: 0.6908073611557484\n",
            "Value 779 Mean Loss: 6.129702478647232\n",
            "dones: tensor(24.)\n",
            "Policy 780 Mean Loss: -0.007736980856861919\n",
            "Entropy 780 Mean Loss: 0.6904766224324703\n",
            "Value 780 Mean Loss: 4.597128704190254\n",
            "dones: tensor(24.)\n",
            "Policy 781 Mean Loss: -0.003661146794911474\n",
            "Entropy 781 Mean Loss: 0.6902972795069218\n",
            "Value 781 Mean Loss: 4.54801818728447\n",
            "dones: tensor(24.)\n",
            "Policy 782 Mean Loss: -0.011389946041163057\n",
            "Entropy 782 Mean Loss: 0.6901963129639626\n",
            "Value 782 Mean Loss: 4.729260802268982\n",
            "dones: tensor(22.)\n",
            "Policy 783 Mean Loss: -0.0034800294670276344\n",
            "Entropy 783 Mean Loss: 0.6906418241560459\n",
            "Value 783 Mean Loss: 4.196180284023285\n",
            "dones: tensor(19.)\n",
            "Policy 784 Mean Loss: 0.004247587581630796\n",
            "Entropy 784 Mean Loss: 0.6910122036933899\n",
            "Value 784 Mean Loss: 4.639663532376289\n",
            "dones: tensor(20.)\n",
            "Policy 785 Mean Loss: -0.007416105247102678\n",
            "Entropy 785 Mean Loss: 0.6908953040838242\n",
            "Value 785 Mean Loss: 4.266019731760025\n",
            "dones: tensor(23.)\n",
            "Policy 786 Mean Loss: -0.0073857476527336985\n",
            "Entropy 786 Mean Loss: 0.691276054829359\n",
            "Value 786 Mean Loss: 4.966057017445564\n",
            "dones: tensor(20.)\n",
            "Policy 787 Mean Loss: -0.009302964550442994\n",
            "Entropy 787 Mean Loss: 0.6909267269074917\n",
            "Value 787 Mean Loss: 4.266335532069206\n",
            "dones: tensor(23.)\n",
            "Policy 788 Mean Loss: -0.004338389553595334\n",
            "Entropy 788 Mean Loss: 0.6912612840533257\n",
            "Value 788 Mean Loss: 3.964613601565361\n",
            "dones: tensor(25.)\n",
            "Policy 789 Mean Loss: -0.005211561161559075\n",
            "Entropy 789 Mean Loss: 0.6905686445534229\n",
            "Value 789 Mean Loss: 4.893632888793945\n",
            "dones: tensor(21.)\n",
            "Policy 790 Mean Loss: -0.012484861363191158\n",
            "Entropy 790 Mean Loss: 0.6896817088127136\n",
            "Value 790 Mean Loss: 5.479826629161835\n",
            "dones: tensor(22.)\n",
            "Policy 791 Mean Loss: -0.007587843108922243\n",
            "Entropy 791 Mean Loss: 0.6899478547275066\n",
            "Value 791 Mean Loss: 5.249086678028107\n",
            "dones: tensor(23.)\n",
            "Policy 792 Mean Loss: -0.010922976420260966\n",
            "Entropy 792 Mean Loss: 0.6899784505367279\n",
            "Value 792 Mean Loss: 5.547148138284683\n",
            "dones: tensor(22.)\n",
            "Policy 793 Mean Loss: -0.006524373544380069\n",
            "Entropy 793 Mean Loss: 0.6909116543829441\n",
            "Value 793 Mean Loss: 4.4141406416893005\n",
            "dones: tensor(27.)\n",
            "Policy 794 Mean Loss: -0.001100795459933579\n",
            "Entropy 794 Mean Loss: 0.6913836002349854\n",
            "Value 794 Mean Loss: 4.542966231703758\n",
            "dones: tensor(22.)\n",
            "Policy 795 Mean Loss: -0.002052069641649723\n",
            "Entropy 795 Mean Loss: 0.6914147697389126\n",
            "Value 795 Mean Loss: 5.633552581071854\n",
            "dones: tensor(22.)\n",
            "Policy 796 Mean Loss: -0.0070437423419207335\n",
            "Entropy 796 Mean Loss: 0.6914116963744164\n",
            "Value 796 Mean Loss: 4.1740105748176575\n",
            "dones: tensor(26.)\n",
            "Policy 797 Mean Loss: -0.0031648066360503435\n",
            "Entropy 797 Mean Loss: 0.6914679855108261\n",
            "Value 797 Mean Loss: 4.416495770215988\n",
            "dones: tensor(23.)\n",
            "Policy 798 Mean Loss: -0.004590034863213077\n",
            "Entropy 798 Mean Loss: 0.691399659961462\n",
            "Value 798 Mean Loss: 5.125795006752014\n",
            "dones: tensor(18.)\n",
            "Policy 799 Mean Loss: -0.005128153599798679\n",
            "Entropy 799 Mean Loss: 0.690605390816927\n",
            "Value 799 Mean Loss: 4.7508218586444855\n",
            "dones: tensor(28.)\n",
            "Policy 800 Mean Loss: -0.009983690804801881\n",
            "Entropy 800 Mean Loss: 0.6906149908900261\n",
            "Value 800 Mean Loss: 4.959468454122543\n",
            "dones: tensor(23.)\n",
            "Policy 801 Mean Loss: -0.008883458329364657\n",
            "Entropy 801 Mean Loss: 0.6903614923357964\n",
            "Value 801 Mean Loss: 4.310354053974152\n",
            "dones: tensor(16.)\n",
            "Policy 802 Mean Loss: -0.00962496135616675\n",
            "Entropy 802 Mean Loss: 0.689825989305973\n",
            "Value 802 Mean Loss: 3.57811276614666\n",
            "dones: tensor(19.)\n",
            "Policy 803 Mean Loss: -0.003859192132949829\n",
            "Entropy 803 Mean Loss: 0.69043929874897\n",
            "Value 803 Mean Loss: 4.815345376729965\n",
            "dones: tensor(20.)\n",
            "Policy 804 Mean Loss: -0.004307443683501333\n",
            "Entropy 804 Mean Loss: 0.6905948594212532\n",
            "Value 804 Mean Loss: 4.898192524909973\n",
            "dones: tensor(19.)\n",
            "Policy 805 Mean Loss: -0.003948384488467127\n",
            "Entropy 805 Mean Loss: 0.6905185654759407\n",
            "Value 805 Mean Loss: 4.043805167078972\n",
            "dones: tensor(22.)\n",
            "Policy 806 Mean Loss: -0.007152644393499941\n",
            "Entropy 806 Mean Loss: 0.691140990704298\n",
            "Value 806 Mean Loss: 4.4720324873924255\n",
            "dones: tensor(23.)\n",
            "Policy 807 Mean Loss: -0.009197532490361482\n",
            "Entropy 807 Mean Loss: 0.6909484937787056\n",
            "Value 807 Mean Loss: 4.597692012786865\n",
            "dones: tensor(23.)\n",
            "Policy 808 Mean Loss: 0.0012433556839823723\n",
            "Entropy 808 Mean Loss: 0.6912314705550671\n",
            "Value 808 Mean Loss: 4.888296335935593\n",
            "dones: tensor(16.)\n",
            "Policy 809 Mean Loss: -0.00225061149103567\n",
            "Entropy 809 Mean Loss: 0.6911903396248817\n",
            "Value 809 Mean Loss: 4.195847004652023\n",
            "dones: tensor(18.)\n",
            "Policy 810 Mean Loss: -0.0023603090085089207\n",
            "Entropy 810 Mean Loss: 0.6914879158139229\n",
            "Value 810 Mean Loss: 4.274254754185677\n",
            "dones: tensor(17.)\n",
            "Policy 811 Mean Loss: -0.0032954562921077013\n",
            "Entropy 811 Mean Loss: 0.6912757232785225\n",
            "Value 811 Mean Loss: 4.0635998994112015\n",
            "dones: tensor(21.)\n",
            "Policy 812 Mean Loss: -0.006460820033680648\n",
            "Entropy 812 Mean Loss: 0.6911019124090672\n",
            "Value 812 Mean Loss: 4.421958699822426\n",
            "dones: tensor(27.)\n",
            "Policy 813 Mean Loss: -0.00339895611978136\n",
            "Entropy 813 Mean Loss: 0.690994530916214\n",
            "Value 813 Mean Loss: 5.402145087718964\n",
            "dones: tensor(24.)\n",
            "Policy 814 Mean Loss: -0.0030179297318682075\n",
            "Entropy 814 Mean Loss: 0.6907528080046177\n",
            "Value 814 Mean Loss: 4.779420077800751\n",
            "dones: tensor(22.)\n",
            "Policy 815 Mean Loss: -1.10010732896626e-05\n",
            "Entropy 815 Mean Loss: 0.6905732080340385\n",
            "Value 815 Mean Loss: 4.148532226681709\n",
            "dones: tensor(25.)\n",
            "Policy 816 Mean Loss: -0.006827540113590658\n",
            "Entropy 816 Mean Loss: 0.6905125677585602\n",
            "Value 816 Mean Loss: 4.419061720371246\n",
            "dones: tensor(21.)\n",
            "Policy 817 Mean Loss: -0.008871089085005224\n",
            "Entropy 817 Mean Loss: 0.6903568468987942\n",
            "Value 817 Mean Loss: 4.172059923410416\n",
            "dones: tensor(21.)\n",
            "Policy 818 Mean Loss: -0.002192897314671427\n",
            "Entropy 818 Mean Loss: 0.6908525787293911\n",
            "Value 818 Mean Loss: 4.364378750324249\n",
            "dones: tensor(19.)\n",
            "Policy 819 Mean Loss: -0.0024125025956891477\n",
            "Entropy 819 Mean Loss: 0.6908268705010414\n",
            "Value 819 Mean Loss: 3.863067105412483\n",
            "dones: tensor(24.)\n",
            "Policy 820 Mean Loss: -0.008047251962125301\n",
            "Entropy 820 Mean Loss: 0.6908737309277058\n",
            "Value 820 Mean Loss: 4.500084847211838\n",
            "dones: tensor(23.)\n",
            "Policy 821 Mean Loss: -0.0026369139086455107\n",
            "Entropy 821 Mean Loss: 0.6907704323530197\n",
            "Value 821 Mean Loss: 4.413405165076256\n",
            "dones: tensor(21.)\n",
            "Policy 822 Mean Loss: -0.004086493805516511\n",
            "Entropy 822 Mean Loss: 0.6907619498670101\n",
            "Value 822 Mean Loss: 4.806495323777199\n",
            "dones: tensor(23.)\n",
            "Policy 823 Mean Loss: -0.0013850706745870411\n",
            "Entropy 823 Mean Loss: 0.6907063201069832\n",
            "Value 823 Mean Loss: 4.736268222332001\n",
            "dones: tensor(24.)\n",
            "Policy 824 Mean Loss: -0.0007216992089524865\n",
            "Entropy 824 Mean Loss: 0.6908486038446426\n",
            "Value 824 Mean Loss: 5.124454498291016\n",
            "dones: tensor(20.)\n",
            "Policy 825 Mean Loss: -0.0014884457341395319\n",
            "Entropy 825 Mean Loss: 0.6908363327383995\n",
            "Value 825 Mean Loss: 4.970614552497864\n",
            "dones: tensor(21.)\n",
            "Policy 826 Mean Loss: -0.005739141837693751\n",
            "Entropy 826 Mean Loss: 0.6904864646494389\n",
            "Value 826 Mean Loss: 5.102647483348846\n",
            "dones: tensor(23.)\n",
            "Policy 827 Mean Loss: -0.004713242349680513\n",
            "Entropy 827 Mean Loss: 0.6906465440988541\n",
            "Value 827 Mean Loss: 4.631741389632225\n",
            "dones: tensor(19.)\n",
            "Policy 828 Mean Loss: -0.004045441281050444\n",
            "Entropy 828 Mean Loss: 0.6908175237476826\n",
            "Value 828 Mean Loss: 3.5895209461450577\n",
            "dones: tensor(20.)\n",
            "Policy 829 Mean Loss: 0.002674347080755979\n",
            "Entropy 829 Mean Loss: 0.6910330317914486\n",
            "Value 829 Mean Loss: 4.666790917515755\n",
            "dones: tensor(23.)\n",
            "Policy 830 Mean Loss: -0.006773352099116892\n",
            "Entropy 830 Mean Loss: 0.690797820687294\n",
            "Value 830 Mean Loss: 4.582495957612991\n",
            "dones: tensor(25.)\n",
            "Policy 831 Mean Loss: -0.007671071856748313\n",
            "Entropy 831 Mean Loss: 0.6909140907227993\n",
            "Value 831 Mean Loss: 5.132960349321365\n",
            "dones: tensor(21.)\n",
            "Policy 832 Mean Loss: -0.008607532945461571\n",
            "Entropy 832 Mean Loss: 0.6907977573573589\n",
            "Value 832 Mean Loss: 4.941978573799133\n",
            "dones: tensor(19.)\n",
            "Policy 833 Mean Loss: -0.009324946790002286\n",
            "Entropy 833 Mean Loss: 0.6904831975698471\n",
            "Value 833 Mean Loss: 4.829498931765556\n",
            "dones: tensor(23.)\n",
            "Policy 834 Mean Loss: -0.004495232831686735\n",
            "Entropy 834 Mean Loss: 0.6905128061771393\n",
            "Value 834 Mean Loss: 4.504293546080589\n",
            "dones: tensor(25.)\n",
            "Policy 835 Mean Loss: -0.004446180246304721\n",
            "Entropy 835 Mean Loss: 0.6904431991279125\n",
            "Value 835 Mean Loss: 4.827883169054985\n",
            "dones: tensor(23.)\n",
            "Policy 836 Mean Loss: -0.0027174254064448178\n",
            "Entropy 836 Mean Loss: 0.6904141195118427\n",
            "Value 836 Mean Loss: 4.231584191322327\n",
            "dones: tensor(26.)\n",
            "Policy 837 Mean Loss: -0.001770015514921397\n",
            "Entropy 837 Mean Loss: 0.6904629543423653\n",
            "Value 837 Mean Loss: 4.5910664498806\n",
            "dones: tensor(25.)\n",
            "Policy 838 Mean Loss: -0.007188540534116328\n",
            "Entropy 838 Mean Loss: 0.6906924247741699\n",
            "Value 838 Mean Loss: 4.817027240991592\n",
            "dones: tensor(21.)\n",
            "Policy 839 Mean Loss: -0.005706589261535555\n",
            "Entropy 839 Mean Loss: 0.6908323392271996\n",
            "Value 839 Mean Loss: 4.197587937116623\n",
            "dones: tensor(22.)\n",
            "Policy 840 Mean Loss: -0.0118869892321527\n",
            "Entropy 840 Mean Loss: 0.6904981024563313\n",
            "Value 840 Mean Loss: 5.130495071411133\n",
            "dones: tensor(20.)\n",
            "Policy 841 Mean Loss: -0.011230403382796794\n",
            "Entropy 841 Mean Loss: 0.689863808453083\n",
            "Value 841 Mean Loss: 3.9671700745821\n",
            "dones: tensor(25.)\n",
            "Policy 842 Mean Loss: -0.0007849042303860188\n",
            "Entropy 842 Mean Loss: 0.6898897849023342\n",
            "Value 842 Mean Loss: 5.077582985162735\n",
            "dones: tensor(23.)\n",
            "Policy 843 Mean Loss: -0.010758133779745549\n",
            "Entropy 843 Mean Loss: 0.6903025470674038\n",
            "Value 843 Mean Loss: 4.3825066685676575\n",
            "dones: tensor(25.)\n",
            "Policy 844 Mean Loss: -0.009577506105415523\n",
            "Entropy 844 Mean Loss: 0.6906851306557655\n",
            "Value 844 Mean Loss: 4.9599529504776\n",
            "dones: tensor(23.)\n",
            "Policy 845 Mean Loss: -0.007632592576555908\n",
            "Entropy 845 Mean Loss: 0.6910957060754299\n",
            "Value 845 Mean Loss: 4.934564709663391\n",
            "dones: tensor(22.)\n",
            "Policy 846 Mean Loss: -0.007022574660368264\n",
            "Entropy 846 Mean Loss: 0.6908760033547878\n",
            "Value 846 Mean Loss: 3.787619024515152\n",
            "dones: tensor(24.)\n",
            "Policy 847 Mean Loss: -0.007954982516821474\n",
            "Entropy 847 Mean Loss: 0.6904208697378635\n",
            "Value 847 Mean Loss: 4.406540721654892\n",
            "dones: tensor(28.)\n",
            "Policy 848 Mean Loss: -0.008108139329124242\n",
            "Entropy 848 Mean Loss: 0.6905065402388573\n",
            "Value 848 Mean Loss: 5.089060485363007\n",
            "dones: tensor(20.)\n",
            "Policy 849 Mean Loss: -0.006253522704355419\n",
            "Entropy 849 Mean Loss: 0.6899572275578976\n",
            "Value 849 Mean Loss: 4.104191482067108\n",
            "dones: tensor(21.)\n",
            "Policy 850 Mean Loss: -0.006184387137182057\n",
            "Entropy 850 Mean Loss: 0.6901434995234013\n",
            "Value 850 Mean Loss: 4.061322897672653\n",
            "dones: tensor(19.)\n",
            "Policy 851 Mean Loss: -0.01209443504922092\n",
            "Entropy 851 Mean Loss: 0.6898940317332745\n",
            "Value 851 Mean Loss: 4.3023170828819275\n",
            "dones: tensor(27.)\n",
            "Policy 852 Mean Loss: -0.010652548808138818\n",
            "Entropy 852 Mean Loss: 0.690115612000227\n",
            "Value 852 Mean Loss: 4.852768987417221\n",
            "dones: tensor(21.)\n",
            "Policy 853 Mean Loss: -0.005101240589283407\n",
            "Entropy 853 Mean Loss: 0.6902876906096935\n",
            "Value 853 Mean Loss: 4.964956551790237\n",
            "dones: tensor(21.)\n",
            "Policy 854 Mean Loss: -0.01303706446196884\n",
            "Entropy 854 Mean Loss: 0.6905950754880905\n",
            "Value 854 Mean Loss: 4.291064903140068\n",
            "dones: tensor(22.)\n",
            "Policy 855 Mean Loss: -0.007133112289011478\n",
            "Entropy 855 Mean Loss: 0.6908192709088326\n",
            "Value 855 Mean Loss: 4.7322225868701935\n",
            "dones: tensor(26.)\n",
            "Policy 856 Mean Loss: -0.008638075116323307\n",
            "Entropy 856 Mean Loss: 0.6908846721053123\n",
            "Value 856 Mean Loss: 5.001561194658279\n",
            "dones: tensor(20.)\n",
            "Policy 857 Mean Loss: -0.007023676953394897\n",
            "Entropy 857 Mean Loss: 0.6903281323611736\n",
            "Value 857 Mean Loss: 3.872691825032234\n",
            "dones: tensor(21.)\n",
            "Policy 858 Mean Loss: -0.00795853981981054\n",
            "Entropy 858 Mean Loss: 0.6900218166410923\n",
            "Value 858 Mean Loss: 4.36914736032486\n",
            "dones: tensor(21.)\n",
            "Policy 859 Mean Loss: -0.01000808144453913\n",
            "Entropy 859 Mean Loss: 0.6900941506028175\n",
            "Value 859 Mean Loss: 4.363538280129433\n",
            "dones: tensor(19.)\n",
            "Policy 860 Mean Loss: -0.0058440082357265055\n",
            "Entropy 860 Mean Loss: 0.6904628910124302\n",
            "Value 860 Mean Loss: 4.644729971885681\n",
            "dones: tensor(22.)\n",
            "Policy 861 Mean Loss: -0.002912800235208124\n",
            "Entropy 861 Mean Loss: 0.690582238137722\n",
            "Value 861 Mean Loss: 4.209339141845703\n",
            "dones: tensor(24.)\n",
            "Policy 862 Mean Loss: -0.006237720896024257\n",
            "Entropy 862 Mean Loss: 0.6904823146760464\n",
            "Value 862 Mean Loss: 4.949416965246201\n",
            "dones: tensor(17.)\n",
            "Policy 863 Mean Loss: -0.007279227254912257\n",
            "Entropy 863 Mean Loss: 0.6904669962823391\n",
            "Value 863 Mean Loss: 4.259888157248497\n",
            "dones: tensor(24.)\n",
            "Policy 864 Mean Loss: -0.008163508435245603\n",
            "Entropy 864 Mean Loss: 0.6910915412008762\n",
            "Value 864 Mean Loss: 5.222838401794434\n",
            "dones: tensor(22.)\n",
            "Policy 865 Mean Loss: -0.006419605691917241\n",
            "Entropy 865 Mean Loss: 0.691502258181572\n",
            "Value 865 Mean Loss: 4.490976497530937\n",
            "dones: tensor(22.)\n",
            "Policy 866 Mean Loss: -0.009772532270289958\n",
            "Entropy 866 Mean Loss: 0.6911015100777149\n",
            "Value 866 Mean Loss: 4.22476989030838\n",
            "dones: tensor(24.)\n",
            "Policy 867 Mean Loss: -0.0060759381740354\n",
            "Entropy 867 Mean Loss: 0.6910258382558823\n",
            "Value 867 Mean Loss: 4.593355119228363\n",
            "dones: tensor(27.)\n",
            "Policy 868 Mean Loss: -0.004899219260551035\n",
            "Entropy 868 Mean Loss: 0.6909507028758526\n",
            "Value 868 Mean Loss: 4.9045427441596985\n",
            "dones: tensor(23.)\n",
            "Policy 869 Mean Loss: -0.005635669804178178\n",
            "Entropy 869 Mean Loss: 0.6910711601376534\n",
            "Value 869 Mean Loss: 4.799044817686081\n",
            "dones: tensor(20.)\n",
            "Policy 870 Mean Loss: -0.006785406614653766\n",
            "Entropy 870 Mean Loss: 0.6909148655831814\n",
            "Value 870 Mean Loss: 4.063761129975319\n",
            "dones: tensor(25.)\n",
            "Policy 871 Mean Loss: -0.010879712062887847\n",
            "Entropy 871 Mean Loss: 0.6910881847143173\n",
            "Value 871 Mean Loss: 4.754244297742844\n",
            "dones: tensor(24.)\n",
            "Policy 872 Mean Loss: -0.004037171078380197\n",
            "Entropy 872 Mean Loss: 0.6908874958753586\n",
            "Value 872 Mean Loss: 4.435004219412804\n",
            "dones: tensor(22.)\n",
            "Policy 873 Mean Loss: -0.0015021941508166492\n",
            "Entropy 873 Mean Loss: 0.6906502209603786\n",
            "Value 873 Mean Loss: 3.871405005455017\n",
            "dones: tensor(21.)\n",
            "Policy 874 Mean Loss: 0.0010104901157319546\n",
            "Entropy 874 Mean Loss: 0.6909433379769325\n",
            "Value 874 Mean Loss: 4.237427428364754\n",
            "dones: tensor(27.)\n",
            "Policy 875 Mean Loss: 0.0029911408200860023\n",
            "Entropy 875 Mean Loss: 0.6911154538393021\n",
            "Value 875 Mean Loss: 4.535354748368263\n",
            "dones: tensor(19.)\n",
            "Policy 876 Mean Loss: -0.004378223849926144\n",
            "Entropy 876 Mean Loss: 0.6910039111971855\n",
            "Value 876 Mean Loss: 3.8145599216222763\n",
            "dones: tensor(23.)\n",
            "Policy 877 Mean Loss: -0.009390308638103306\n",
            "Entropy 877 Mean Loss: 0.6911545433104038\n",
            "Value 877 Mean Loss: 4.577547207474709\n",
            "dones: tensor(25.)\n",
            "Policy 878 Mean Loss: -0.005898986884858459\n",
            "Entropy 878 Mean Loss: 0.6909668669104576\n",
            "Value 878 Mean Loss: 4.379822641611099\n",
            "dones: tensor(22.)\n",
            "Policy 879 Mean Loss: -0.005746647599153221\n",
            "Entropy 879 Mean Loss: 0.6904258318245411\n",
            "Value 879 Mean Loss: 4.7116996347904205\n",
            "dones: tensor(20.)\n",
            "Policy 880 Mean Loss: -0.0036807101569138467\n",
            "Entropy 880 Mean Loss: 0.6905309781432152\n",
            "Value 880 Mean Loss: 5.101567983627319\n",
            "dones: tensor(22.)\n",
            "Policy 881 Mean Loss: -0.003889414423611015\n",
            "Entropy 881 Mean Loss: 0.6908255144953728\n",
            "Value 881 Mean Loss: 4.386181011795998\n",
            "dones: tensor(21.)\n",
            "Policy 882 Mean Loss: -0.0016183584230020642\n",
            "Entropy 882 Mean Loss: 0.690876193344593\n",
            "Value 882 Mean Loss: 4.241695389151573\n",
            "dones: tensor(23.)\n",
            "Policy 883 Mean Loss: 0.004389400826767087\n",
            "Entropy 883 Mean Loss: 0.6913696825504303\n",
            "Value 883 Mean Loss: 5.1962180733680725\n",
            "dones: tensor(24.)\n",
            "Policy 884 Mean Loss: -0.0014399088686332107\n",
            "Entropy 884 Mean Loss: 0.6914114505052567\n",
            "Value 884 Mean Loss: 5.037645757198334\n",
            "dones: tensor(23.)\n",
            "Policy 885 Mean Loss: -0.005937034671660513\n",
            "Entropy 885 Mean Loss: 0.6914200745522976\n",
            "Value 885 Mean Loss: 3.801277071237564\n",
            "dones: tensor(21.)\n",
            "Policy 886 Mean Loss: -0.0038280055741779506\n",
            "Entropy 886 Mean Loss: 0.6910580061376095\n",
            "Value 886 Mean Loss: 4.233300670981407\n",
            "dones: tensor(20.)\n",
            "Policy 887 Mean Loss: -0.0033788345754146576\n",
            "Entropy 887 Mean Loss: 0.691224679350853\n",
            "Value 887 Mean Loss: 4.617099642753601\n",
            "dones: tensor(23.)\n",
            "Policy 888 Mean Loss: -0.004612148739397526\n",
            "Entropy 888 Mean Loss: 0.6907184012234211\n",
            "Value 888 Mean Loss: 4.594611197710037\n",
            "dones: tensor(25.)\n",
            "Policy 889 Mean Loss: -0.008482058707159013\n",
            "Entropy 889 Mean Loss: 0.6907654702663422\n",
            "Value 889 Mean Loss: 4.594559833407402\n",
            "dones: tensor(19.)\n",
            "Policy 890 Mean Loss: -0.008081018051598221\n",
            "Entropy 890 Mean Loss: 0.6904080882668495\n",
            "Value 890 Mean Loss: 4.4311259388923645\n",
            "dones: tensor(22.)\n",
            "Policy 891 Mean Loss: -0.008174929767847061\n",
            "Entropy 891 Mean Loss: 0.690722431987524\n",
            "Value 891 Mean Loss: 4.333724543452263\n",
            "dones: tensor(19.)\n",
            "Policy 892 Mean Loss: -0.0033651089179329574\n",
            "Entropy 892 Mean Loss: 0.690350379794836\n",
            "Value 892 Mean Loss: 4.257271558046341\n",
            "dones: tensor(22.)\n",
            "Policy 893 Mean Loss: -0.00347451597917825\n",
            "Entropy 893 Mean Loss: 0.6905767843127251\n",
            "Value 893 Mean Loss: 4.354451686143875\n",
            "dones: tensor(27.)\n",
            "Policy 894 Mean Loss: -0.006219412665814161\n",
            "Entropy 894 Mean Loss: 0.6911365985870361\n",
            "Value 894 Mean Loss: 4.826804041862488\n",
            "dones: tensor(20.)\n",
            "Policy 895 Mean Loss: -0.00996040558675304\n",
            "Entropy 895 Mean Loss: 0.690806545317173\n",
            "Value 895 Mean Loss: 4.397476628422737\n",
            "dones: tensor(24.)\n",
            "Policy 896 Mean Loss: -0.007041937846224755\n",
            "Entropy 896 Mean Loss: 0.6906873658299446\n",
            "Value 896 Mean Loss: 4.400001376867294\n",
            "dones: tensor(24.)\n",
            "Policy 897 Mean Loss: -0.010698446887545288\n",
            "Entropy 897 Mean Loss: 0.6907154321670532\n",
            "Value 897 Mean Loss: 4.671053856611252\n",
            "dones: tensor(26.)\n",
            "Policy 898 Mean Loss: -0.007750969962216914\n",
            "Entropy 898 Mean Loss: 0.6909491382539272\n",
            "Value 898 Mean Loss: 4.874838650226593\n",
            "dones: tensor(16.)\n",
            "Policy 899 Mean Loss: -0.01096817766665481\n",
            "Entropy 899 Mean Loss: 0.6901854686439037\n",
            "Value 899 Mean Loss: 4.272017225623131\n",
            "dones: tensor(27.)\n",
            "Policy 900 Mean Loss: -0.013055097195319831\n",
            "Entropy 900 Mean Loss: 0.6905716806650162\n",
            "Value 900 Mean Loss: 5.02880422770977\n",
            "dones: tensor(19.)\n",
            "Policy 901 Mean Loss: -0.013037144322879612\n",
            "Entropy 901 Mean Loss: 0.6897339411079884\n",
            "Value 901 Mean Loss: 4.102581322193146\n",
            "dones: tensor(21.)\n",
            "Policy 902 Mean Loss: -0.005158135551027954\n",
            "Entropy 902 Mean Loss: 0.6902381330728531\n",
            "Value 902 Mean Loss: 4.893409341573715\n",
            "dones: tensor(19.)\n",
            "Policy 903 Mean Loss: -0.008578313805628568\n",
            "Entropy 903 Mean Loss: 0.6900029517710209\n",
            "Value 903 Mean Loss: 4.432943403720856\n",
            "dones: tensor(22.)\n",
            "Policy 904 Mean Loss: -0.008462657453492284\n",
            "Entropy 904 Mean Loss: 0.6905591003596783\n",
            "Value 904 Mean Loss: 4.5117220133543015\n",
            "dones: tensor(22.)\n",
            "Policy 905 Mean Loss: -0.008707086555659771\n",
            "Entropy 905 Mean Loss: 0.6905277669429779\n",
            "Value 905 Mean Loss: 4.354042246937752\n",
            "dones: tensor(23.)\n",
            "Policy 906 Mean Loss: -0.006329485622700304\n",
            "Entropy 906 Mean Loss: 0.6905430406332016\n",
            "Value 906 Mean Loss: 4.013403505086899\n",
            "dones: tensor(30.)\n",
            "Policy 907 Mean Loss: -0.008696963835973293\n",
            "Entropy 907 Mean Loss: 0.690264604985714\n",
            "Value 907 Mean Loss: 5.3416703045368195\n",
            "dones: tensor(24.)\n",
            "Policy 908 Mean Loss: -0.014214339316822588\n",
            "Entropy 908 Mean Loss: 0.689963661134243\n",
            "Value 908 Mean Loss: 4.635098621249199\n",
            "dones: tensor(20.)\n",
            "Policy 909 Mean Loss: -0.003910376864951104\n",
            "Entropy 909 Mean Loss: 0.6903453581035137\n",
            "Value 909 Mean Loss: 4.200360879302025\n",
            "dones: tensor(24.)\n",
            "Policy 910 Mean Loss: -0.01046263478929177\n",
            "Entropy 910 Mean Loss: 0.6904363371431828\n",
            "Value 910 Mean Loss: 4.855871766805649\n",
            "dones: tensor(22.)\n",
            "Policy 911 Mean Loss: -0.006109648616984487\n",
            "Entropy 911 Mean Loss: 0.6907790675759315\n",
            "Value 911 Mean Loss: 4.334511965513229\n",
            "dones: tensor(22.)\n",
            "Policy 912 Mean Loss: -0.008480890013743192\n",
            "Entropy 912 Mean Loss: 0.6908436603844166\n",
            "Value 912 Mean Loss: 3.8885091692209244\n",
            "dones: tensor(23.)\n",
            "Policy 913 Mean Loss: -0.0032428778358735144\n",
            "Entropy 913 Mean Loss: 0.6909129172563553\n",
            "Value 913 Mean Loss: 4.661533981561661\n",
            "dones: tensor(20.)\n",
            "Policy 914 Mean Loss: -0.009251129697076976\n",
            "Entropy 914 Mean Loss: 0.6907311268150806\n",
            "Value 914 Mean Loss: 4.12907375395298\n",
            "dones: tensor(15.)\n",
            "Policy 915 Mean Loss: -0.005640662042424083\n",
            "Entropy 915 Mean Loss: 0.6906401552259922\n",
            "Value 915 Mean Loss: 5.039213925600052\n",
            "dones: tensor(20.)\n",
            "Policy 916 Mean Loss: -0.0005542333237826824\n",
            "Entropy 916 Mean Loss: 0.6909730732440948\n",
            "Value 916 Mean Loss: 4.23154054582119\n",
            "dones: tensor(15.)\n",
            "Policy 917 Mean Loss: 0.0004942467785440385\n",
            "Entropy 917 Mean Loss: 0.6908998899161816\n",
            "Value 917 Mean Loss: 3.619958132505417\n",
            "dones: tensor(22.)\n",
            "Policy 918 Mean Loss: -0.005827946530189365\n",
            "Entropy 918 Mean Loss: 0.6911615058779716\n",
            "Value 918 Mean Loss: 4.803174793720245\n",
            "dones: tensor(23.)\n",
            "Policy 919 Mean Loss: -0.007062201853841543\n",
            "Entropy 919 Mean Loss: 0.6913337670266628\n",
            "Value 919 Mean Loss: 5.538038939237595\n",
            "dones: tensor(20.)\n",
            "Policy 920 Mean Loss: -0.005882599798496813\n",
            "Entropy 920 Mean Loss: 0.6912138946354389\n",
            "Value 920 Mean Loss: 4.230590432882309\n",
            "dones: tensor(21.)\n",
            "Policy 921 Mean Loss: -0.002331192488782108\n",
            "Entropy 921 Mean Loss: 0.691155169159174\n",
            "Value 921 Mean Loss: 4.521305754780769\n",
            "dones: tensor(24.)\n",
            "Policy 922 Mean Loss: -0.004802368232049048\n",
            "Entropy 922 Mean Loss: 0.6914793066680431\n",
            "Value 922 Mean Loss: 4.388734757900238\n",
            "dones: tensor(29.)\n",
            "Policy 923 Mean Loss: -0.008031841251067817\n",
            "Entropy 923 Mean Loss: 0.6914904601871967\n",
            "Value 923 Mean Loss: 5.711606085300446\n",
            "dones: tensor(22.)\n",
            "Policy 924 Mean Loss: -0.007275842304807156\n",
            "Entropy 924 Mean Loss: 0.6913581006228924\n",
            "Value 924 Mean Loss: 5.446303337812424\n",
            "dones: tensor(20.)\n",
            "Policy 925 Mean Loss: -0.0037418538704514503\n",
            "Entropy 925 Mean Loss: 0.691329337656498\n",
            "Value 925 Mean Loss: 4.358185812830925\n",
            "dones: tensor(24.)\n",
            "Policy 926 Mean Loss: -0.006229858554434031\n",
            "Entropy 926 Mean Loss: 0.6912729777395725\n",
            "Value 926 Mean Loss: 4.7748527228832245\n",
            "dones: tensor(23.)\n",
            "Policy 927 Mean Loss: -0.00658384634880349\n",
            "Entropy 927 Mean Loss: 0.6912990510463715\n",
            "Value 927 Mean Loss: 4.613724261522293\n",
            "dones: tensor(23.)\n",
            "Policy 928 Mean Loss: -0.002529009710997343\n",
            "Entropy 928 Mean Loss: 0.6915004104375839\n",
            "Value 928 Mean Loss: 5.712742581963539\n",
            "dones: tensor(24.)\n",
            "Policy 929 Mean Loss: -0.0053729095961898565\n",
            "Entropy 929 Mean Loss: 0.6916976571083069\n",
            "Value 929 Mean Loss: 5.00093612074852\n",
            "dones: tensor(20.)\n",
            "Policy 930 Mean Loss: -0.0026209192583337426\n",
            "Entropy 930 Mean Loss: 0.6917392946779728\n",
            "Value 930 Mean Loss: 4.9085333943367\n",
            "dones: tensor(21.)\n",
            "Policy 931 Mean Loss: -0.004526811128016561\n",
            "Entropy 931 Mean Loss: 0.69178307056427\n",
            "Value 931 Mean Loss: 5.3915514051914215\n",
            "dones: tensor(23.)\n",
            "Policy 932 Mean Loss: -0.005045883473940194\n",
            "Entropy 932 Mean Loss: 0.6917452216148376\n",
            "Value 932 Mean Loss: 4.23523111641407\n",
            "dones: tensor(21.)\n",
            "Policy 933 Mean Loss: -0.005604091857094318\n",
            "Entropy 933 Mean Loss: 0.6918004304170609\n",
            "Value 933 Mean Loss: 5.012175887823105\n",
            "dones: tensor(22.)\n",
            "Policy 934 Mean Loss: -0.006597836269065738\n",
            "Entropy 934 Mean Loss: 0.6913689635694027\n",
            "Value 934 Mean Loss: 4.5347936898469925\n",
            "dones: tensor(21.)\n",
            "Policy 935 Mean Loss: -0.00794654106721282\n",
            "Entropy 935 Mean Loss: 0.6912238001823425\n",
            "Value 935 Mean Loss: 4.724121451377869\n",
            "dones: tensor(29.)\n",
            "Policy 936 Mean Loss: -0.005946017685346305\n",
            "Entropy 936 Mean Loss: 0.6913532540202141\n",
            "Value 936 Mean Loss: 5.187590777873993\n",
            "dones: tensor(25.)\n",
            "Policy 937 Mean Loss: -0.0011683153570629656\n",
            "Entropy 937 Mean Loss: 0.6913252845406532\n",
            "Value 937 Mean Loss: 4.472692057490349\n",
            "dones: tensor(23.)\n",
            "Policy 938 Mean Loss: -0.006198323506396264\n",
            "Entropy 938 Mean Loss: 0.6914314366877079\n",
            "Value 938 Mean Loss: 4.203940719366074\n",
            "dones: tensor(18.)\n",
            "Policy 939 Mean Loss: -0.005367422359995544\n",
            "Entropy 939 Mean Loss: 0.6914454698562622\n",
            "Value 939 Mean Loss: 3.9591371715068817\n",
            "dones: tensor(25.)\n",
            "Policy 940 Mean Loss: -0.006480994343291968\n",
            "Entropy 940 Mean Loss: 0.6914551071822643\n",
            "Value 940 Mean Loss: 4.49119645357132\n",
            "dones: tensor(21.)\n",
            "Policy 941 Mean Loss: -0.00613013788824901\n",
            "Entropy 941 Mean Loss: 0.6912894360721111\n",
            "Value 941 Mean Loss: 4.138740748167038\n",
            "dones: tensor(24.)\n",
            "Policy 942 Mean Loss: -0.004460437863599509\n",
            "Entropy 942 Mean Loss: 0.6913701333105564\n",
            "Value 942 Mean Loss: 4.3166342079639435\n",
            "dones: tensor(22.)\n",
            "Policy 943 Mean Loss: -0.0058667497942224145\n",
            "Entropy 943 Mean Loss: 0.6911797076463699\n",
            "Value 943 Mean Loss: 4.599048405885696\n",
            "dones: tensor(22.)\n",
            "Policy 944 Mean Loss: -0.004458030452951789\n",
            "Entropy 944 Mean Loss: 0.6912015788257122\n",
            "Value 944 Mean Loss: 4.195377752184868\n",
            "dones: tensor(25.)\n",
            "Policy 945 Mean Loss: -0.005469891184475273\n",
            "Entropy 945 Mean Loss: 0.6913166530430317\n",
            "Value 945 Mean Loss: 4.7303164303302765\n",
            "dones: tensor(24.)\n",
            "Policy 946 Mean Loss: -0.009974732587579638\n",
            "Entropy 946 Mean Loss: 0.6907867379486561\n",
            "Value 946 Mean Loss: 4.730471134185791\n",
            "dones: tensor(23.)\n",
            "Policy 947 Mean Loss: -0.009685999248176813\n",
            "Entropy 947 Mean Loss: 0.6906796991825104\n",
            "Value 947 Mean Loss: 4.215707302093506\n",
            "dones: tensor(23.)\n",
            "Policy 948 Mean Loss: -0.009596463642083108\n",
            "Entropy 948 Mean Loss: 0.6907624937593937\n",
            "Value 948 Mean Loss: 4.671148955821991\n",
            "dones: tensor(24.)\n",
            "Policy 949 Mean Loss: -0.008045251830480993\n",
            "Entropy 949 Mean Loss: 0.6908449418842793\n",
            "Value 949 Mean Loss: 4.5441418290138245\n",
            "dones: tensor(21.)\n",
            "Policy 950 Mean Loss: -0.004363733227364719\n",
            "Entropy 950 Mean Loss: 0.6909061633050442\n",
            "Value 950 Mean Loss: 4.5090097934007645\n",
            "dones: tensor(24.)\n",
            "Policy 951 Mean Loss: -0.008444302366115153\n",
            "Entropy 951 Mean Loss: 0.6907878220081329\n",
            "Value 951 Mean Loss: 5.029400110244751\n",
            "dones: tensor(25.)\n",
            "Policy 952 Mean Loss: -0.010456546326167881\n",
            "Entropy 952 Mean Loss: 0.6907473467290401\n",
            "Value 952 Mean Loss: 5.392584830522537\n",
            "dones: tensor(25.)\n",
            "Policy 953 Mean Loss: -0.011726196098607033\n",
            "Entropy 953 Mean Loss: 0.6897171661257744\n",
            "Value 953 Mean Loss: 4.352277413010597\n",
            "dones: tensor(19.)\n",
            "Policy 954 Mean Loss: -0.005299319920595735\n",
            "Entropy 954 Mean Loss: 0.6897397935390472\n",
            "Value 954 Mean Loss: 4.1666197925806046\n",
            "dones: tensor(25.)\n",
            "Policy 955 Mean Loss: -0.011777819483540952\n",
            "Entropy 955 Mean Loss: 0.689972635358572\n",
            "Value 955 Mean Loss: 4.561448484659195\n",
            "dones: tensor(24.)\n",
            "Policy 956 Mean Loss: -0.008328690950293094\n",
            "Entropy 956 Mean Loss: 0.6904670968651772\n",
            "Value 956 Mean Loss: 4.2879025638103485\n",
            "dones: tensor(26.)\n",
            "Policy 957 Mean Loss: -0.005969212972559035\n",
            "Entropy 957 Mean Loss: 0.6910015195608139\n",
            "Value 957 Mean Loss: 4.95159113407135\n",
            "dones: tensor(24.)\n",
            "Policy 958 Mean Loss: -0.012825940852053463\n",
            "Entropy 958 Mean Loss: 0.6906429082155228\n",
            "Value 958 Mean Loss: 4.230212464928627\n",
            "dones: tensor(27.)\n",
            "Policy 959 Mean Loss: -0.00850292871473357\n",
            "Entropy 959 Mean Loss: 0.6909956373274326\n",
            "Value 959 Mean Loss: 4.3234065771102905\n",
            "dones: tensor(22.)\n",
            "Policy 960 Mean Loss: -0.01311434229137376\n",
            "Entropy 960 Mean Loss: 0.6906195916235447\n",
            "Value 960 Mean Loss: 3.8206854164600372\n",
            "dones: tensor(23.)\n",
            "Policy 961 Mean Loss: -0.006037512270268053\n",
            "Entropy 961 Mean Loss: 0.6906361989676952\n",
            "Value 961 Mean Loss: 4.217077419161797\n",
            "dones: tensor(22.)\n",
            "Policy 962 Mean Loss: -0.006184905709233135\n",
            "Entropy 962 Mean Loss: 0.6909179612994194\n",
            "Value 962 Mean Loss: 3.7639324218034744\n",
            "dones: tensor(24.)\n",
            "Policy 963 Mean Loss: -0.009405025222804397\n",
            "Entropy 963 Mean Loss: 0.6910584643483162\n",
            "Value 963 Mean Loss: 4.726333051919937\n",
            "dones: tensor(20.)\n",
            "Policy 964 Mean Loss: -0.008142932143528014\n",
            "Entropy 964 Mean Loss: 0.6907261535525322\n",
            "Value 964 Mean Loss: 3.90871824324131\n",
            "dones: tensor(19.)\n",
            "Policy 965 Mean Loss: -0.01031781587516889\n",
            "Entropy 965 Mean Loss: 0.6912255436182022\n",
            "Value 965 Mean Loss: 4.193933516740799\n",
            "dones: tensor(18.)\n",
            "Policy 966 Mean Loss: -0.0074516586028039455\n",
            "Entropy 966 Mean Loss: 0.6911993212997913\n",
            "Value 966 Mean Loss: 6.316303491592407\n",
            "dones: tensor(21.)\n",
            "Policy 967 Mean Loss: -0.007799195998813957\n",
            "Entropy 967 Mean Loss: 0.6912020295858383\n",
            "Value 967 Mean Loss: 5.167392283678055\n",
            "dones: tensor(27.)\n",
            "Policy 968 Mean Loss: -0.008118070603813976\n",
            "Entropy 968 Mean Loss: 0.6911230012774467\n",
            "Value 968 Mean Loss: 5.657647430896759\n",
            "dones: tensor(21.)\n",
            "Policy 969 Mean Loss: -0.007393851527012885\n",
            "Entropy 969 Mean Loss: 0.6909429281949997\n",
            "Value 969 Mean Loss: 4.417958706617355\n",
            "dones: tensor(27.)\n",
            "Policy 970 Mean Loss: -0.00811404240084812\n",
            "Entropy 970 Mean Loss: 0.6911062896251678\n",
            "Value 970 Mean Loss: 5.070446282625198\n",
            "dones: tensor(26.)\n",
            "Policy 971 Mean Loss: -0.0076647556852549314\n",
            "Entropy 971 Mean Loss: 0.6907137036323547\n",
            "Value 971 Mean Loss: 5.139923721551895\n",
            "dones: tensor(17.)\n",
            "Policy 972 Mean Loss: -0.009941875585354865\n",
            "Entropy 972 Mean Loss: 0.6907632946968079\n",
            "Value 972 Mean Loss: 4.646675109863281\n",
            "dones: tensor(20.)\n",
            "Policy 973 Mean Loss: -0.010405378241557628\n",
            "Entropy 973 Mean Loss: 0.6905392482876778\n",
            "Value 973 Mean Loss: 4.217251002788544\n",
            "dones: tensor(23.)\n",
            "Policy 974 Mean Loss: -0.006307121249847114\n",
            "Entropy 974 Mean Loss: 0.6908102259039879\n",
            "Value 974 Mean Loss: 4.5124766528606415\n",
            "dones: tensor(25.)\n",
            "Policy 975 Mean Loss: -0.009471210069023073\n",
            "Entropy 975 Mean Loss: 0.6910532414913177\n",
            "Value 975 Mean Loss: 4.7304627895355225\n",
            "dones: tensor(21.)\n",
            "Policy 976 Mean Loss: -0.009871597634628415\n",
            "Entropy 976 Mean Loss: 0.6909135580062866\n",
            "Value 976 Mean Loss: 4.34761506319046\n",
            "dones: tensor(23.)\n",
            "Policy 977 Mean Loss: -0.007141530164517462\n",
            "Entropy 977 Mean Loss: 0.6908359825611115\n",
            "Value 977 Mean Loss: 5.222239643335342\n",
            "dones: tensor(22.)\n",
            "Policy 978 Mean Loss: -0.008008346048882231\n",
            "Entropy 978 Mean Loss: 0.6908495053648949\n",
            "Value 978 Mean Loss: 4.673276290297508\n",
            "dones: tensor(22.)\n",
            "Policy 979 Mean Loss: -0.006786341487895697\n",
            "Entropy 979 Mean Loss: 0.6908156909048557\n",
            "Value 979 Mean Loss: 4.5437261164188385\n",
            "dones: tensor(14.)\n",
            "Policy 980 Mean Loss: -0.009581715799868107\n",
            "Entropy 980 Mean Loss: 0.6903965696692467\n",
            "Value 980 Mean Loss: 4.522351622581482\n",
            "dones: tensor(22.)\n",
            "Policy 981 Mean Loss: -0.01018550555454567\n",
            "Entropy 981 Mean Loss: 0.6907649599015713\n",
            "Value 981 Mean Loss: 4.810314774513245\n",
            "dones: tensor(26.)\n",
            "Policy 982 Mean Loss: -0.004602866596542299\n",
            "Entropy 982 Mean Loss: 0.690726175904274\n",
            "Value 982 Mean Loss: 5.160408109426498\n",
            "dones: tensor(25.)\n",
            "Policy 983 Mean Loss: -0.006129532295744866\n",
            "Entropy 983 Mean Loss: 0.6909020468592644\n",
            "Value 983 Mean Loss: 4.343650117516518\n",
            "dones: tensor(26.)\n",
            "Policy 984 Mean Loss: -0.006340738676954061\n",
            "Entropy 984 Mean Loss: 0.6908045932650566\n",
            "Value 984 Mean Loss: 4.78853939473629\n",
            "dones: tensor(23.)\n",
            "Policy 985 Mean Loss: -0.005738329404266551\n",
            "Entropy 985 Mean Loss: 0.6905964761972427\n",
            "Value 985 Mean Loss: 4.34988908469677\n",
            "dones: tensor(22.)\n",
            "Policy 986 Mean Loss: -0.010691907431464642\n",
            "Entropy 986 Mean Loss: 0.6907357200980186\n",
            "Value 986 Mean Loss: 4.360946208238602\n",
            "dones: tensor(24.)\n",
            "Policy 987 Mean Loss: -0.00970318610779941\n",
            "Entropy 987 Mean Loss: 0.6909186691045761\n",
            "Value 987 Mean Loss: 4.188221260905266\n",
            "dones: tensor(25.)\n",
            "Policy 988 Mean Loss: -0.0044981230166740716\n",
            "Entropy 988 Mean Loss: 0.690928190946579\n",
            "Value 988 Mean Loss: 4.490258753299713\n",
            "dones: tensor(24.)\n",
            "Policy 989 Mean Loss: -0.0018190976697951555\n",
            "Entropy 989 Mean Loss: 0.6912425868213177\n",
            "Value 989 Mean Loss: 4.073186576366425\n",
            "dones: tensor(18.)\n",
            "Policy 990 Mean Loss: -0.002814085630234331\n",
            "Entropy 990 Mean Loss: 0.6908124536275864\n",
            "Value 990 Mean Loss: 4.152479276061058\n",
            "dones: tensor(25.)\n",
            "Policy 991 Mean Loss: -0.0046794842928647995\n",
            "Entropy 991 Mean Loss: 0.6912460029125214\n",
            "Value 991 Mean Loss: 4.840714514255524\n",
            "dones: tensor(24.)\n",
            "Policy 992 Mean Loss: -0.006172334076836705\n",
            "Entropy 992 Mean Loss: 0.6913106739521027\n",
            "Value 992 Mean Loss: 4.428215399384499\n",
            "dones: tensor(22.)\n",
            "Policy 993 Mean Loss: -0.0028303390135988593\n",
            "Entropy 993 Mean Loss: 0.6912051178514957\n",
            "Value 993 Mean Loss: 5.438066303730011\n",
            "dones: tensor(20.)\n",
            "Policy 994 Mean Loss: -0.005990399688016623\n",
            "Entropy 994 Mean Loss: 0.6907652392983437\n",
            "Value 994 Mean Loss: 4.360733330249786\n",
            "dones: tensor(18.)\n",
            "Policy 995 Mean Loss: -0.0014996862155385315\n",
            "Entropy 995 Mean Loss: 0.6905586011707783\n",
            "Value 995 Mean Loss: 3.9901070445775986\n",
            "dones: tensor(23.)\n",
            "Policy 996 Mean Loss: -0.008336419938132167\n",
            "Entropy 996 Mean Loss: 0.6909666173160076\n",
            "Value 996 Mean Loss: 4.887031674385071\n",
            "dones: tensor(24.)\n",
            "Policy 997 Mean Loss: -0.010761234036181122\n",
            "Entropy 997 Mean Loss: 0.690843652933836\n",
            "Value 997 Mean Loss: 4.862767785787582\n",
            "dones: tensor(21.)\n",
            "Policy 998 Mean Loss: -0.006676506949588656\n",
            "Entropy 998 Mean Loss: 0.6906543113291264\n",
            "Value 998 Mean Loss: 4.988622009754181\n",
            "dones: tensor(16.)\n",
            "Policy 999 Mean Loss: 1.3359705917537212e-05\n",
            "Entropy 999 Mean Loss: 0.6904890164732933\n",
            "Value 999 Mean Loss: 5.428224831819534\n",
            "dones: tensor(25.)\n",
            "Policy 1000 Mean Loss: -0.008517946174833924\n",
            "Entropy 1000 Mean Loss: 0.690655954182148\n",
            "Value 1000 Mean Loss: 4.880911201238632\n",
            "dones: tensor(20.)\n",
            "Policy 1001 Mean Loss: -0.007179768057540059\n",
            "Entropy 1001 Mean Loss: 0.6904263943433762\n",
            "Value 1001 Mean Loss: 4.947016686201096\n",
            "dones: tensor(23.)\n",
            "Policy 1002 Mean Loss: -0.006508391699753702\n",
            "Entropy 1002 Mean Loss: 0.6907183825969696\n",
            "Value 1002 Mean Loss: 4.610430538654327\n",
            "dones: tensor(22.)\n",
            "Policy 1003 Mean Loss: -0.0062135734769981354\n",
            "Entropy 1003 Mean Loss: 0.6909787617623806\n",
            "Value 1003 Mean Loss: 4.176861837506294\n",
            "dones: tensor(19.)\n",
            "Policy 1004 Mean Loss: -0.002812787512084469\n",
            "Entropy 1004 Mean Loss: 0.6912045516073704\n",
            "Value 1004 Mean Loss: 4.347216486930847\n",
            "dones: tensor(21.)\n",
            "Policy 1005 Mean Loss: -0.004082562285475433\n",
            "Entropy 1005 Mean Loss: 0.691267304122448\n",
            "Value 1005 Mean Loss: 5.0125842690467834\n",
            "dones: tensor(21.)\n",
            "Policy 1006 Mean Loss: -0.00626921106595546\n",
            "Entropy 1006 Mean Loss: 0.6908402480185032\n",
            "Value 1006 Mean Loss: 5.047316551208496\n",
            "dones: tensor(21.)\n",
            "Policy 1007 Mean Loss: -0.00840219808742404\n",
            "Entropy 1007 Mean Loss: 0.6904997080564499\n",
            "Value 1007 Mean Loss: 4.138871386647224\n",
            "dones: tensor(22.)\n",
            "Policy 1008 Mean Loss: -0.0007275562966242433\n",
            "Entropy 1008 Mean Loss: 0.690739382058382\n",
            "Value 1008 Mean Loss: 5.102456152439117\n",
            "dones: tensor(20.)\n",
            "Policy 1009 Mean Loss: -0.009695617482066154\n",
            "Entropy 1009 Mean Loss: 0.6905943490564823\n",
            "Value 1009 Mean Loss: 4.472260147333145\n",
            "dones: tensor(21.)\n",
            "Policy 1010 Mean Loss: -0.007829612586647272\n",
            "Entropy 1010 Mean Loss: 0.6909315213561058\n",
            "Value 1010 Mean Loss: 5.000605285167694\n",
            "dones: tensor(24.)\n",
            "Policy 1011 Mean Loss: -0.008025572227779776\n",
            "Entropy 1011 Mean Loss: 0.6909069120883942\n",
            "Value 1011 Mean Loss: 4.867135107517242\n",
            "dones: tensor(21.)\n",
            "Policy 1012 Mean Loss: -0.011918317002709955\n",
            "Entropy 1012 Mean Loss: 0.6908268593251705\n",
            "Value 1012 Mean Loss: 4.462067723274231\n",
            "dones: tensor(25.)\n",
            "Policy 1013 Mean Loss: -0.004944478394463658\n",
            "Entropy 1013 Mean Loss: 0.6908004432916641\n",
            "Value 1013 Mean Loss: 4.9314287304878235\n",
            "dones: tensor(22.)\n",
            "Policy 1014 Mean Loss: -0.0032237754785455763\n",
            "Entropy 1014 Mean Loss: 0.690755307674408\n",
            "Value 1014 Mean Loss: 4.686812520027161\n",
            "dones: tensor(24.)\n",
            "Policy 1015 Mean Loss: -0.0032959133968688548\n",
            "Entropy 1015 Mean Loss: 0.6908186674118042\n",
            "Value 1015 Mean Loss: 5.019797146320343\n",
            "dones: tensor(21.)\n",
            "Policy 1016 Mean Loss: -0.006179110845550895\n",
            "Entropy 1016 Mean Loss: 0.6905677653849125\n",
            "Value 1016 Mean Loss: 4.769957035779953\n",
            "dones: tensor(28.)\n",
            "Policy 1017 Mean Loss: -0.0011145499302074313\n",
            "Entropy 1017 Mean Loss: 0.6909756101667881\n",
            "Value 1017 Mean Loss: 4.808446824550629\n",
            "dones: tensor(21.)\n",
            "Policy 1018 Mean Loss: -0.004885831498540938\n",
            "Entropy 1018 Mean Loss: 0.6908727250993252\n",
            "Value 1018 Mean Loss: 4.6488200426101685\n",
            "dones: tensor(19.)\n",
            "Policy 1019 Mean Loss: -0.008110825612675399\n",
            "Entropy 1019 Mean Loss: 0.6905404180288315\n",
            "Value 1019 Mean Loss: 3.815047040581703\n",
            "dones: tensor(22.)\n",
            "Policy 1020 Mean Loss: -0.004796120338141918\n",
            "Entropy 1020 Mean Loss: 0.6904162466526031\n",
            "Value 1020 Mean Loss: 4.342573821544647\n",
            "dones: tensor(22.)\n",
            "Policy 1021 Mean Loss: -0.007130377634894103\n",
            "Entropy 1021 Mean Loss: 0.6903877481818199\n",
            "Value 1021 Mean Loss: 4.593667447566986\n",
            "dones: tensor(24.)\n",
            "Policy 1022 Mean Loss: -0.00710928748594597\n",
            "Entropy 1022 Mean Loss: 0.6906231753528118\n",
            "Value 1022 Mean Loss: 4.705534264445305\n",
            "dones: tensor(24.)\n",
            "Policy 1023 Mean Loss: -0.013023784675169736\n",
            "Entropy 1023 Mean Loss: 0.690413199365139\n",
            "Value 1023 Mean Loss: 5.268168240785599\n",
            "dones: tensor(24.)\n",
            "Policy 1024 Mean Loss: -0.0062724563758820295\n",
            "Entropy 1024 Mean Loss: 0.6905732937157154\n",
            "Value 1024 Mean Loss: 4.294888913631439\n",
            "dones: tensor(22.)\n",
            "Policy 1025 Mean Loss: -0.0087211785139516\n",
            "Entropy 1025 Mean Loss: 0.6909205615520477\n",
            "Value 1025 Mean Loss: 4.404174193739891\n",
            "dones: tensor(20.)\n",
            "Policy 1026 Mean Loss: -0.010307682096026838\n",
            "Entropy 1026 Mean Loss: 0.6908047460019588\n",
            "Value 1026 Mean Loss: 3.909921035170555\n",
            "dones: tensor(25.)\n",
            "Policy 1027 Mean Loss: -0.007835119438823313\n",
            "Entropy 1027 Mean Loss: 0.6911699362099171\n",
            "Value 1027 Mean Loss: 4.793704271316528\n",
            "dones: tensor(25.)\n",
            "Policy 1028 Mean Loss: 0.0035106924478895962\n",
            "Entropy 1028 Mean Loss: 0.6910785287618637\n",
            "Value 1028 Mean Loss: 4.151211112737656\n",
            "dones: tensor(24.)\n",
            "Policy 1029 Mean Loss: -0.00887879595393315\n",
            "Entropy 1029 Mean Loss: 0.6910147033631802\n",
            "Value 1029 Mean Loss: 3.943817988038063\n",
            "dones: tensor(18.)\n",
            "Policy 1030 Mean Loss: -0.008348300907528028\n",
            "Entropy 1030 Mean Loss: 0.6905574575066566\n",
            "Value 1030 Mean Loss: 4.029426619410515\n",
            "dones: tensor(24.)\n",
            "Policy 1031 Mean Loss: -0.010910719982348382\n",
            "Entropy 1031 Mean Loss: 0.690610196441412\n",
            "Value 1031 Mean Loss: 4.085659459233284\n",
            "dones: tensor(27.)\n",
            "Policy 1032 Mean Loss: -0.006206256453879178\n",
            "Entropy 1032 Mean Loss: 0.6908575482666492\n",
            "Value 1032 Mean Loss: 4.681226283311844\n",
            "dones: tensor(24.)\n",
            "Policy 1033 Mean Loss: -0.004491122788749635\n",
            "Entropy 1033 Mean Loss: 0.690854649990797\n",
            "Value 1033 Mean Loss: 4.824508726596832\n",
            "dones: tensor(24.)\n",
            "Policy 1034 Mean Loss: -0.0035428135888651013\n",
            "Entropy 1034 Mean Loss: 0.69087128713727\n",
            "Value 1034 Mean Loss: 4.252499267458916\n",
            "dones: tensor(23.)\n",
            "Policy 1035 Mean Loss: -0.004178340896032751\n",
            "Entropy 1035 Mean Loss: 0.6908684447407722\n",
            "Value 1035 Mean Loss: 3.9078239053487778\n",
            "dones: tensor(25.)\n",
            "Policy 1036 Mean Loss: -0.005787842092104256\n",
            "Entropy 1036 Mean Loss: 0.6910373754799366\n",
            "Value 1036 Mean Loss: 4.201428219676018\n",
            "dones: tensor(18.)\n",
            "Policy 1037 Mean Loss: -0.006498465198092163\n",
            "Entropy 1037 Mean Loss: 0.6906697601079941\n",
            "Value 1037 Mean Loss: 4.659551218152046\n",
            "dones: tensor(22.)\n",
            "Policy 1038 Mean Loss: -0.007908892235718668\n",
            "Entropy 1038 Mean Loss: 0.690739531069994\n",
            "Value 1038 Mean Loss: 4.175356313586235\n",
            "dones: tensor(22.)\n",
            "Policy 1039 Mean Loss: -0.005764877365436405\n",
            "Entropy 1039 Mean Loss: 0.6906951740384102\n",
            "Value 1039 Mean Loss: 4.396804943680763\n",
            "dones: tensor(19.)\n",
            "Policy 1040 Mean Loss: -0.006093502801377326\n",
            "Entropy 1040 Mean Loss: 0.6909326314926147\n",
            "Value 1040 Mean Loss: 4.18152379989624\n",
            "dones: tensor(22.)\n",
            "Policy 1041 Mean Loss: -0.0060794351738877594\n",
            "Entropy 1041 Mean Loss: 0.6908199116587639\n",
            "Value 1041 Mean Loss: 4.088701233267784\n",
            "dones: tensor(25.)\n",
            "Policy 1042 Mean Loss: -0.00825685408199206\n",
            "Entropy 1042 Mean Loss: 0.6910836659371853\n",
            "Value 1042 Mean Loss: 4.851439297199249\n",
            "dones: tensor(18.)\n",
            "Policy 1043 Mean Loss: -0.0033767855493351817\n",
            "Entropy 1043 Mean Loss: 0.6907085441052914\n",
            "Value 1043 Mean Loss: 4.152288228273392\n",
            "dones: tensor(20.)\n",
            "Policy 1044 Mean Loss: -0.0042570390505716205\n",
            "Entropy 1044 Mean Loss: 0.690678495913744\n",
            "Value 1044 Mean Loss: 3.7692652195692062\n",
            "dones: tensor(20.)\n",
            "Policy 1045 Mean Loss: -0.0073009367333725095\n",
            "Entropy 1045 Mean Loss: 0.6909937746822834\n",
            "Value 1045 Mean Loss: 4.787191063165665\n",
            "dones: tensor(26.)\n",
            "Policy 1046 Mean Loss: -0.004437557712662965\n",
            "Entropy 1046 Mean Loss: 0.6910530850291252\n",
            "Value 1046 Mean Loss: 4.886339247226715\n",
            "dones: tensor(17.)\n",
            "Policy 1047 Mean Loss: -0.008319504093378782\n",
            "Entropy 1047 Mean Loss: 0.6908983588218689\n",
            "Value 1047 Mean Loss: 4.577746152877808\n",
            "dones: tensor(22.)\n",
            "Policy 1048 Mean Loss: -0.005414495535660535\n",
            "Entropy 1048 Mean Loss: 0.6909750215709209\n",
            "Value 1048 Mean Loss: 4.497936487197876\n",
            "dones: tensor(21.)\n",
            "Policy 1049 Mean Loss: -0.00922732037724927\n",
            "Entropy 1049 Mean Loss: 0.6911445558071136\n",
            "Value 1049 Mean Loss: 4.644868791103363\n",
            "dones: tensor(22.)\n",
            "Policy 1050 Mean Loss: -0.009862045350018889\n",
            "Entropy 1050 Mean Loss: 0.6908680610358715\n",
            "Value 1050 Mean Loss: 4.7871644496917725\n",
            "dones: tensor(23.)\n",
            "Policy 1051 Mean Loss: -0.007471791177522391\n",
            "Entropy 1051 Mean Loss: 0.6909001804888248\n",
            "Value 1051 Mean Loss: 4.941381514072418\n",
            "dones: tensor(21.)\n",
            "Policy 1052 Mean Loss: -0.009446644660783932\n",
            "Entropy 1052 Mean Loss: 0.69019940122962\n",
            "Value 1052 Mean Loss: 4.361040323972702\n",
            "dones: tensor(24.)\n",
            "Policy 1053 Mean Loss: -0.0087062256061472\n",
            "Entropy 1053 Mean Loss: 0.6903939135372639\n",
            "Value 1053 Mean Loss: 4.674208790063858\n",
            "dones: tensor(27.)\n",
            "Policy 1054 Mean Loss: -0.0037371704529505223\n",
            "Entropy 1054 Mean Loss: 0.6907963715493679\n",
            "Value 1054 Mean Loss: 5.445328414440155\n",
            "dones: tensor(21.)\n",
            "Policy 1055 Mean Loss: -0.01389725657645613\n",
            "Entropy 1055 Mean Loss: 0.6906269304454327\n",
            "Value 1055 Mean Loss: 4.526302099227905\n",
            "dones: tensor(21.)\n",
            "Policy 1056 Mean Loss: -0.0031998504418879747\n",
            "Entropy 1056 Mean Loss: 0.6908170878887177\n",
            "Value 1056 Mean Loss: 4.789844244718552\n",
            "dones: tensor(23.)\n",
            "Policy 1057 Mean Loss: -0.009956386755220592\n",
            "Entropy 1057 Mean Loss: 0.6909006759524345\n",
            "Value 1057 Mean Loss: 5.072656959295273\n",
            "dones: tensor(21.)\n",
            "Policy 1058 Mean Loss: -0.0012305565760470927\n",
            "Entropy 1058 Mean Loss: 0.6909897141158581\n",
            "Value 1058 Mean Loss: 4.334181323647499\n",
            "dones: tensor(22.)\n",
            "Policy 1059 Mean Loss: -0.0032796463929116726\n",
            "Entropy 1059 Mean Loss: 0.6907553002238274\n",
            "Value 1059 Mean Loss: 4.792255014181137\n",
            "dones: tensor(26.)\n",
            "Policy 1060 Mean Loss: -0.008242670854087919\n",
            "Entropy 1060 Mean Loss: 0.6906778253614902\n",
            "Value 1060 Mean Loss: 4.723784238100052\n",
            "dones: tensor(21.)\n",
            "Policy 1061 Mean Loss: -0.009992926148697734\n",
            "Entropy 1061 Mean Loss: 0.6905351057648659\n",
            "Value 1061 Mean Loss: 4.469283759593964\n",
            "dones: tensor(21.)\n",
            "Policy 1062 Mean Loss: -0.005931744701229036\n",
            "Entropy 1062 Mean Loss: 0.6906600929796696\n",
            "Value 1062 Mean Loss: 3.9585737138986588\n",
            "dones: tensor(18.)\n",
            "Policy 1063 Mean Loss: -0.005026649567298591\n",
            "Entropy 1063 Mean Loss: 0.6909932754933834\n",
            "Value 1063 Mean Loss: 4.0485245287418365\n",
            "dones: tensor(17.)\n",
            "Policy 1064 Mean Loss: 0.0018159797473344952\n",
            "Entropy 1064 Mean Loss: 0.6913203112781048\n",
            "Value 1064 Mean Loss: 4.296454161405563\n",
            "dones: tensor(19.)\n",
            "Policy 1065 Mean Loss: -0.008055860409513116\n",
            "Entropy 1065 Mean Loss: 0.6909834444522858\n",
            "Value 1065 Mean Loss: 4.204982236027718\n",
            "dones: tensor(18.)\n",
            "Policy 1066 Mean Loss: -0.005934020853601396\n",
            "Entropy 1066 Mean Loss: 0.6908368766307831\n",
            "Value 1066 Mean Loss: 4.49809367954731\n",
            "dones: tensor(20.)\n",
            "Policy 1067 Mean Loss: -0.003917601658031344\n",
            "Entropy 1067 Mean Loss: 0.690594457089901\n",
            "Value 1067 Mean Loss: 5.1943250596523285\n",
            "dones: tensor(26.)\n",
            "Policy 1068 Mean Loss: -0.0035932736936956644\n",
            "Entropy 1068 Mean Loss: 0.6906514726579189\n",
            "Value 1068 Mean Loss: 5.62902158498764\n",
            "dones: tensor(20.)\n",
            "Policy 1069 Mean Loss: -0.006732294394169003\n",
            "Entropy 1069 Mean Loss: 0.6899420656263828\n",
            "Value 1069 Mean Loss: 4.28905688226223\n",
            "dones: tensor(26.)\n",
            "Policy 1070 Mean Loss: -0.011910759145393968\n",
            "Entropy 1070 Mean Loss: 0.6907149739563465\n",
            "Value 1070 Mean Loss: 5.482036978006363\n",
            "dones: tensor(27.)\n",
            "Policy 1071 Mean Loss: -0.008663528540637344\n",
            "Entropy 1071 Mean Loss: 0.6910383962094784\n",
            "Value 1071 Mean Loss: 5.01521509885788\n",
            "dones: tensor(24.)\n",
            "Policy 1072 Mean Loss: -0.002059991005808115\n",
            "Entropy 1072 Mean Loss: 0.6904958039522171\n",
            "Value 1072 Mean Loss: 4.547534182667732\n",
            "dones: tensor(25.)\n",
            "Policy 1073 Mean Loss: -0.006856333697214723\n",
            "Entropy 1073 Mean Loss: 0.6904637962579727\n",
            "Value 1073 Mean Loss: 5.832123249769211\n",
            "dones: tensor(19.)\n",
            "Policy 1074 Mean Loss: -0.004633234755601734\n",
            "Entropy 1074 Mean Loss: 0.6902558468282223\n",
            "Value 1074 Mean Loss: 4.5512905567884445\n",
            "dones: tensor(24.)\n",
            "Policy 1075 Mean Loss: -0.010185380990151316\n",
            "Entropy 1075 Mean Loss: 0.6906426213681698\n",
            "Value 1075 Mean Loss: 5.067847698926926\n",
            "dones: tensor(20.)\n",
            "Policy 1076 Mean Loss: -0.009342168748844415\n",
            "Entropy 1076 Mean Loss: 0.690346896648407\n",
            "Value 1076 Mean Loss: 4.482711017131805\n",
            "dones: tensor(25.)\n",
            "Policy 1077 Mean Loss: -0.004073043528478593\n",
            "Entropy 1077 Mean Loss: 0.6909391209483147\n",
            "Value 1077 Mean Loss: 5.238769739866257\n",
            "dones: tensor(20.)\n",
            "Policy 1078 Mean Loss: -0.0029640483553521335\n",
            "Entropy 1078 Mean Loss: 0.6910027749836445\n",
            "Value 1078 Mean Loss: 5.365863412618637\n",
            "dones: tensor(25.)\n",
            "Policy 1079 Mean Loss: -0.008364465727936476\n",
            "Entropy 1079 Mean Loss: 0.690943282097578\n",
            "Value 1079 Mean Loss: 5.088809132575989\n",
            "dones: tensor(26.)\n",
            "Policy 1080 Mean Loss: -0.009911937813740224\n",
            "Entropy 1080 Mean Loss: 0.691239982843399\n",
            "Value 1080 Mean Loss: 4.944448292255402\n",
            "dones: tensor(24.)\n",
            "Policy 1081 Mean Loss: -0.0032097157672978938\n",
            "Entropy 1081 Mean Loss: 0.6912887766957283\n",
            "Value 1081 Mean Loss: 4.571927219629288\n",
            "dones: tensor(24.)\n",
            "Policy 1082 Mean Loss: -0.002409899316262454\n",
            "Entropy 1082 Mean Loss: 0.6911313161253929\n",
            "Value 1082 Mean Loss: 4.365153759717941\n",
            "dones: tensor(22.)\n",
            "Policy 1083 Mean Loss: -0.003527626977302134\n",
            "Entropy 1083 Mean Loss: 0.6908713802695274\n",
            "Value 1083 Mean Loss: 4.55519013106823\n",
            "dones: tensor(22.)\n",
            "Policy 1084 Mean Loss: -0.005090121820103377\n",
            "Entropy 1084 Mean Loss: 0.6907628625631332\n",
            "Value 1084 Mean Loss: 4.1276839673519135\n",
            "dones: tensor(19.)\n",
            "Policy 1085 Mean Loss: -0.008899897569790483\n",
            "Entropy 1085 Mean Loss: 0.690628033131361\n",
            "Value 1085 Mean Loss: 4.241947993636131\n",
            "dones: tensor(22.)\n",
            "Policy 1086 Mean Loss: -0.006981341517530382\n",
            "Entropy 1086 Mean Loss: 0.6911473385989666\n",
            "Value 1086 Mean Loss: 4.486714154481888\n",
            "dones: tensor(23.)\n",
            "Policy 1087 Mean Loss: -0.0024643430369906127\n",
            "Entropy 1087 Mean Loss: 0.6911442577838898\n",
            "Value 1087 Mean Loss: 4.260794147849083\n",
            "dones: tensor(24.)\n",
            "Policy 1088 Mean Loss: -0.005412448197603226\n",
            "Entropy 1088 Mean Loss: 0.6912153400480747\n",
            "Value 1088 Mean Loss: 4.383049190044403\n",
            "dones: tensor(18.)\n",
            "Policy 1089 Mean Loss: -0.0025672463525552303\n",
            "Entropy 1089 Mean Loss: 0.6912394389510155\n",
            "Value 1089 Mean Loss: 4.496466279029846\n",
            "dones: tensor(21.)\n",
            "Policy 1090 Mean Loss: -0.005910904030315578\n",
            "Entropy 1090 Mean Loss: 0.6909205093979836\n",
            "Value 1090 Mean Loss: 4.070929944515228\n",
            "dones: tensor(22.)\n",
            "Policy 1091 Mean Loss: 0.0022117234184406698\n",
            "Entropy 1091 Mean Loss: 0.6909297965466976\n",
            "Value 1091 Mean Loss: 4.687780827283859\n",
            "dones: tensor(22.)\n",
            "Policy 1092 Mean Loss: -0.005484459223225713\n",
            "Entropy 1092 Mean Loss: 0.6910308711230755\n",
            "Value 1092 Mean Loss: 4.916538178920746\n",
            "dones: tensor(20.)\n",
            "Policy 1093 Mean Loss: -0.003291259810794145\n",
            "Entropy 1093 Mean Loss: 0.6907517164945602\n",
            "Value 1093 Mean Loss: 4.132033854722977\n",
            "dones: tensor(20.)\n",
            "Policy 1094 Mean Loss: -0.006529897276777774\n",
            "Entropy 1094 Mean Loss: 0.69051144272089\n",
            "Value 1094 Mean Loss: 4.856674462556839\n",
            "dones: tensor(26.)\n",
            "Policy 1095 Mean Loss: -0.005765688954852521\n",
            "Entropy 1095 Mean Loss: 0.6910294778645039\n",
            "Value 1095 Mean Loss: 5.007113397121429\n",
            "dones: tensor(23.)\n",
            "Policy 1096 Mean Loss: -0.0051128462655469775\n",
            "Entropy 1096 Mean Loss: 0.6905820891261101\n",
            "Value 1096 Mean Loss: 4.830961912870407\n",
            "dones: tensor(23.)\n",
            "Policy 1097 Mean Loss: -0.004835903353523463\n",
            "Entropy 1097 Mean Loss: 0.6906147040426731\n",
            "Value 1097 Mean Loss: 4.01225845515728\n",
            "dones: tensor(24.)\n",
            "Policy 1098 Mean Loss: -0.007824827800504863\n",
            "Entropy 1098 Mean Loss: 0.6907825209200382\n",
            "Value 1098 Mean Loss: 4.244571045041084\n",
            "dones: tensor(26.)\n",
            "Policy 1099 Mean Loss: -0.005201110034249723\n",
            "Entropy 1099 Mean Loss: 0.6908836737275124\n",
            "Value 1099 Mean Loss: 4.818291008472443\n",
            "dones: tensor(27.)\n",
            "Policy 1100 Mean Loss: -0.007165910326875746\n",
            "Entropy 1100 Mean Loss: 0.6908799856901169\n",
            "Value 1100 Mean Loss: 5.005478084087372\n",
            "dones: tensor(24.)\n",
            "Policy 1101 Mean Loss: -0.012133388314396143\n",
            "Entropy 1101 Mean Loss: 0.690415758639574\n",
            "Value 1101 Mean Loss: 4.432308539748192\n",
            "dones: tensor(13.)\n",
            "Policy 1102 Mean Loss: -0.006989094254095107\n",
            "Entropy 1102 Mean Loss: 0.6899450160562992\n",
            "Value 1102 Mean Loss: 8.01866015791893\n",
            "dones: tensor(25.)\n",
            "Policy 1103 Mean Loss: -0.011649255873635411\n",
            "Entropy 1103 Mean Loss: 0.690365232527256\n",
            "Value 1103 Mean Loss: 4.858477205038071\n",
            "dones: tensor(20.)\n",
            "Policy 1104 Mean Loss: -0.005095049156807363\n",
            "Entropy 1104 Mean Loss: 0.6898899525403976\n",
            "Value 1104 Mean Loss: 3.975643441081047\n",
            "dones: tensor(23.)\n",
            "Policy 1105 Mean Loss: -0.007295202405657619\n",
            "Entropy 1105 Mean Loss: 0.6903251931071281\n",
            "Value 1105 Mean Loss: 4.307244002819061\n",
            "dones: tensor(23.)\n",
            "Policy 1106 Mean Loss: -0.009623487072531134\n",
            "Entropy 1106 Mean Loss: 0.6903724148869514\n",
            "Value 1106 Mean Loss: 5.087822914123535\n",
            "dones: tensor(27.)\n",
            "Policy 1107 Mean Loss: -0.004483542230445892\n",
            "Entropy 1107 Mean Loss: 0.6908159032464027\n",
            "Value 1107 Mean Loss: 5.263243407011032\n",
            "dones: tensor(19.)\n",
            "Policy 1108 Mean Loss: -0.009207719936966896\n",
            "Entropy 1108 Mean Loss: 0.6902699843049049\n",
            "Value 1108 Mean Loss: 4.8342587649822235\n",
            "dones: tensor(24.)\n",
            "Policy 1109 Mean Loss: -0.004959844460245222\n",
            "Entropy 1109 Mean Loss: 0.6907874643802643\n",
            "Value 1109 Mean Loss: 4.489250048995018\n",
            "dones: tensor(22.)\n",
            "Policy 1110 Mean Loss: -0.007978283218108118\n",
            "Entropy 1110 Mean Loss: 0.690771896392107\n",
            "Value 1110 Mean Loss: 4.5797838270664215\n",
            "dones: tensor(20.)\n",
            "Policy 1111 Mean Loss: -0.006631176162045449\n",
            "Entropy 1111 Mean Loss: 0.690743513405323\n",
            "Value 1111 Mean Loss: 4.290965244174004\n",
            "dones: tensor(21.)\n",
            "Policy 1112 Mean Loss: -0.011350586137268692\n",
            "Entropy 1112 Mean Loss: 0.6904829517006874\n",
            "Value 1112 Mean Loss: 4.318889737129211\n",
            "dones: tensor(22.)\n",
            "Policy 1113 Mean Loss: -0.007594673428684473\n",
            "Entropy 1113 Mean Loss: 0.6906446106731892\n",
            "Value 1113 Mean Loss: 4.724144950509071\n",
            "dones: tensor(23.)\n",
            "Policy 1114 Mean Loss: -0.004104629217181355\n",
            "Entropy 1114 Mean Loss: 0.6910353042185307\n",
            "Value 1114 Mean Loss: 4.659631997346878\n",
            "dones: tensor(23.)\n",
            "Policy 1115 Mean Loss: -0.0049032276147045195\n",
            "Entropy 1115 Mean Loss: 0.6908429190516472\n",
            "Value 1115 Mean Loss: 4.330044001340866\n",
            "dones: tensor(25.)\n",
            "Policy 1116 Mean Loss: -0.004991703433915973\n",
            "Entropy 1116 Mean Loss: 0.6909091658890247\n",
            "Value 1116 Mean Loss: 4.86605042219162\n",
            "dones: tensor(20.)\n",
            "Policy 1117 Mean Loss: -0.009532348543871194\n",
            "Entropy 1117 Mean Loss: 0.6906454712152481\n",
            "Value 1117 Mean Loss: 4.52906833589077\n",
            "dones: tensor(23.)\n",
            "Policy 1118 Mean Loss: -0.01163066050503403\n",
            "Entropy 1118 Mean Loss: 0.6908973827958107\n",
            "Value 1118 Mean Loss: 4.5912957191467285\n",
            "dones: tensor(21.)\n",
            "Policy 1119 Mean Loss: -0.007035739836283028\n",
            "Entropy 1119 Mean Loss: 0.6912529356777668\n",
            "Value 1119 Mean Loss: 4.402872622013092\n",
            "dones: tensor(26.)\n",
            "Policy 1120 Mean Loss: -0.006718271179124713\n",
            "Entropy 1120 Mean Loss: 0.6913037896156311\n",
            "Value 1120 Mean Loss: 4.914443254470825\n",
            "dones: tensor(23.)\n",
            "Policy 1121 Mean Loss: -0.007852367620216683\n",
            "Entropy 1121 Mean Loss: 0.6911328323185444\n",
            "Value 1121 Mean Loss: 4.680091753602028\n",
            "dones: tensor(24.)\n",
            "Policy 1122 Mean Loss: -0.007845698622986674\n",
            "Entropy 1122 Mean Loss: 0.6910807490348816\n",
            "Value 1122 Mean Loss: 4.464759111404419\n",
            "dones: tensor(21.)\n",
            "Policy 1123 Mean Loss: -0.0071298168040812016\n",
            "Entropy 1123 Mean Loss: 0.6906978897750378\n",
            "Value 1123 Mean Loss: 5.119902700185776\n",
            "dones: tensor(23.)\n",
            "Policy 1124 Mean Loss: -0.007055050111375749\n",
            "Entropy 1124 Mean Loss: 0.6909416913986206\n",
            "Value 1124 Mean Loss: 4.687947481870651\n",
            "dones: tensor(26.)\n",
            "Policy 1125 Mean Loss: -0.005472764954902232\n",
            "Entropy 1125 Mean Loss: 0.6904929131269455\n",
            "Value 1125 Mean Loss: 5.117221266031265\n",
            "dones: tensor(19.)\n",
            "Policy 1126 Mean Loss: -0.0029389444971457124\n",
            "Entropy 1126 Mean Loss: 0.690265703946352\n",
            "Value 1126 Mean Loss: 4.680671647191048\n",
            "dones: tensor(22.)\n",
            "Policy 1127 Mean Loss: -0.011499372718390077\n",
            "Entropy 1127 Mean Loss: 0.690143994987011\n",
            "Value 1127 Mean Loss: 4.9132447093725204\n",
            "dones: tensor(21.)\n",
            "Policy 1128 Mean Loss: -0.0114313053782098\n",
            "Entropy 1128 Mean Loss: 0.690350379794836\n",
            "Value 1128 Mean Loss: 4.508729964494705\n",
            "dones: tensor(19.)\n",
            "Policy 1129 Mean Loss: -0.00578735675662756\n",
            "Entropy 1129 Mean Loss: 0.6904515698552132\n",
            "Value 1129 Mean Loss: 4.954311728477478\n",
            "dones: tensor(17.)\n",
            "Policy 1130 Mean Loss: -0.0029922155663371086\n",
            "Entropy 1130 Mean Loss: 0.6905612275004387\n",
            "Value 1130 Mean Loss: 4.317907854914665\n",
            "dones: tensor(23.)\n",
            "Policy 1131 Mean Loss: -0.007123316405341029\n",
            "Entropy 1131 Mean Loss: 0.6907351016998291\n",
            "Value 1131 Mean Loss: 4.7370535135269165\n",
            "dones: tensor(24.)\n",
            "Policy 1132 Mean Loss: -0.009124234842602164\n",
            "Entropy 1132 Mean Loss: 0.690929964184761\n",
            "Value 1132 Mean Loss: 5.215926140546799\n",
            "dones: tensor(25.)\n",
            "Policy 1133 Mean Loss: -0.00797502271598205\n",
            "Entropy 1133 Mean Loss: 0.6909923776984215\n",
            "Value 1133 Mean Loss: 4.275071948766708\n",
            "dones: tensor(21.)\n",
            "Policy 1134 Mean Loss: -0.008374947705306113\n",
            "Entropy 1134 Mean Loss: 0.6907496117055416\n",
            "Value 1134 Mean Loss: 4.982936292886734\n",
            "dones: tensor(21.)\n",
            "Policy 1135 Mean Loss: -0.008807320846244693\n",
            "Entropy 1135 Mean Loss: 0.6909114941954613\n",
            "Value 1135 Mean Loss: 4.660528242588043\n",
            "dones: tensor(23.)\n",
            "Policy 1136 Mean Loss: -0.004975612973794341\n",
            "Entropy 1136 Mean Loss: 0.6907729208469391\n",
            "Value 1136 Mean Loss: 4.924953520298004\n",
            "dones: tensor(18.)\n",
            "Policy 1137 Mean Loss: -0.007924699690192938\n",
            "Entropy 1137 Mean Loss: 0.6906358748674393\n",
            "Value 1137 Mean Loss: 4.431521832942963\n",
            "dones: tensor(23.)\n",
            "Policy 1138 Mean Loss: -0.01172828790731728\n",
            "Entropy 1138 Mean Loss: 0.6903846114873886\n",
            "Value 1138 Mean Loss: 4.580446407198906\n",
            "dones: tensor(21.)\n",
            "Policy 1139 Mean Loss: -0.004707401851192117\n",
            "Entropy 1139 Mean Loss: 0.6905921511352062\n",
            "Value 1139 Mean Loss: 4.357412740588188\n",
            "dones: tensor(22.)\n",
            "Policy 1140 Mean Loss: -0.004926903580781072\n",
            "Entropy 1140 Mean Loss: 0.6908821277320385\n",
            "Value 1140 Mean Loss: 4.682765960693359\n",
            "dones: tensor(18.)\n",
            "Policy 1141 Mean Loss: -0.0062280334532260895\n",
            "Entropy 1141 Mean Loss: 0.6909857466816902\n",
            "Value 1141 Mean Loss: 4.199469432234764\n",
            "dones: tensor(20.)\n",
            "Policy 1142 Mean Loss: -0.00848055025562644\n",
            "Entropy 1142 Mean Loss: 0.6908872984349728\n",
            "Value 1142 Mean Loss: 4.065767467021942\n",
            "dones: tensor(22.)\n",
            "Policy 1143 Mean Loss: -0.007372272608336061\n",
            "Entropy 1143 Mean Loss: 0.6907611787319183\n",
            "Value 1143 Mean Loss: 4.3068894892930984\n",
            "dones: tensor(24.)\n",
            "Policy 1144 Mean Loss: -0.005116673011798412\n",
            "Entropy 1144 Mean Loss: 0.690601259469986\n",
            "Value 1144 Mean Loss: 4.537903234362602\n",
            "dones: tensor(21.)\n",
            "Policy 1145 Mean Loss: -0.002526373486034572\n",
            "Entropy 1145 Mean Loss: 0.6900750249624252\n",
            "Value 1145 Mean Loss: 4.410385727882385\n",
            "dones: tensor(21.)\n",
            "Policy 1146 Mean Loss: -0.008976505836471915\n",
            "Entropy 1146 Mean Loss: 0.6899730898439884\n",
            "Value 1146 Mean Loss: 4.702045902609825\n",
            "dones: tensor(25.)\n",
            "Policy 1147 Mean Loss: -0.009404353389982134\n",
            "Entropy 1147 Mean Loss: 0.690218485891819\n",
            "Value 1147 Mean Loss: 4.845216542482376\n",
            "dones: tensor(23.)\n",
            "Policy 1148 Mean Loss: -0.006160827178973705\n",
            "Entropy 1148 Mean Loss: 0.6907860636711121\n",
            "Value 1148 Mean Loss: 4.656864732503891\n",
            "dones: tensor(18.)\n",
            "Policy 1149 Mean Loss: -0.01306055556051433\n",
            "Entropy 1149 Mean Loss: 0.6900945752859116\n",
            "Value 1149 Mean Loss: 4.937684118747711\n",
            "dones: tensor(25.)\n",
            "Policy 1150 Mean Loss: -0.010109741473570466\n",
            "Entropy 1150 Mean Loss: 0.690481636673212\n",
            "Value 1150 Mean Loss: 4.45744526386261\n",
            "dones: tensor(27.)\n",
            "Policy 1151 Mean Loss: -0.004313776385970414\n",
            "Entropy 1151 Mean Loss: 0.6909925043582916\n",
            "Value 1151 Mean Loss: 4.6129129230976105\n",
            "dones: tensor(22.)\n",
            "Policy 1152 Mean Loss: -0.010905457573244348\n",
            "Entropy 1152 Mean Loss: 0.6905906796455383\n",
            "Value 1152 Mean Loss: 4.371209561824799\n",
            "dones: tensor(22.)\n",
            "Policy 1153 Mean Loss: -0.005889310559723526\n",
            "Entropy 1153 Mean Loss: 0.6909372471272945\n",
            "Value 1153 Mean Loss: 4.331333935260773\n",
            "dones: tensor(25.)\n",
            "Policy 1154 Mean Loss: -0.00854325806722045\n",
            "Entropy 1154 Mean Loss: 0.6909711770713329\n",
            "Value 1154 Mean Loss: 4.672526985406876\n",
            "dones: tensor(24.)\n",
            "Policy 1155 Mean Loss: -0.007887142361141741\n",
            "Entropy 1155 Mean Loss: 0.6911444030702114\n",
            "Value 1155 Mean Loss: 5.147108793258667\n",
            "dones: tensor(27.)\n",
            "Policy 1156 Mean Loss: -0.009079985436983407\n",
            "Entropy 1156 Mean Loss: 0.6912047639489174\n",
            "Value 1156 Mean Loss: 5.536745846271515\n",
            "dones: tensor(23.)\n",
            "Policy 1157 Mean Loss: -0.0005079491529613733\n",
            "Entropy 1157 Mean Loss: 0.6912027485668659\n",
            "Value 1157 Mean Loss: 4.286533504724503\n",
            "dones: tensor(24.)\n",
            "Policy 1158 Mean Loss: -0.007451525947544724\n",
            "Entropy 1158 Mean Loss: 0.6913734972476959\n",
            "Value 1158 Mean Loss: 4.542969048023224\n",
            "dones: tensor(22.)\n",
            "Policy 1159 Mean Loss: -0.00805254525039345\n",
            "Entropy 1159 Mean Loss: 0.6908707357943058\n",
            "Value 1159 Mean Loss: 4.523386538028717\n",
            "dones: tensor(20.)\n",
            "Policy 1160 Mean Loss: -0.0049382211291231215\n",
            "Entropy 1160 Mean Loss: 0.6905405521392822\n",
            "Value 1160 Mean Loss: 4.488828927278519\n",
            "dones: tensor(26.)\n",
            "Policy 1161 Mean Loss: -0.008924092748202384\n",
            "Entropy 1161 Mean Loss: 0.6907243728637695\n",
            "Value 1161 Mean Loss: 5.046975553035736\n",
            "dones: tensor(27.)\n",
            "Policy 1162 Mean Loss: -0.010047302697785199\n",
            "Entropy 1162 Mean Loss: 0.6905834190547466\n",
            "Value 1162 Mean Loss: 4.779626131057739\n",
            "dones: tensor(20.)\n",
            "Policy 1163 Mean Loss: -0.0024915002286434174\n",
            "Entropy 1163 Mean Loss: 0.6903523318469524\n",
            "Value 1163 Mean Loss: 5.116575330495834\n",
            "dones: tensor(21.)\n",
            "Policy 1164 Mean Loss: -0.006131133413873613\n",
            "Entropy 1164 Mean Loss: 0.6908129341900349\n",
            "Value 1164 Mean Loss: 3.7197973430156708\n",
            "dones: tensor(24.)\n",
            "Policy 1165 Mean Loss: -0.003173608914949\n",
            "Entropy 1165 Mean Loss: 0.6911827251315117\n",
            "Value 1165 Mean Loss: 4.483922719955444\n",
            "dones: tensor(20.)\n",
            "Policy 1166 Mean Loss: -0.0045533934608101845\n",
            "Entropy 1166 Mean Loss: 0.6911488994956017\n",
            "Value 1166 Mean Loss: 4.393260225653648\n",
            "dones: tensor(20.)\n",
            "Policy 1167 Mean Loss: -0.0027673793956637383\n",
            "Entropy 1167 Mean Loss: 0.6910656616091728\n",
            "Value 1167 Mean Loss: 4.265355706214905\n",
            "dones: tensor(23.)\n",
            "Policy 1168 Mean Loss: -0.007687519479077309\n",
            "Entropy 1168 Mean Loss: 0.6909863017499447\n",
            "Value 1168 Mean Loss: 4.719310641288757\n",
            "dones: tensor(22.)\n",
            "Policy 1169 Mean Loss: -0.005781565501820296\n",
            "Entropy 1169 Mean Loss: 0.6911093853414059\n",
            "Value 1169 Mean Loss: 4.5385731011629105\n",
            "dones: tensor(21.)\n",
            "Policy 1170 Mean Loss: -0.007363701763097197\n",
            "Entropy 1170 Mean Loss: 0.6911183148622513\n",
            "Value 1170 Mean Loss: 4.5540797263383865\n",
            "dones: tensor(23.)\n",
            "Policy 1171 Mean Loss: -0.006552765378728509\n",
            "Entropy 1171 Mean Loss: 0.6909447386860847\n",
            "Value 1171 Mean Loss: 4.180829629302025\n",
            "dones: tensor(24.)\n",
            "Policy 1172 Mean Loss: -0.007267087348736823\n",
            "Entropy 1172 Mean Loss: 0.6908549554646015\n",
            "Value 1172 Mean Loss: 4.490114688873291\n",
            "dones: tensor(22.)\n",
            "Policy 1173 Mean Loss: -0.002586955961305648\n",
            "Entropy 1173 Mean Loss: 0.6907965913414955\n",
            "Value 1173 Mean Loss: 4.913734495639801\n",
            "dones: tensor(22.)\n",
            "Policy 1174 Mean Loss: -0.006996309093665332\n",
            "Entropy 1174 Mean Loss: 0.6907808184623718\n",
            "Value 1174 Mean Loss: 4.766846090555191\n",
            "dones: tensor(26.)\n",
            "Policy 1175 Mean Loss: -0.003940477385185659\n",
            "Entropy 1175 Mean Loss: 0.6908609941601753\n",
            "Value 1175 Mean Loss: 4.783469766378403\n",
            "dones: tensor(20.)\n",
            "Policy 1176 Mean Loss: -0.008236616500653327\n",
            "Entropy 1176 Mean Loss: 0.690346498042345\n",
            "Value 1176 Mean Loss: 4.721117675304413\n",
            "dones: tensor(23.)\n",
            "Policy 1177 Mean Loss: -0.006199111347086728\n",
            "Entropy 1177 Mean Loss: 0.6904469802975655\n",
            "Value 1177 Mean Loss: 4.5979175716638565\n",
            "dones: tensor(28.)\n",
            "Policy 1178 Mean Loss: -0.00829346914542839\n",
            "Entropy 1178 Mean Loss: 0.6904844529926777\n",
            "Value 1178 Mean Loss: 5.535339117050171\n",
            "dones: tensor(27.)\n",
            "Policy 1179 Mean Loss: -0.005345866142306477\n",
            "Entropy 1179 Mean Loss: 0.6904255039989948\n",
            "Value 1179 Mean Loss: 5.020027533173561\n",
            "dones: tensor(21.)\n",
            "Policy 1180 Mean Loss: -0.006320948217762634\n",
            "Entropy 1180 Mean Loss: 0.6905305907130241\n",
            "Value 1180 Mean Loss: 5.0424031019210815\n",
            "dones: tensor(22.)\n",
            "Policy 1181 Mean Loss: -0.006230625323951244\n",
            "Entropy 1181 Mean Loss: 0.6909015960991383\n",
            "Value 1181 Mean Loss: 3.866335704922676\n",
            "dones: tensor(23.)\n",
            "Policy 1182 Mean Loss: -0.007509240065701306\n",
            "Entropy 1182 Mean Loss: 0.6909023374319077\n",
            "Value 1182 Mean Loss: 4.270280584692955\n",
            "dones: tensor(23.)\n",
            "Policy 1183 Mean Loss: -0.00811498868279159\n",
            "Entropy 1183 Mean Loss: 0.6914215423166752\n",
            "Value 1183 Mean Loss: 3.964111015200615\n",
            "dones: tensor(22.)\n",
            "Policy 1184 Mean Loss: -0.005299602227751166\n",
            "Entropy 1184 Mean Loss: 0.691082302480936\n",
            "Value 1184 Mean Loss: 4.40819576382637\n",
            "dones: tensor(20.)\n",
            "Policy 1185 Mean Loss: -0.0026595862000249326\n",
            "Entropy 1185 Mean Loss: 0.6911888346076012\n",
            "Value 1185 Mean Loss: 4.207165241241455\n",
            "dones: tensor(24.)\n",
            "Policy 1186 Mean Loss: -0.0030492612859234214\n",
            "Entropy 1186 Mean Loss: 0.6909998953342438\n",
            "Value 1186 Mean Loss: 4.0434098690748215\n",
            "dones: tensor(26.)\n",
            "Policy 1187 Mean Loss: -0.004520895308814943\n",
            "Entropy 1187 Mean Loss: 0.6910446099936962\n",
            "Value 1187 Mean Loss: 4.659641265869141\n",
            "dones: tensor(21.)\n",
            "Policy 1188 Mean Loss: -0.004971102316631004\n",
            "Entropy 1188 Mean Loss: 0.6908468380570412\n",
            "Value 1188 Mean Loss: 3.7418412417173386\n",
            "dones: tensor(24.)\n",
            "Policy 1189 Mean Loss: -0.009371451800689101\n",
            "Entropy 1189 Mean Loss: 0.6911247931420803\n",
            "Value 1189 Mean Loss: 4.317388594150543\n",
            "dones: tensor(24.)\n",
            "Policy 1190 Mean Loss: -0.007544477703049779\n",
            "Entropy 1190 Mean Loss: 0.6911468617618084\n",
            "Value 1190 Mean Loss: 4.608843341469765\n",
            "dones: tensor(23.)\n",
            "Policy 1191 Mean Loss: -0.006487094913609326\n",
            "Entropy 1191 Mean Loss: 0.6913258656859398\n",
            "Value 1191 Mean Loss: 4.008492067456245\n",
            "dones: tensor(22.)\n",
            "Policy 1192 Mean Loss: -0.004146439197938889\n",
            "Entropy 1192 Mean Loss: 0.6909021288156509\n",
            "Value 1192 Mean Loss: 4.403313234448433\n",
            "dones: tensor(21.)\n",
            "Policy 1193 Mean Loss: -0.0031460789614357054\n",
            "Entropy 1193 Mean Loss: 0.6907355561852455\n",
            "Value 1193 Mean Loss: 4.714603364467621\n",
            "dones: tensor(24.)\n",
            "Policy 1194 Mean Loss: -0.0030221809283830225\n",
            "Entropy 1194 Mean Loss: 0.6908826045691967\n",
            "Value 1194 Mean Loss: 4.020812943577766\n",
            "dones: tensor(23.)\n",
            "Policy 1195 Mean Loss: -0.004573691519908607\n",
            "Entropy 1195 Mean Loss: 0.6908211447298527\n",
            "Value 1195 Mean Loss: 4.757218807935715\n",
            "dones: tensor(26.)\n",
            "Policy 1196 Mean Loss: -0.005564267572481185\n",
            "Entropy 1196 Mean Loss: 0.6906394548714161\n",
            "Value 1196 Mean Loss: 4.898694455623627\n",
            "dones: tensor(25.)\n",
            "Policy 1197 Mean Loss: -0.006051898992154747\n",
            "Entropy 1197 Mean Loss: 0.6903949901461601\n",
            "Value 1197 Mean Loss: 4.402895703911781\n",
            "dones: tensor(20.)\n",
            "Policy 1198 Mean Loss: -0.00481622910592705\n",
            "Entropy 1198 Mean Loss: 0.6899902299046516\n",
            "Value 1198 Mean Loss: 4.419486790895462\n",
            "dones: tensor(23.)\n",
            "Policy 1199 Mean Loss: -0.011825687543023378\n",
            "Entropy 1199 Mean Loss: 0.6904171258211136\n",
            "Value 1199 Mean Loss: 4.2195709347724915\n",
            "dones: tensor(24.)\n",
            "Policy 1200 Mean Loss: -0.007211975869722664\n",
            "Entropy 1200 Mean Loss: 0.6905874609947205\n",
            "Value 1200 Mean Loss: 4.0121931582689285\n",
            "dones: tensor(19.)\n",
            "Policy 1201 Mean Loss: -0.002494259737432003\n",
            "Entropy 1201 Mean Loss: 0.6904496103525162\n",
            "Value 1201 Mean Loss: 4.512560218572617\n",
            "dones: tensor(26.)\n",
            "Policy 1202 Mean Loss: -0.00666421209461987\n",
            "Entropy 1202 Mean Loss: 0.6907556019723415\n",
            "Value 1202 Mean Loss: 4.727181449532509\n",
            "dones: tensor(22.)\n",
            "Policy 1203 Mean Loss: -0.003937136149033904\n",
            "Entropy 1203 Mean Loss: 0.6907289363443851\n",
            "Value 1203 Mean Loss: 3.7895446568727493\n",
            "dones: tensor(20.)\n",
            "Policy 1204 Mean Loss: -0.00378896965412423\n",
            "Entropy 1204 Mean Loss: 0.6907162852585316\n",
            "Value 1204 Mean Loss: 4.566910296678543\n",
            "dones: tensor(23.)\n",
            "Policy 1205 Mean Loss: -0.003928440710296854\n",
            "Entropy 1205 Mean Loss: 0.690774280577898\n",
            "Value 1205 Mean Loss: 4.303061246871948\n",
            "dones: tensor(23.)\n",
            "Policy 1206 Mean Loss: -0.005953646497800946\n",
            "Entropy 1206 Mean Loss: 0.6908610574901104\n",
            "Value 1206 Mean Loss: 4.250119552016258\n",
            "dones: tensor(19.)\n",
            "Policy 1207 Mean Loss: -0.005027042527217418\n",
            "Entropy 1207 Mean Loss: 0.6908736936748028\n",
            "Value 1207 Mean Loss: 5.062260389328003\n",
            "dones: tensor(24.)\n",
            "Policy 1208 Mean Loss: -0.006538533780258149\n",
            "Entropy 1208 Mean Loss: 0.6910368055105209\n",
            "Value 1208 Mean Loss: 4.702975124120712\n",
            "dones: tensor(21.)\n",
            "Policy 1209 Mean Loss: -0.0012555845896713436\n",
            "Entropy 1209 Mean Loss: 0.6911164820194244\n",
            "Value 1209 Mean Loss: 4.608287543058395\n",
            "dones: tensor(19.)\n",
            "Policy 1210 Mean Loss: -0.004540901049040258\n",
            "Entropy 1210 Mean Loss: 0.6908466443419456\n",
            "Value 1210 Mean Loss: 4.829038739204407\n",
            "dones: tensor(20.)\n",
            "Policy 1211 Mean Loss: -0.0024046021280810237\n",
            "Entropy 1211 Mean Loss: 0.6909177862107754\n",
            "Value 1211 Mean Loss: 4.047792300581932\n",
            "dones: tensor(21.)\n",
            "Policy 1212 Mean Loss: -0.006753666326403618\n",
            "Entropy 1212 Mean Loss: 0.691013727337122\n",
            "Value 1212 Mean Loss: 3.99765607714653\n",
            "dones: tensor(25.)\n",
            "Policy 1213 Mean Loss: -0.005824350519105792\n",
            "Entropy 1213 Mean Loss: 0.6910044103860855\n",
            "Value 1213 Mean Loss: 4.640484422445297\n",
            "dones: tensor(20.)\n",
            "Policy 1214 Mean Loss: -0.005473171593621373\n",
            "Entropy 1214 Mean Loss: 0.6909989975392818\n",
            "Value 1214 Mean Loss: 4.751854240894318\n",
            "dones: tensor(21.)\n",
            "Policy 1215 Mean Loss: -0.004186461213976145\n",
            "Entropy 1215 Mean Loss: 0.6906299702823162\n",
            "Value 1215 Mean Loss: 4.506812572479248\n",
            "dones: tensor(25.)\n",
            "Policy 1216 Mean Loss: -0.005363228032365441\n",
            "Entropy 1216 Mean Loss: 0.690444964915514\n",
            "Value 1216 Mean Loss: 4.58475786447525\n",
            "dones: tensor(21.)\n",
            "Policy 1217 Mean Loss: -0.0076011441415175796\n",
            "Entropy 1217 Mean Loss: 0.6904607862234116\n",
            "Value 1217 Mean Loss: 4.540332689881325\n",
            "dones: tensor(19.)\n",
            "Policy 1218 Mean Loss: -0.0057685429928824306\n",
            "Entropy 1218 Mean Loss: 0.6902268193662167\n",
            "Value 1218 Mean Loss: 3.6518624424934387\n",
            "dones: tensor(21.)\n",
            "Policy 1219 Mean Loss: -0.0021765126730315387\n",
            "Entropy 1219 Mean Loss: 0.6907935850322247\n",
            "Value 1219 Mean Loss: 4.415671616792679\n",
            "dones: tensor(27.)\n",
            "Policy 1220 Mean Loss: -0.005116417654789984\n",
            "Entropy 1220 Mean Loss: 0.6909234039485455\n",
            "Value 1220 Mean Loss: 5.174028158187866\n",
            "dones: tensor(26.)\n",
            "Policy 1221 Mean Loss: -0.011697207810357213\n",
            "Entropy 1221 Mean Loss: 0.6905215792357922\n",
            "Value 1221 Mean Loss: 4.518688425421715\n",
            "dones: tensor(24.)\n",
            "Policy 1222 Mean Loss: -0.012157903518527746\n",
            "Entropy 1222 Mean Loss: 0.6904483027756214\n",
            "Value 1222 Mean Loss: 4.255940347909927\n",
            "dones: tensor(19.)\n",
            "Policy 1223 Mean Loss: -0.0036747707636095583\n",
            "Entropy 1223 Mean Loss: 0.6904251426458359\n",
            "Value 1223 Mean Loss: 4.29206919670105\n",
            "dones: tensor(22.)\n",
            "Policy 1224 Mean Loss: -0.007083193515427411\n",
            "Entropy 1224 Mean Loss: 0.6904890239238739\n",
            "Value 1224 Mean Loss: 4.057530239224434\n",
            "dones: tensor(21.)\n",
            "Policy 1225 Mean Loss: -0.009343667363282293\n",
            "Entropy 1225 Mean Loss: 0.6901105158030987\n",
            "Value 1225 Mean Loss: 3.8093346655368805\n",
            "dones: tensor(29.)\n",
            "Policy 1226 Mean Loss: -0.007924767851363868\n",
            "Entropy 1226 Mean Loss: 0.690637543797493\n",
            "Value 1226 Mean Loss: 5.04471418261528\n",
            "dones: tensor(19.)\n",
            "Policy 1227 Mean Loss: -0.009600272285751998\n",
            "Entropy 1227 Mean Loss: 0.6901861913502216\n",
            "Value 1227 Mean Loss: 4.45788799226284\n",
            "dones: tensor(21.)\n",
            "Policy 1228 Mean Loss: -0.007102181203663349\n",
            "Entropy 1228 Mean Loss: 0.6900383345782757\n",
            "Value 1228 Mean Loss: 4.866083323955536\n",
            "dones: tensor(21.)\n",
            "Policy 1229 Mean Loss: -0.008291775709949434\n",
            "Entropy 1229 Mean Loss: 0.6898767352104187\n",
            "Value 1229 Mean Loss: 4.120834514498711\n",
            "dones: tensor(26.)\n",
            "Policy 1230 Mean Loss: -0.014927513082511723\n",
            "Entropy 1230 Mean Loss: 0.6900016739964485\n",
            "Value 1230 Mean Loss: 4.92022117972374\n",
            "dones: tensor(20.)\n",
            "Policy 1231 Mean Loss: -0.00502843561116606\n",
            "Entropy 1231 Mean Loss: 0.6901636682450771\n",
            "Value 1231 Mean Loss: 3.9516856372356415\n",
            "dones: tensor(21.)\n",
            "Policy 1232 Mean Loss: -0.0004452723078429699\n",
            "Entropy 1232 Mean Loss: 0.6902841664850712\n",
            "Value 1232 Mean Loss: 4.734241008758545\n",
            "dones: tensor(22.)\n",
            "Policy 1233 Mean Loss: -0.010482987912837416\n",
            "Entropy 1233 Mean Loss: 0.690562766045332\n",
            "Value 1233 Mean Loss: 4.254044860601425\n",
            "dones: tensor(23.)\n",
            "Policy 1234 Mean Loss: -0.010098961531184614\n",
            "Entropy 1234 Mean Loss: 0.690755270421505\n",
            "Value 1234 Mean Loss: 4.420307174324989\n",
            "dones: tensor(23.)\n",
            "Policy 1235 Mean Loss: -0.007379083661362529\n",
            "Entropy 1235 Mean Loss: 0.6910771019756794\n",
            "Value 1235 Mean Loss: 4.89597550034523\n",
            "dones: tensor(23.)\n",
            "Policy 1236 Mean Loss: -0.010935382801108062\n",
            "Entropy 1236 Mean Loss: 0.6906563006341457\n",
            "Value 1236 Mean Loss: 4.6468653082847595\n",
            "dones: tensor(25.)\n",
            "Policy 1237 Mean Loss: -0.005010155902709812\n",
            "Entropy 1237 Mean Loss: 0.6911018230021\n",
            "Value 1237 Mean Loss: 4.299247369170189\n",
            "dones: tensor(24.)\n",
            "Policy 1238 Mean Loss: -0.008882331778295338\n",
            "Entropy 1238 Mean Loss: 0.6910795271396637\n",
            "Value 1238 Mean Loss: 4.96713787317276\n",
            "dones: tensor(20.)\n",
            "Policy 1239 Mean Loss: -0.009715265070553869\n",
            "Entropy 1239 Mean Loss: 0.6905004009604454\n",
            "Value 1239 Mean Loss: 4.207824170589447\n",
            "dones: tensor(22.)\n",
            "Policy 1240 Mean Loss: -0.006596186140086502\n",
            "Entropy 1240 Mean Loss: 0.6907866299152374\n",
            "Value 1240 Mean Loss: 4.209717333316803\n",
            "dones: tensor(24.)\n",
            "Policy 1241 Mean Loss: -0.006984654755797237\n",
            "Entropy 1241 Mean Loss: 0.6910712458193302\n",
            "Value 1241 Mean Loss: 4.261879056692123\n",
            "dones: tensor(24.)\n",
            "Policy 1242 Mean Loss: -0.006185198726598173\n",
            "Entropy 1242 Mean Loss: 0.6910255998373032\n",
            "Value 1242 Mean Loss: 4.902624577283859\n",
            "dones: tensor(24.)\n",
            "Policy 1243 Mean Loss: -0.009187320771161467\n",
            "Entropy 1243 Mean Loss: 0.6907817386090755\n",
            "Value 1243 Mean Loss: 4.598210841417313\n",
            "dones: tensor(20.)\n",
            "Policy 1244 Mean Loss: -0.00611273804679513\n",
            "Entropy 1244 Mean Loss: 0.6908620297908783\n",
            "Value 1244 Mean Loss: 4.135500892996788\n",
            "dones: tensor(24.)\n",
            "Policy 1245 Mean Loss: -0.004308941133785993\n",
            "Entropy 1245 Mean Loss: 0.6913996934890747\n",
            "Value 1245 Mean Loss: 4.511306911706924\n",
            "dones: tensor(21.)\n",
            "Policy 1246 Mean Loss: -0.008534334192518145\n",
            "Entropy 1246 Mean Loss: 0.6908806934952736\n",
            "Value 1246 Mean Loss: 4.97574183344841\n",
            "dones: tensor(25.)\n",
            "Policy 1247 Mean Loss: -0.007216753496322781\n",
            "Entropy 1247 Mean Loss: 0.6909696273505688\n",
            "Value 1247 Mean Loss: 4.487344399094582\n",
            "dones: tensor(23.)\n",
            "Policy 1248 Mean Loss: -0.010463093814905733\n",
            "Entropy 1248 Mean Loss: 0.6907699853181839\n",
            "Value 1248 Mean Loss: 5.3924576342105865\n",
            "dones: tensor(25.)\n",
            "Policy 1249 Mean Loss: -0.011846314300782979\n",
            "Entropy 1249 Mean Loss: 0.6907876692712307\n",
            "Value 1249 Mean Loss: 4.678801387548447\n",
            "dones: tensor(25.)\n",
            "Policy 1250 Mean Loss: -0.006165595143102109\n",
            "Entropy 1250 Mean Loss: 0.6907921880483627\n",
            "Value 1250 Mean Loss: 5.3178724348545074\n",
            "dones: tensor(33.)\n",
            "Policy 1251 Mean Loss: -0.007112233259249479\n",
            "Entropy 1251 Mean Loss: 0.691243652254343\n",
            "Value 1251 Mean Loss: 5.787176042795181\n",
            "dones: tensor(19.)\n",
            "Policy 1252 Mean Loss: -0.01080757548334077\n",
            "Entropy 1252 Mean Loss: 0.6907235682010651\n",
            "Value 1252 Mean Loss: 4.205596357584\n",
            "dones: tensor(22.)\n",
            "Policy 1253 Mean Loss: -0.007706579257501289\n",
            "Entropy 1253 Mean Loss: 0.6905516535043716\n",
            "Value 1253 Mean Loss: 4.501232758164406\n",
            "dones: tensor(29.)\n",
            "Policy 1254 Mean Loss: -0.010954546392895281\n",
            "Entropy 1254 Mean Loss: 0.6907384917140007\n",
            "Value 1254 Mean Loss: 5.4638804495334625\n",
            "dones: tensor(24.)\n",
            "Policy 1255 Mean Loss: -0.009411410021129996\n",
            "Entropy 1255 Mean Loss: 0.6908656843006611\n",
            "Value 1255 Mean Loss: 4.6779763996601105\n",
            "dones: tensor(18.)\n",
            "Policy 1256 Mean Loss: -0.005051100859418511\n",
            "Entropy 1256 Mean Loss: 0.6905090846121311\n",
            "Value 1256 Mean Loss: 4.208076491951942\n",
            "dones: tensor(22.)\n",
            "Policy 1257 Mean Loss: -0.006167702958919108\n",
            "Entropy 1257 Mean Loss: 0.6907573416829109\n",
            "Value 1257 Mean Loss: 4.268152862787247\n",
            "dones: tensor(22.)\n",
            "Policy 1258 Mean Loss: -0.0020756005542352796\n",
            "Entropy 1258 Mean Loss: 0.6908502094447613\n",
            "Value 1258 Mean Loss: 4.345871403813362\n",
            "dones: tensor(25.)\n",
            "Policy 1259 Mean Loss: -0.007091167208272964\n",
            "Entropy 1259 Mean Loss: 0.690937340259552\n",
            "Value 1259 Mean Loss: 4.997803777456284\n",
            "dones: tensor(23.)\n",
            "Policy 1260 Mean Loss: -0.009462947607971728\n",
            "Entropy 1260 Mean Loss: 0.6908982172608376\n",
            "Value 1260 Mean Loss: 4.467899993062019\n",
            "dones: tensor(23.)\n",
            "Policy 1261 Mean Loss: -0.008013021491933614\n",
            "Entropy 1261 Mean Loss: 0.6907630376517773\n",
            "Value 1261 Mean Loss: 4.93024206161499\n",
            "dones: tensor(21.)\n",
            "Policy 1262 Mean Loss: -0.0043993135914206505\n",
            "Entropy 1262 Mean Loss: 0.6907053701579571\n",
            "Value 1262 Mean Loss: 4.228251039981842\n",
            "dones: tensor(23.)\n",
            "Policy 1263 Mean Loss: -0.006693190196529031\n",
            "Entropy 1263 Mean Loss: 0.6906517036259174\n",
            "Value 1263 Mean Loss: 4.601360470056534\n",
            "dones: tensor(20.)\n",
            "Policy 1264 Mean Loss: -0.000681169971358031\n",
            "Entropy 1264 Mean Loss: 0.6906737275421619\n",
            "Value 1264 Mean Loss: 4.597066223621368\n",
            "dones: tensor(24.)\n",
            "Policy 1265 Mean Loss: -0.008625998045317829\n",
            "Entropy 1265 Mean Loss: 0.6906339600682259\n",
            "Value 1265 Mean Loss: 4.832039564847946\n",
            "dones: tensor(24.)\n",
            "Policy 1266 Mean Loss: -0.007403776573482901\n",
            "Entropy 1266 Mean Loss: 0.6905204094946384\n",
            "Value 1266 Mean Loss: 4.383302003145218\n",
            "dones: tensor(22.)\n",
            "Policy 1267 Mean Loss: -0.0070056659751571715\n",
            "Entropy 1267 Mean Loss: 0.69073486328125\n",
            "Value 1267 Mean Loss: 4.9138378500938416\n",
            "dones: tensor(22.)\n",
            "Policy 1268 Mean Loss: -0.007308283413294703\n",
            "Entropy 1268 Mean Loss: 0.690796185284853\n",
            "Value 1268 Mean Loss: 4.370710968971252\n",
            "dones: tensor(20.)\n",
            "Policy 1269 Mean Loss: -0.002738812007009983\n",
            "Entropy 1269 Mean Loss: 0.6906359679996967\n",
            "Value 1269 Mean Loss: 5.152110278606415\n",
            "dones: tensor(22.)\n",
            "Policy 1270 Mean Loss: -0.00446247827494517\n",
            "Entropy 1270 Mean Loss: 0.6905971951782703\n",
            "Value 1270 Mean Loss: 4.028459474444389\n",
            "dones: tensor(22.)\n",
            "Policy 1271 Mean Loss: -0.010983351792674512\n",
            "Entropy 1271 Mean Loss: 0.6904679536819458\n",
            "Value 1271 Mean Loss: 4.568819731473923\n",
            "dones: tensor(24.)\n",
            "Policy 1272 Mean Loss: -0.004828266391996294\n",
            "Entropy 1272 Mean Loss: 0.6906917430460453\n",
            "Value 1272 Mean Loss: 4.4429289400577545\n",
            "dones: tensor(19.)\n",
            "Policy 1273 Mean Loss: -0.005372241605073214\n",
            "Entropy 1273 Mean Loss: 0.6908720321953297\n",
            "Value 1273 Mean Loss: 3.9720530956983566\n",
            "dones: tensor(22.)\n",
            "Policy 1274 Mean Loss: 0.0013602779363282025\n",
            "Entropy 1274 Mean Loss: 0.691098015755415\n",
            "Value 1274 Mean Loss: 5.219682663679123\n",
            "dones: tensor(18.)\n",
            "Policy 1275 Mean Loss: -0.00461824843659997\n",
            "Entropy 1275 Mean Loss: 0.6906670033931732\n",
            "Value 1275 Mean Loss: 4.116228103637695\n",
            "dones: tensor(20.)\n",
            "Policy 1276 Mean Loss: 0.001111453166231513\n",
            "Entropy 1276 Mean Loss: 0.6910226941108704\n",
            "Value 1276 Mean Loss: 4.329291447997093\n",
            "dones: tensor(21.)\n",
            "Policy 1277 Mean Loss: -0.007204355904832482\n",
            "Entropy 1277 Mean Loss: 0.6911405362188816\n",
            "Value 1277 Mean Loss: 4.293568015098572\n",
            "dones: tensor(22.)\n",
            "Policy 1278 Mean Loss: -0.0060237315483391285\n",
            "Entropy 1278 Mean Loss: 0.690929289907217\n",
            "Value 1278 Mean Loss: 4.768896698951721\n",
            "dones: tensor(24.)\n",
            "Policy 1279 Mean Loss: -0.004471260239370167\n",
            "Entropy 1279 Mean Loss: 0.6909577697515488\n",
            "Value 1279 Mean Loss: 5.320233553647995\n",
            "dones: tensor(20.)\n",
            "Policy 1280 Mean Loss: -0.008036677958443761\n",
            "Entropy 1280 Mean Loss: 0.6906365975737572\n",
            "Value 1280 Mean Loss: 4.275919511914253\n",
            "dones: tensor(23.)\n",
            "Policy 1281 Mean Loss: -0.0012004867894575\n",
            "Entropy 1281 Mean Loss: 0.6909899413585663\n",
            "Value 1281 Mean Loss: 4.67724534869194\n",
            "dones: tensor(20.)\n",
            "Policy 1282 Mean Loss: -0.005837861011968926\n",
            "Entropy 1282 Mean Loss: 0.6905034147202969\n",
            "Value 1282 Mean Loss: 4.333982408046722\n",
            "dones: tensor(20.)\n",
            "Policy 1283 Mean Loss: -0.006706122134346515\n",
            "Entropy 1283 Mean Loss: 0.6907283589243889\n",
            "Value 1283 Mean Loss: 4.003866299986839\n",
            "dones: tensor(18.)\n",
            "Policy 1284 Mean Loss: -0.005170367890968919\n",
            "Entropy 1284 Mean Loss: 0.6908013634383678\n",
            "Value 1284 Mean Loss: 4.323060154914856\n",
            "dones: tensor(23.)\n",
            "Policy 1285 Mean Loss: -0.002439201809465885\n",
            "Entropy 1285 Mean Loss: 0.6908720582723618\n",
            "Value 1285 Mean Loss: 4.5145261734724045\n",
            "dones: tensor(20.)\n",
            "Policy 1286 Mean Loss: -0.006992294976953417\n",
            "Entropy 1286 Mean Loss: 0.6909551732242107\n",
            "Value 1286 Mean Loss: 4.185927242040634\n",
            "dones: tensor(23.)\n",
            "Policy 1287 Mean Loss: -0.0025539405760355294\n",
            "Entropy 1287 Mean Loss: 0.6911213621497154\n",
            "Value 1287 Mean Loss: 4.298051029443741\n",
            "dones: tensor(21.)\n",
            "Policy 1288 Mean Loss: -0.00967595656402409\n",
            "Entropy 1288 Mean Loss: 0.6908287703990936\n",
            "Value 1288 Mean Loss: 4.43896096944809\n",
            "dones: tensor(19.)\n",
            "Policy 1289 Mean Loss: -0.0015983308549039066\n",
            "Entropy 1289 Mean Loss: 0.6904889643192291\n",
            "Value 1289 Mean Loss: 4.635244995355606\n",
            "dones: tensor(20.)\n",
            "Policy 1290 Mean Loss: -0.003588001651223749\n",
            "Entropy 1290 Mean Loss: 0.690545529127121\n",
            "Value 1290 Mean Loss: 4.227826029062271\n",
            "dones: tensor(20.)\n",
            "Policy 1291 Mean Loss: -0.004097418626770377\n",
            "Entropy 1291 Mean Loss: 0.6903285980224609\n",
            "Value 1291 Mean Loss: 4.518565446138382\n",
            "dones: tensor(28.)\n",
            "Policy 1292 Mean Loss: -0.006708146363962442\n",
            "Entropy 1292 Mean Loss: 0.6906682141125202\n",
            "Value 1292 Mean Loss: 5.335666060447693\n",
            "dones: tensor(25.)\n",
            "Policy 1293 Mean Loss: -0.006673114199656993\n",
            "Entropy 1293 Mean Loss: 0.6905843801796436\n",
            "Value 1293 Mean Loss: 4.817705035209656\n",
            "dones: tensor(25.)\n",
            "Policy 1294 Mean Loss: -0.005794646276626736\n",
            "Entropy 1294 Mean Loss: 0.6905119009315968\n",
            "Value 1294 Mean Loss: 4.524437993764877\n",
            "dones: tensor(21.)\n",
            "Policy 1295 Mean Loss: -0.010190986329689622\n",
            "Entropy 1295 Mean Loss: 0.6903597377240658\n",
            "Value 1295 Mean Loss: 4.3024692833423615\n",
            "dones: tensor(21.)\n",
            "Policy 1296 Mean Loss: -0.0065728764166124165\n",
            "Entropy 1296 Mean Loss: 0.6908791698515415\n",
            "Value 1296 Mean Loss: 4.353970557451248\n",
            "dones: tensor(22.)\n",
            "Policy 1297 Mean Loss: -0.006438807584345341\n",
            "Entropy 1297 Mean Loss: 0.6911167241632938\n",
            "Value 1297 Mean Loss: 4.740335464477539\n",
            "dones: tensor(23.)\n",
            "Policy 1298 Mean Loss: -0.0012662092340178788\n",
            "Entropy 1298 Mean Loss: 0.6911155544221401\n",
            "Value 1298 Mean Loss: 4.458440363407135\n",
            "dones: tensor(27.)\n",
            "Policy 1299 Mean Loss: -0.004427347448654473\n",
            "Entropy 1299 Mean Loss: 0.6913942322134972\n",
            "Value 1299 Mean Loss: 4.641220152378082\n",
            "dones: tensor(22.)\n",
            "Policy 1300 Mean Loss: -0.006297126295976341\n",
            "Entropy 1300 Mean Loss: 0.691252339631319\n",
            "Value 1300 Mean Loss: 4.638557106256485\n",
            "dones: tensor(24.)\n",
            "Policy 1301 Mean Loss: -0.005013289337512106\n",
            "Entropy 1301 Mean Loss: 0.6910956837236881\n",
            "Value 1301 Mean Loss: 4.271704152226448\n",
            "dones: tensor(23.)\n",
            "Policy 1302 Mean Loss: -0.010321123991161585\n",
            "Entropy 1302 Mean Loss: 0.6910331211984158\n",
            "Value 1302 Mean Loss: 5.008560627698898\n",
            "dones: tensor(25.)\n",
            "Policy 1303 Mean Loss: -0.0054026065627112985\n",
            "Entropy 1303 Mean Loss: 0.6911362670361996\n",
            "Value 1303 Mean Loss: 4.316683992743492\n",
            "dones: tensor(22.)\n",
            "Policy 1304 Mean Loss: -0.008738674921914935\n",
            "Entropy 1304 Mean Loss: 0.6909405663609505\n",
            "Value 1304 Mean Loss: 4.345111131668091\n",
            "dones: tensor(24.)\n",
            "Policy 1305 Mean Loss: -0.0036196460714563727\n",
            "Entropy 1305 Mean Loss: 0.6911808326840401\n",
            "Value 1305 Mean Loss: 4.381769552826881\n",
            "dones: tensor(26.)\n",
            "Policy 1306 Mean Loss: -0.009441110480111092\n",
            "Entropy 1306 Mean Loss: 0.6909937299787998\n",
            "Value 1306 Mean Loss: 4.551392108201981\n",
            "dones: tensor(25.)\n",
            "Policy 1307 Mean Loss: -0.003456595411989838\n",
            "Entropy 1307 Mean Loss: 0.6911250911653042\n",
            "Value 1307 Mean Loss: 4.913065969944\n",
            "dones: tensor(22.)\n",
            "Policy 1308 Mean Loss: -0.006555842119269073\n",
            "Entropy 1308 Mean Loss: 0.690666701644659\n",
            "Value 1308 Mean Loss: 4.012224584817886\n",
            "dones: tensor(24.)\n",
            "Policy 1309 Mean Loss: -0.0072889773291535676\n",
            "Entropy 1309 Mean Loss: 0.6909668110311031\n",
            "Value 1309 Mean Loss: 4.709239065647125\n",
            "dones: tensor(26.)\n",
            "Policy 1310 Mean Loss: -0.007172260171500966\n",
            "Entropy 1310 Mean Loss: 0.690874733030796\n",
            "Value 1310 Mean Loss: 4.301868811249733\n",
            "dones: tensor(21.)\n",
            "Policy 1311 Mean Loss: -0.00612600427120924\n",
            "Entropy 1311 Mean Loss: 0.691011093556881\n",
            "Value 1311 Mean Loss: 4.258683696389198\n",
            "dones: tensor(25.)\n",
            "Policy 1312 Mean Loss: -0.006825885677244514\n",
            "Entropy 1312 Mean Loss: 0.6909906342625618\n",
            "Value 1312 Mean Loss: 4.356312617659569\n",
            "dones: tensor(23.)\n",
            "Policy 1313 Mean Loss: -0.010675429832190275\n",
            "Entropy 1313 Mean Loss: 0.6906269229948521\n",
            "Value 1313 Mean Loss: 4.310406714677811\n",
            "dones: tensor(21.)\n",
            "Policy 1314 Mean Loss: -0.007849679386708885\n",
            "Entropy 1314 Mean Loss: 0.6906475201249123\n",
            "Value 1314 Mean Loss: 4.26425439119339\n",
            "dones: tensor(24.)\n",
            "Policy 1315 Mean Loss: -0.0026975456858053803\n",
            "Entropy 1315 Mean Loss: 0.6906504593789577\n",
            "Value 1315 Mean Loss: 4.350062429904938\n",
            "dones: tensor(25.)\n",
            "Policy 1316 Mean Loss: -0.008476775954477489\n",
            "Entropy 1316 Mean Loss: 0.6906808689236641\n",
            "Value 1316 Mean Loss: 4.694379240274429\n",
            "dones: tensor(20.)\n",
            "Policy 1317 Mean Loss: -0.008939391816966236\n",
            "Entropy 1317 Mean Loss: 0.6906913183629513\n",
            "Value 1317 Mean Loss: 3.433534324169159\n",
            "dones: tensor(18.)\n",
            "Policy 1318 Mean Loss: -0.0055883011082187295\n",
            "Entropy 1318 Mean Loss: 0.690792091190815\n",
            "Value 1318 Mean Loss: 4.285478293895721\n",
            "dones: tensor(22.)\n",
            "Policy 1319 Mean Loss: -0.008583305694628507\n",
            "Entropy 1319 Mean Loss: 0.6907760314643383\n",
            "Value 1319 Mean Loss: 4.455110028386116\n",
            "dones: tensor(21.)\n",
            "Policy 1320 Mean Loss: -0.007296595722436905\n",
            "Entropy 1320 Mean Loss: 0.6908146925270557\n",
            "Value 1320 Mean Loss: 4.816486105322838\n",
            "dones: tensor(22.)\n",
            "Policy 1321 Mean Loss: -0.003323054115753621\n",
            "Entropy 1321 Mean Loss: 0.6909067928791046\n",
            "Value 1321 Mean Loss: 4.535210192203522\n",
            "dones: tensor(22.)\n",
            "Policy 1322 Mean Loss: -0.002902962500229478\n",
            "Entropy 1322 Mean Loss: 0.6907777115702629\n",
            "Value 1322 Mean Loss: 4.564320906996727\n",
            "dones: tensor(21.)\n",
            "Policy 1323 Mean Loss: -0.010142752900719643\n",
            "Entropy 1323 Mean Loss: 0.6905268654227257\n",
            "Value 1323 Mean Loss: 4.513586789369583\n",
            "dones: tensor(21.)\n",
            "Policy 1324 Mean Loss: -0.009369308623718098\n",
            "Entropy 1324 Mean Loss: 0.690628781914711\n",
            "Value 1324 Mean Loss: 4.1420188546180725\n",
            "dones: tensor(23.)\n",
            "Policy 1325 Mean Loss: -0.011690295592416078\n",
            "Entropy 1325 Mean Loss: 0.6903301067650318\n",
            "Value 1325 Mean Loss: 4.4624824821949005\n",
            "dones: tensor(30.)\n",
            "Policy 1326 Mean Loss: -0.011112595966551453\n",
            "Entropy 1326 Mean Loss: 0.6901652850210667\n",
            "Value 1326 Mean Loss: 5.669309169054031\n",
            "dones: tensor(28.)\n",
            "Policy 1327 Mean Loss: -0.007138706627301872\n",
            "Entropy 1327 Mean Loss: 0.6902824975550175\n",
            "Value 1327 Mean Loss: 4.615341410040855\n",
            "dones: tensor(27.)\n",
            "Policy 1328 Mean Loss: -0.008750059932935983\n",
            "Entropy 1328 Mean Loss: 0.6903119422495365\n",
            "Value 1328 Mean Loss: 4.368165597319603\n",
            "dones: tensor(22.)\n",
            "Policy 1329 Mean Loss: -0.007517381221987307\n",
            "Entropy 1329 Mean Loss: 0.6902791261672974\n",
            "Value 1329 Mean Loss: 4.057913720607758\n",
            "dones: tensor(22.)\n",
            "Policy 1330 Mean Loss: -0.012298970017582178\n",
            "Entropy 1330 Mean Loss: 0.6903543472290039\n",
            "Value 1330 Mean Loss: 4.456563100218773\n",
            "dones: tensor(23.)\n",
            "Policy 1331 Mean Loss: -0.007757650688290596\n",
            "Entropy 1331 Mean Loss: 0.6907798908650875\n",
            "Value 1331 Mean Loss: 4.1317333579063416\n",
            "dones: tensor(24.)\n",
            "Policy 1332 Mean Loss: -0.00620370457181707\n",
            "Entropy 1332 Mean Loss: 0.6908166296780109\n",
            "Value 1332 Mean Loss: 4.570540323853493\n",
            "dones: tensor(19.)\n",
            "Policy 1333 Mean Loss: -0.008121384715195745\n",
            "Entropy 1333 Mean Loss: 0.6905100904405117\n",
            "Value 1333 Mean Loss: 4.064063414931297\n",
            "dones: tensor(21.)\n",
            "Policy 1334 Mean Loss: -0.008722216705791652\n",
            "Entropy 1334 Mean Loss: 0.6905501075088978\n",
            "Value 1334 Mean Loss: 4.9575477838516235\n",
            "dones: tensor(22.)\n",
            "Policy 1335 Mean Loss: -0.009076201444258913\n",
            "Entropy 1335 Mean Loss: 0.6908419132232666\n",
            "Value 1335 Mean Loss: 3.9485674500465393\n",
            "dones: tensor(24.)\n",
            "Policy 1336 Mean Loss: -0.0041375309228897095\n",
            "Entropy 1336 Mean Loss: 0.6910928376019001\n",
            "Value 1336 Mean Loss: 4.264916732907295\n",
            "dones: tensor(22.)\n",
            "Policy 1337 Mean Loss: -0.0071414419217035174\n",
            "Entropy 1337 Mean Loss: 0.6909363344311714\n",
            "Value 1337 Mean Loss: 3.9594725966453552\n",
            "dones: tensor(25.)\n",
            "Policy 1338 Mean Loss: -0.005284248560201377\n",
            "Entropy 1338 Mean Loss: 0.6908759772777557\n",
            "Value 1338 Mean Loss: 4.759938567876816\n",
            "dones: tensor(22.)\n",
            "Policy 1339 Mean Loss: -0.005147420975845307\n",
            "Entropy 1339 Mean Loss: 0.6909540258347988\n",
            "Value 1339 Mean Loss: 4.775927782058716\n",
            "dones: tensor(19.)\n",
            "Policy 1340 Mean Loss: -0.009221903106663376\n",
            "Entropy 1340 Mean Loss: 0.6906466074287891\n",
            "Value 1340 Mean Loss: 3.990646556019783\n",
            "dones: tensor(22.)\n",
            "Policy 1341 Mean Loss: -0.0012675407051574439\n",
            "Entropy 1341 Mean Loss: 0.6907104998826981\n",
            "Value 1341 Mean Loss: 4.3671265840530396\n",
            "dones: tensor(22.)\n",
            "Policy 1342 Mean Loss: -0.006059294944861904\n",
            "Entropy 1342 Mean Loss: 0.6909128576517105\n",
            "Value 1342 Mean Loss: 4.246692776679993\n",
            "dones: tensor(24.)\n",
            "Policy 1343 Mean Loss: -0.002539347915444523\n",
            "Entropy 1343 Mean Loss: 0.6910193152725697\n",
            "Value 1343 Mean Loss: 4.885014533996582\n",
            "dones: tensor(18.)\n",
            "Policy 1344 Mean Loss: -0.006931722164154053\n",
            "Entropy 1344 Mean Loss: 0.690935879945755\n",
            "Value 1344 Mean Loss: 4.4517014771699905\n",
            "dones: tensor(23.)\n",
            "Policy 1345 Mean Loss: -0.004684556974098086\n",
            "Entropy 1345 Mean Loss: 0.6910727620124817\n",
            "Value 1345 Mean Loss: 4.618109703063965\n",
            "dones: tensor(23.)\n",
            "Policy 1346 Mean Loss: -0.007369037426542491\n",
            "Entropy 1346 Mean Loss: 0.6909496709704399\n",
            "Value 1346 Mean Loss: 4.51706400513649\n",
            "dones: tensor(23.)\n",
            "Policy 1347 Mean Loss: -0.0038607519236393273\n",
            "Entropy 1347 Mean Loss: 0.6910162530839443\n",
            "Value 1347 Mean Loss: 4.687185391783714\n",
            "dones: tensor(23.)\n",
            "Policy 1348 Mean Loss: -0.00969391135731712\n",
            "Entropy 1348 Mean Loss: 0.6908621452748775\n",
            "Value 1348 Mean Loss: 4.301215440034866\n",
            "dones: tensor(24.)\n",
            "Policy 1349 Mean Loss: -0.006837210210505873\n",
            "Entropy 1349 Mean Loss: 0.6909754313528538\n",
            "Value 1349 Mean Loss: 4.406937435269356\n",
            "dones: tensor(28.)\n",
            "Policy 1350 Mean Loss: -0.009606150444597006\n",
            "Entropy 1350 Mean Loss: 0.6911928951740265\n",
            "Value 1350 Mean Loss: 4.800663441419601\n",
            "dones: tensor(19.)\n",
            "Policy 1351 Mean Loss: -0.006218704453203827\n",
            "Entropy 1351 Mean Loss: 0.6906602680683136\n",
            "Value 1351 Mean Loss: 4.056403800845146\n",
            "dones: tensor(26.)\n",
            "Policy 1352 Mean Loss: -0.009072921238839626\n",
            "Entropy 1352 Mean Loss: 0.6905218437314034\n",
            "Value 1352 Mean Loss: 4.874662339687347\n",
            "dones: tensor(19.)\n",
            "Policy 1353 Mean Loss: -0.014748332556337118\n",
            "Entropy 1353 Mean Loss: 0.6900659613311291\n",
            "Value 1353 Mean Loss: 4.152764797210693\n",
            "dones: tensor(21.)\n",
            "Policy 1354 Mean Loss: -0.009559336001984775\n",
            "Entropy 1354 Mean Loss: 0.6901800818741322\n",
            "Value 1354 Mean Loss: 3.929228901863098\n",
            "dones: tensor(27.)\n",
            "Policy 1355 Mean Loss: -0.01220332266530022\n",
            "Entropy 1355 Mean Loss: 0.6908054836094379\n",
            "Value 1355 Mean Loss: 5.480961859226227\n",
            "dones: tensor(23.)\n",
            "Policy 1356 Mean Loss: -0.010788483428768814\n",
            "Entropy 1356 Mean Loss: 0.69073136895895\n",
            "Value 1356 Mean Loss: 4.144113823771477\n",
            "dones: tensor(24.)\n",
            "Policy 1357 Mean Loss: -0.007320246077142656\n",
            "Entropy 1357 Mean Loss: 0.6909237317740917\n",
            "Value 1357 Mean Loss: 4.577611327171326\n",
            "dones: tensor(25.)\n",
            "Policy 1358 Mean Loss: -0.006449397478718311\n",
            "Entropy 1358 Mean Loss: 0.6911109685897827\n",
            "Value 1358 Mean Loss: 4.50267381966114\n",
            "dones: tensor(25.)\n",
            "Policy 1359 Mean Loss: -0.006454485293943435\n",
            "Entropy 1359 Mean Loss: 0.6910766996443272\n",
            "Value 1359 Mean Loss: 4.4134660214185715\n",
            "dones: tensor(19.)\n",
            "Policy 1360 Mean Loss: -0.005864686798304319\n",
            "Entropy 1360 Mean Loss: 0.6907080672681332\n",
            "Value 1360 Mean Loss: 3.5877586007118225\n",
            "dones: tensor(25.)\n",
            "Policy 1361 Mean Loss: -0.009022696991451085\n",
            "Entropy 1361 Mean Loss: 0.6908293291926384\n",
            "Value 1361 Mean Loss: 4.311646789312363\n",
            "dones: tensor(28.)\n",
            "Policy 1362 Mean Loss: -0.00972205912694335\n",
            "Entropy 1362 Mean Loss: 0.6909621693193913\n",
            "Value 1362 Mean Loss: 4.7926768362522125\n",
            "dones: tensor(23.)\n",
            "Policy 1363 Mean Loss: -0.0040049306699074805\n",
            "Entropy 1363 Mean Loss: 0.6909432858228683\n",
            "Value 1363 Mean Loss: 4.469011411070824\n",
            "dones: tensor(20.)\n",
            "Policy 1364 Mean Loss: -0.0058138209860771894\n",
            "Entropy 1364 Mean Loss: 0.6909170113503933\n",
            "Value 1364 Mean Loss: 4.385377615690231\n",
            "dones: tensor(24.)\n",
            "Policy 1365 Mean Loss: -0.011646529077552259\n",
            "Entropy 1365 Mean Loss: 0.6910106316208839\n",
            "Value 1365 Mean Loss: 4.508237361907959\n",
            "dones: tensor(23.)\n",
            "Policy 1366 Mean Loss: -0.005640406510792673\n",
            "Entropy 1366 Mean Loss: 0.6907383091747761\n",
            "Value 1366 Mean Loss: 4.466487169265747\n",
            "dones: tensor(21.)\n",
            "Policy 1367 Mean Loss: -0.0031945620430633426\n",
            "Entropy 1367 Mean Loss: 0.690795011818409\n",
            "Value 1367 Mean Loss: 4.61452442407608\n",
            "dones: tensor(26.)\n",
            "Policy 1368 Mean Loss: -0.004109660862013698\n",
            "Entropy 1368 Mean Loss: 0.6909759417176247\n",
            "Value 1368 Mean Loss: 4.35940782725811\n",
            "dones: tensor(23.)\n",
            "Policy 1369 Mean Loss: -0.006438927666749805\n",
            "Entropy 1369 Mean Loss: 0.6907233595848083\n",
            "Value 1369 Mean Loss: 4.461413398385048\n",
            "dones: tensor(21.)\n",
            "Policy 1370 Mean Loss: -0.007476282888092101\n",
            "Entropy 1370 Mean Loss: 0.6907216608524323\n",
            "Value 1370 Mean Loss: 4.35764579474926\n",
            "dones: tensor(22.)\n",
            "Policy 1371 Mean Loss: -0.0019864391651935875\n",
            "Entropy 1371 Mean Loss: 0.6908117085695267\n",
            "Value 1371 Mean Loss: 4.360595658421516\n",
            "dones: tensor(26.)\n",
            "Policy 1372 Mean Loss: -0.008809666614979506\n",
            "Entropy 1372 Mean Loss: 0.6907557062804699\n",
            "Value 1372 Mean Loss: 4.71072855591774\n",
            "dones: tensor(26.)\n",
            "Policy 1373 Mean Loss: -0.003085292992182076\n",
            "Entropy 1373 Mean Loss: 0.6909358315169811\n",
            "Value 1373 Mean Loss: 4.551013335585594\n",
            "dones: tensor(20.)\n",
            "Policy 1374 Mean Loss: -0.0010458806063979864\n",
            "Entropy 1374 Mean Loss: 0.6910414732992649\n",
            "Value 1374 Mean Loss: 4.1165056973695755\n",
            "dones: tensor(25.)\n",
            "Policy 1375 Mean Loss: -0.0037539529148489237\n",
            "Entropy 1375 Mean Loss: 0.6911355964839458\n",
            "Value 1375 Mean Loss: 4.880959302186966\n",
            "dones: tensor(22.)\n",
            "Policy 1376 Mean Loss: -0.0008599612629041076\n",
            "Entropy 1376 Mean Loss: 0.6911311820149422\n",
            "Value 1376 Mean Loss: 4.395476430654526\n",
            "dones: tensor(27.)\n",
            "Policy 1377 Mean Loss: -0.005122647969983518\n",
            "Entropy 1377 Mean Loss: 0.6913395449519157\n",
            "Value 1377 Mean Loss: 4.846225291490555\n",
            "dones: tensor(27.)\n",
            "Policy 1378 Mean Loss: -0.00329493050230667\n",
            "Entropy 1378 Mean Loss: 0.691339273005724\n",
            "Value 1378 Mean Loss: 4.694412559270859\n",
            "dones: tensor(20.)\n",
            "Policy 1379 Mean Loss: -0.005986498203128576\n",
            "Entropy 1379 Mean Loss: 0.6909566596150398\n",
            "Value 1379 Mean Loss: 3.7397363781929016\n",
            "dones: tensor(23.)\n",
            "Policy 1380 Mean Loss: -0.008915697515476495\n",
            "Entropy 1380 Mean Loss: 0.6910839639604092\n",
            "Value 1380 Mean Loss: 4.385572478175163\n",
            "dones: tensor(22.)\n",
            "Policy 1381 Mean Loss: -0.00772871176013723\n",
            "Entropy 1381 Mean Loss: 0.6906534396111965\n",
            "Value 1381 Mean Loss: 4.519792929291725\n",
            "dones: tensor(19.)\n",
            "Policy 1382 Mean Loss: -0.008643384440802038\n",
            "Entropy 1382 Mean Loss: 0.6905967965722084\n",
            "Value 1382 Mean Loss: 4.432843118906021\n",
            "dones: tensor(21.)\n",
            "Policy 1383 Mean Loss: -0.006703454768285155\n",
            "Entropy 1383 Mean Loss: 0.6907186470925808\n",
            "Value 1383 Mean Loss: 4.509545996785164\n",
            "dones: tensor(24.)\n",
            "Policy 1384 Mean Loss: -0.007757611805573106\n",
            "Entropy 1384 Mean Loss: 0.6908686310052872\n",
            "Value 1384 Mean Loss: 4.450508192181587\n",
            "dones: tensor(22.)\n",
            "Policy 1385 Mean Loss: -0.00042490637861192226\n",
            "Entropy 1385 Mean Loss: 0.6905086487531662\n",
            "Value 1385 Mean Loss: 4.2574900686740875\n",
            "dones: tensor(24.)\n",
            "Policy 1386 Mean Loss: -0.009850023896433413\n",
            "Entropy 1386 Mean Loss: 0.6905457228422165\n",
            "Value 1386 Mean Loss: 4.988430559635162\n",
            "dones: tensor(19.)\n",
            "Policy 1387 Mean Loss: -0.008946619171183556\n",
            "Entropy 1387 Mean Loss: 0.6900314427912235\n",
            "Value 1387 Mean Loss: 4.084660306572914\n",
            "dones: tensor(29.)\n",
            "Policy 1388 Mean Loss: -0.009104414202738553\n",
            "Entropy 1388 Mean Loss: 0.6905088648200035\n",
            "Value 1388 Mean Loss: 5.392468959093094\n",
            "dones: tensor(22.)\n",
            "Policy 1389 Mean Loss: -0.0027109678485430777\n",
            "Entropy 1389 Mean Loss: 0.690638080239296\n",
            "Value 1389 Mean Loss: 4.1095577627420425\n",
            "dones: tensor(22.)\n",
            "Policy 1390 Mean Loss: -0.007624191697686911\n",
            "Entropy 1390 Mean Loss: 0.6905243061482906\n",
            "Value 1390 Mean Loss: 4.587053000926971\n",
            "dones: tensor(23.)\n",
            "Policy 1391 Mean Loss: -0.006817345740273595\n",
            "Entropy 1391 Mean Loss: 0.6903909146785736\n",
            "Value 1391 Mean Loss: 4.740303546190262\n",
            "dones: tensor(24.)\n",
            "Policy 1392 Mean Loss: -0.00931745331035927\n",
            "Entropy 1392 Mean Loss: 0.6906272992491722\n",
            "Value 1392 Mean Loss: 4.4511343985795975\n",
            "dones: tensor(20.)\n",
            "Policy 1393 Mean Loss: -0.004044407629407942\n",
            "Entropy 1393 Mean Loss: 0.6907102093100548\n",
            "Value 1393 Mean Loss: 4.308149069547653\n",
            "dones: tensor(20.)\n",
            "Policy 1394 Mean Loss: -0.0013647021842189133\n",
            "Entropy 1394 Mean Loss: 0.6907095313072205\n",
            "Value 1394 Mean Loss: 4.078241646289825\n",
            "dones: tensor(23.)\n",
            "Policy 1395 Mean Loss: -0.004974507144652307\n",
            "Entropy 1395 Mean Loss: 0.6910745464265347\n",
            "Value 1395 Mean Loss: 4.539392292499542\n",
            "dones: tensor(23.)\n",
            "Policy 1396 Mean Loss: -0.0025172666064463556\n",
            "Entropy 1396 Mean Loss: 0.6909800581634045\n",
            "Value 1396 Mean Loss: 4.30626305937767\n",
            "dones: tensor(22.)\n",
            "Policy 1397 Mean Loss: -0.006952912430278957\n",
            "Entropy 1397 Mean Loss: 0.691070556640625\n",
            "Value 1397 Mean Loss: 4.9285357892513275\n",
            "dones: tensor(20.)\n",
            "Policy 1398 Mean Loss: -0.0021019873674958944\n",
            "Entropy 1398 Mean Loss: 0.6908316612243652\n",
            "Value 1398 Mean Loss: 4.536551207304001\n",
            "dones: tensor(20.)\n",
            "Policy 1399 Mean Loss: -0.005790282157249749\n",
            "Entropy 1399 Mean Loss: 0.6907607838511467\n",
            "Value 1399 Mean Loss: 3.7272748947143555\n",
            "dones: tensor(24.)\n",
            "Policy 1400 Mean Loss: -0.005359090864658356\n",
            "Entropy 1400 Mean Loss: 0.6911816298961639\n",
            "Value 1400 Mean Loss: 4.389704391360283\n",
            "dones: tensor(24.)\n",
            "Policy 1401 Mean Loss: -0.007041485630907118\n",
            "Entropy 1401 Mean Loss: 0.690938726067543\n",
            "Value 1401 Mean Loss: 4.697646945714951\n",
            "dones: tensor(22.)\n",
            "Policy 1402 Mean Loss: -0.007735046558082104\n",
            "Entropy 1402 Mean Loss: 0.6905489005148411\n",
            "Value 1402 Mean Loss: 4.363424450159073\n",
            "dones: tensor(25.)\n",
            "Policy 1403 Mean Loss: -0.004570221295580268\n",
            "Entropy 1403 Mean Loss: 0.6906113214790821\n",
            "Value 1403 Mean Loss: 4.702437460422516\n",
            "dones: tensor(26.)\n",
            "Policy 1404 Mean Loss: -0.010165700688958168\n",
            "Entropy 1404 Mean Loss: 0.6905836574733257\n",
            "Value 1404 Mean Loss: 4.892662137746811\n",
            "dones: tensor(27.)\n",
            "Policy 1405 Mean Loss: -0.0047061030636541545\n",
            "Entropy 1405 Mean Loss: 0.6909058541059494\n",
            "Value 1405 Mean Loss: 4.670014560222626\n",
            "dones: tensor(21.)\n",
            "Policy 1406 Mean Loss: -0.004545145318843424\n",
            "Entropy 1406 Mean Loss: 0.6908821240067482\n",
            "Value 1406 Mean Loss: 3.689051553606987\n",
            "dones: tensor(20.)\n",
            "Policy 1407 Mean Loss: -0.007134225685149431\n",
            "Entropy 1407 Mean Loss: 0.6907316409051418\n",
            "Value 1407 Mean Loss: 4.339104980230331\n",
            "dones: tensor(20.)\n",
            "Policy 1408 Mean Loss: -0.011204982700292021\n",
            "Entropy 1408 Mean Loss: 0.6905998513102531\n",
            "Value 1408 Mean Loss: 4.278312593698502\n",
            "dones: tensor(22.)\n",
            "Policy 1409 Mean Loss: -0.0029600175912491977\n",
            "Entropy 1409 Mean Loss: 0.6905710436403751\n",
            "Value 1409 Mean Loss: 3.9955311715602875\n",
            "dones: tensor(19.)\n",
            "Policy 1410 Mean Loss: -0.007591825269628316\n",
            "Entropy 1410 Mean Loss: 0.6903565190732479\n",
            "Value 1410 Mean Loss: 5.222877085208893\n",
            "dones: tensor(24.)\n",
            "Policy 1411 Mean Loss: -0.006231454957742244\n",
            "Entropy 1411 Mean Loss: 0.6904391273856163\n",
            "Value 1411 Mean Loss: 4.472320884466171\n",
            "dones: tensor(20.)\n",
            "Policy 1412 Mean Loss: -0.0022304372396320105\n",
            "Entropy 1412 Mean Loss: 0.6906831376254559\n",
            "Value 1412 Mean Loss: 4.111780807375908\n",
            "dones: tensor(19.)\n",
            "Policy 1413 Mean Loss: -0.009551599679980427\n",
            "Entropy 1413 Mean Loss: 0.6903055794537067\n",
            "Value 1413 Mean Loss: 4.707944959402084\n",
            "dones: tensor(18.)\n",
            "Policy 1414 Mean Loss: -0.004805277392733842\n",
            "Entropy 1414 Mean Loss: 0.6905925236642361\n",
            "Value 1414 Mean Loss: 3.976736158132553\n",
            "dones: tensor(21.)\n",
            "Policy 1415 Mean Loss: -0.006127934728283435\n",
            "Entropy 1415 Mean Loss: 0.6906732097268105\n",
            "Value 1415 Mean Loss: 4.412157595157623\n",
            "dones: tensor(18.)\n",
            "Policy 1416 Mean Loss: -0.005966416036244482\n",
            "Entropy 1416 Mean Loss: 0.690849095582962\n",
            "Value 1416 Mean Loss: 5.08100426197052\n",
            "dones: tensor(21.)\n",
            "Policy 1417 Mean Loss: -0.0019219755486119539\n",
            "Entropy 1417 Mean Loss: 0.6907176300883293\n",
            "Value 1417 Mean Loss: 4.4983298778533936\n",
            "dones: tensor(22.)\n",
            "Policy 1418 Mean Loss: -0.014621693058870733\n",
            "Entropy 1418 Mean Loss: 0.6906288117170334\n",
            "Value 1418 Mean Loss: 5.093665823340416\n",
            "dones: tensor(24.)\n",
            "Policy 1419 Mean Loss: -0.006436525902245194\n",
            "Entropy 1419 Mean Loss: 0.6907589249312878\n",
            "Value 1419 Mean Loss: 5.793733775615692\n",
            "dones: tensor(17.)\n",
            "Policy 1420 Mean Loss: -0.009178236534353346\n",
            "Entropy 1420 Mean Loss: 0.6910283677279949\n",
            "Value 1420 Mean Loss: 4.64049531519413\n",
            "dones: tensor(20.)\n",
            "Policy 1421 Mean Loss: -0.004316141945309937\n",
            "Entropy 1421 Mean Loss: 0.6909462884068489\n",
            "Value 1421 Mean Loss: 4.73714092373848\n",
            "dones: tensor(25.)\n",
            "Policy 1422 Mean Loss: -0.006912734592333436\n",
            "Entropy 1422 Mean Loss: 0.6909297779202461\n",
            "Value 1422 Mean Loss: 5.1694671511650085\n",
            "dones: tensor(20.)\n",
            "Policy 1423 Mean Loss: -0.002172717184294015\n",
            "Entropy 1423 Mean Loss: 0.6907707042992115\n",
            "Value 1423 Mean Loss: 5.534877806901932\n",
            "dones: tensor(23.)\n",
            "Policy 1424 Mean Loss: 0.000652859453111887\n",
            "Entropy 1424 Mean Loss: 0.6907653398811817\n",
            "Value 1424 Mean Loss: 4.783882528543472\n",
            "dones: tensor(20.)\n",
            "Policy 1425 Mean Loss: -0.005231331335380673\n",
            "Entropy 1425 Mean Loss: 0.6909638270735741\n",
            "Value 1425 Mean Loss: 4.24952632188797\n",
            "dones: tensor(20.)\n",
            "Policy 1426 Mean Loss: -0.008352396893315017\n",
            "Entropy 1426 Mean Loss: 0.6907080374658108\n",
            "Value 1426 Mean Loss: 4.244132339954376\n",
            "dones: tensor(25.)\n",
            "Policy 1427 Mean Loss: -0.007168477342929691\n",
            "Entropy 1427 Mean Loss: 0.6911270692944527\n",
            "Value 1427 Mean Loss: 4.766328543424606\n",
            "dones: tensor(24.)\n",
            "Policy 1428 Mean Loss: -0.002083114522974938\n",
            "Entropy 1428 Mean Loss: 0.6911160759627819\n",
            "Value 1428 Mean Loss: 5.105812817811966\n",
            "dones: tensor(23.)\n",
            "Policy 1429 Mean Loss: -0.009474955353653058\n",
            "Entropy 1429 Mean Loss: 0.6909129656851292\n",
            "Value 1429 Mean Loss: 4.5646198987960815\n",
            "dones: tensor(20.)\n",
            "Policy 1430 Mean Loss: -0.011083407211117446\n",
            "Entropy 1430 Mean Loss: 0.6908201016485691\n",
            "Value 1430 Mean Loss: 4.542209669947624\n",
            "dones: tensor(24.)\n",
            "Policy 1431 Mean Loss: -0.00377684022532776\n",
            "Entropy 1431 Mean Loss: 0.6907798014581203\n",
            "Value 1431 Mean Loss: 4.729676127433777\n",
            "dones: tensor(16.)\n",
            "Policy 1432 Mean Loss: -0.0011856030323542655\n",
            "Entropy 1432 Mean Loss: 0.6909372955560684\n",
            "Value 1432 Mean Loss: 5.069681793451309\n",
            "dones: tensor(27.)\n",
            "Policy 1433 Mean Loss: -0.008093502605333924\n",
            "Entropy 1433 Mean Loss: 0.6909180171787739\n",
            "Value 1433 Mean Loss: 5.77524608373642\n",
            "dones: tensor(24.)\n",
            "Policy 1434 Mean Loss: -0.008083546592388302\n",
            "Entropy 1434 Mean Loss: 0.6909718960523605\n",
            "Value 1434 Mean Loss: 4.516690164804459\n",
            "dones: tensor(24.)\n",
            "Policy 1435 Mean Loss: -0.003886337683070451\n",
            "Entropy 1435 Mean Loss: 0.6911773569881916\n",
            "Value 1435 Mean Loss: 4.365552172064781\n",
            "dones: tensor(20.)\n",
            "Policy 1436 Mean Loss: -0.005005480081308633\n",
            "Entropy 1436 Mean Loss: 0.6908983960747719\n",
            "Value 1436 Mean Loss: 4.194230005145073\n",
            "dones: tensor(22.)\n",
            "Policy 1437 Mean Loss: -0.0019295522943139076\n",
            "Entropy 1437 Mean Loss: 0.6910551600158215\n",
            "Value 1437 Mean Loss: 4.639376282691956\n",
            "dones: tensor(22.)\n",
            "Policy 1438 Mean Loss: -0.0025094859302043915\n",
            "Entropy 1438 Mean Loss: 0.6911428906023502\n",
            "Value 1438 Mean Loss: 4.808581203222275\n",
            "dones: tensor(25.)\n",
            "Policy 1439 Mean Loss: -0.012756318785250187\n",
            "Entropy 1439 Mean Loss: 0.691197831183672\n",
            "Value 1439 Mean Loss: 4.230093687772751\n",
            "dones: tensor(19.)\n",
            "Policy 1440 Mean Loss: -0.011759603628888726\n",
            "Entropy 1440 Mean Loss: 0.6906628794968128\n",
            "Value 1440 Mean Loss: 4.378516912460327\n",
            "dones: tensor(23.)\n",
            "Policy 1441 Mean Loss: -0.005034218542277813\n",
            "Entropy 1441 Mean Loss: 0.6911617740988731\n",
            "Value 1441 Mean Loss: 5.309865027666092\n",
            "dones: tensor(22.)\n",
            "Policy 1442 Mean Loss: 0.0002168097416870296\n",
            "Entropy 1442 Mean Loss: 0.6910206153988838\n",
            "Value 1442 Mean Loss: 4.224502012133598\n",
            "dones: tensor(21.)\n",
            "Policy 1443 Mean Loss: -0.012751154514262453\n",
            "Entropy 1443 Mean Loss: 0.6909710764884949\n",
            "Value 1443 Mean Loss: 4.458571031689644\n",
            "dones: tensor(21.)\n",
            "Policy 1444 Mean Loss: -0.00667382957180962\n",
            "Entropy 1444 Mean Loss: 0.6906647384166718\n",
            "Value 1444 Mean Loss: 4.45811153948307\n",
            "dones: tensor(27.)\n",
            "Policy 1445 Mean Loss: -0.006624421977903694\n",
            "Entropy 1445 Mean Loss: 0.6909321136772633\n",
            "Value 1445 Mean Loss: 5.146743893623352\n",
            "dones: tensor(18.)\n",
            "Policy 1446 Mean Loss: -0.006706160842441022\n",
            "Entropy 1446 Mean Loss: 0.6905985213816166\n",
            "Value 1446 Mean Loss: 4.7432354390621185\n",
            "dones: tensor(24.)\n",
            "Policy 1447 Mean Loss: -0.003921230207197368\n",
            "Entropy 1447 Mean Loss: 0.6905745267868042\n",
            "Value 1447 Mean Loss: 5.111916869878769\n",
            "dones: tensor(22.)\n",
            "Policy 1448 Mean Loss: -0.007446550473105162\n",
            "Entropy 1448 Mean Loss: 0.690645731985569\n",
            "Value 1448 Mean Loss: 4.302413761615753\n",
            "dones: tensor(24.)\n",
            "Policy 1449 Mean Loss: -0.007482040789909661\n",
            "Entropy 1449 Mean Loss: 0.6906759366393089\n",
            "Value 1449 Mean Loss: 4.441492810845375\n",
            "dones: tensor(22.)\n",
            "Policy 1450 Mean Loss: -0.005314677197020501\n",
            "Entropy 1450 Mean Loss: 0.6901115700602531\n",
            "Value 1450 Mean Loss: 4.683362156152725\n",
            "dones: tensor(21.)\n",
            "Policy 1451 Mean Loss: -0.0013024554937146604\n",
            "Entropy 1451 Mean Loss: 0.6904551647603512\n",
            "Value 1451 Mean Loss: 4.520937979221344\n",
            "dones: tensor(27.)\n",
            "Policy 1452 Mean Loss: -0.0059935792232863605\n",
            "Entropy 1452 Mean Loss: 0.690831333398819\n",
            "Value 1452 Mean Loss: 5.919253468513489\n",
            "dones: tensor(22.)\n",
            "Policy 1453 Mean Loss: -0.007621114491485059\n",
            "Entropy 1453 Mean Loss: 0.69085593521595\n",
            "Value 1453 Mean Loss: 4.402290314435959\n",
            "dones: tensor(21.)\n",
            "Policy 1454 Mean Loss: -0.008708744426257908\n",
            "Entropy 1454 Mean Loss: 0.690459318459034\n",
            "Value 1454 Mean Loss: 4.484956681728363\n",
            "dones: tensor(24.)\n",
            "Policy 1455 Mean Loss: -0.007750295917503536\n",
            "Entropy 1455 Mean Loss: 0.69090161845088\n",
            "Value 1455 Mean Loss: 4.252544745802879\n",
            "dones: tensor(24.)\n",
            "Policy 1456 Mean Loss: -0.007883234124165028\n",
            "Entropy 1456 Mean Loss: 0.6909776516258717\n",
            "Value 1456 Mean Loss: 4.7026492059230804\n",
            "dones: tensor(25.)\n",
            "Policy 1457 Mean Loss: -0.008370433759409934\n",
            "Entropy 1457 Mean Loss: 0.6910206079483032\n",
            "Value 1457 Mean Loss: 4.662540853023529\n",
            "dones: tensor(23.)\n",
            "Policy 1458 Mean Loss: -0.008737277530599385\n",
            "Entropy 1458 Mean Loss: 0.6909505352377892\n",
            "Value 1458 Mean Loss: 4.171742737293243\n",
            "dones: tensor(23.)\n",
            "Policy 1459 Mean Loss: -0.0024920811410993338\n",
            "Entropy 1459 Mean Loss: 0.6911833249032497\n",
            "Value 1459 Mean Loss: 4.8561559319496155\n",
            "dones: tensor(23.)\n",
            "Policy 1460 Mean Loss: -0.008086931484285742\n",
            "Entropy 1460 Mean Loss: 0.691140066832304\n",
            "Value 1460 Mean Loss: 4.5313332080841064\n",
            "dones: tensor(24.)\n",
            "Policy 1461 Mean Loss: -0.005148379015736282\n",
            "Entropy 1461 Mean Loss: 0.6907049044966698\n",
            "Value 1461 Mean Loss: 4.663468360900879\n",
            "dones: tensor(24.)\n",
            "Policy 1462 Mean Loss: -0.007170742901507765\n",
            "Entropy 1462 Mean Loss: 0.6907619014382362\n",
            "Value 1462 Mean Loss: 4.705922931432724\n",
            "dones: tensor(22.)\n",
            "Policy 1463 Mean Loss: -0.0034948086831718683\n",
            "Entropy 1463 Mean Loss: 0.690582413226366\n",
            "Value 1463 Mean Loss: 4.4565015733242035\n",
            "dones: tensor(22.)\n",
            "Policy 1464 Mean Loss: -0.008872357313521206\n",
            "Entropy 1464 Mean Loss: 0.6905078515410423\n",
            "Value 1464 Mean Loss: 4.105576768517494\n",
            "dones: tensor(23.)\n",
            "Policy 1465 Mean Loss: -0.005052729742601514\n",
            "Entropy 1465 Mean Loss: 0.6904938481748104\n",
            "Value 1465 Mean Loss: 4.5533547103405\n",
            "dones: tensor(23.)\n",
            "Policy 1466 Mean Loss: -0.006386954395566136\n",
            "Entropy 1466 Mean Loss: 0.6906566172838211\n",
            "Value 1466 Mean Loss: 4.598615199327469\n",
            "dones: tensor(20.)\n",
            "Policy 1467 Mean Loss: -0.00354133133077994\n",
            "Entropy 1467 Mean Loss: 0.6906662657856941\n",
            "Value 1467 Mean Loss: 4.265782803297043\n",
            "dones: tensor(26.)\n",
            "Policy 1468 Mean Loss: -0.005527449073269963\n",
            "Entropy 1468 Mean Loss: 0.6908879391849041\n",
            "Value 1468 Mean Loss: 4.82588928937912\n",
            "dones: tensor(25.)\n",
            "Policy 1469 Mean Loss: -0.006214408378582448\n",
            "Entropy 1469 Mean Loss: 0.6909678354859352\n",
            "Value 1469 Mean Loss: 4.779292613267899\n",
            "dones: tensor(23.)\n",
            "Policy 1470 Mean Loss: -0.0010697212419472635\n",
            "Entropy 1470 Mean Loss: 0.6911414265632629\n",
            "Value 1470 Mean Loss: 4.866840898990631\n",
            "dones: tensor(22.)\n",
            "Policy 1471 Mean Loss: -0.0031560066272504628\n",
            "Entropy 1471 Mean Loss: 0.6911471784114838\n",
            "Value 1471 Mean Loss: 4.272183299064636\n",
            "dones: tensor(18.)\n",
            "Policy 1472 Mean Loss: -0.0022917810711078346\n",
            "Entropy 1472 Mean Loss: 0.691149391233921\n",
            "Value 1472 Mean Loss: 4.215751186013222\n",
            "dones: tensor(22.)\n",
            "Policy 1473 Mean Loss: -0.006181983568239957\n",
            "Entropy 1473 Mean Loss: 0.6911718435585499\n",
            "Value 1473 Mean Loss: 4.972396939992905\n",
            "dones: tensor(19.)\n",
            "Policy 1474 Mean Loss: -0.0017082943231798708\n",
            "Entropy 1474 Mean Loss: 0.6912492141127586\n",
            "Value 1474 Mean Loss: 5.17534077167511\n",
            "dones: tensor(20.)\n",
            "Policy 1475 Mean Loss: -0.007392436149530113\n",
            "Entropy 1475 Mean Loss: 0.6909340582787991\n",
            "Value 1475 Mean Loss: 4.486162051558495\n",
            "dones: tensor(22.)\n",
            "Policy 1476 Mean Loss: -0.006072216463508084\n",
            "Entropy 1476 Mean Loss: 0.6910801082849503\n",
            "Value 1476 Mean Loss: 4.236597061157227\n",
            "dones: tensor(18.)\n",
            "Policy 1477 Mean Loss: -0.0028018406010232866\n",
            "Entropy 1477 Mean Loss: 0.6906699873507023\n",
            "Value 1477 Mean Loss: 4.085906520485878\n",
            "dones: tensor(25.)\n",
            "Policy 1478 Mean Loss: -0.005580639292020351\n",
            "Entropy 1478 Mean Loss: 0.6911019049584866\n",
            "Value 1478 Mean Loss: 4.845814138650894\n",
            "dones: tensor(23.)\n",
            "Policy 1479 Mean Loss: -0.0025813173269852996\n",
            "Entropy 1479 Mean Loss: 0.6909651458263397\n",
            "Value 1479 Mean Loss: 4.994336634874344\n",
            "dones: tensor(20.)\n",
            "Policy 1480 Mean Loss: -0.006380708946380764\n",
            "Entropy 1480 Mean Loss: 0.690593246370554\n",
            "Value 1480 Mean Loss: 4.3204944878816605\n",
            "dones: tensor(22.)\n",
            "Policy 1481 Mean Loss: -0.002315709600225091\n",
            "Entropy 1481 Mean Loss: 0.6907523274421692\n",
            "Value 1481 Mean Loss: 4.788123771548271\n",
            "dones: tensor(23.)\n",
            "Policy 1482 Mean Loss: -0.006356535479426384\n",
            "Entropy 1482 Mean Loss: 0.690771572291851\n",
            "Value 1482 Mean Loss: 4.76993054151535\n",
            "dones: tensor(20.)\n",
            "Policy 1483 Mean Loss: -0.004002572095487267\n",
            "Entropy 1483 Mean Loss: 0.6905801668763161\n",
            "Value 1483 Mean Loss: 4.564699828624725\n",
            "dones: tensor(23.)\n",
            "Policy 1484 Mean Loss: -0.0028151844162493944\n",
            "Entropy 1484 Mean Loss: 0.6908400878310204\n",
            "Value 1484 Mean Loss: 5.089726954698563\n",
            "dones: tensor(25.)\n",
            "Policy 1485 Mean Loss: -0.008813166292384267\n",
            "Entropy 1485 Mean Loss: 0.6910134963691235\n",
            "Value 1485 Mean Loss: 4.551513984799385\n",
            "dones: tensor(17.)\n",
            "Policy 1486 Mean Loss: -0.005051640560850501\n",
            "Entropy 1486 Mean Loss: 0.6906907968223095\n",
            "Value 1486 Mean Loss: 3.5119909793138504\n",
            "dones: tensor(20.)\n",
            "Policy 1487 Mean Loss: -0.007482184446416795\n",
            "Entropy 1487 Mean Loss: 0.6907636262476444\n",
            "Value 1487 Mean Loss: 4.519271224737167\n",
            "dones: tensor(23.)\n",
            "Policy 1488 Mean Loss: -0.003395664563868195\n",
            "Entropy 1488 Mean Loss: 0.6909210495650768\n",
            "Value 1488 Mean Loss: 4.680304408073425\n",
            "dones: tensor(21.)\n",
            "Policy 1489 Mean Loss: -0.005403287766966969\n",
            "Entropy 1489 Mean Loss: 0.6907025426626205\n",
            "Value 1489 Mean Loss: 4.397126600146294\n",
            "dones: tensor(19.)\n",
            "Policy 1490 Mean Loss: -0.008075345656834543\n",
            "Entropy 1490 Mean Loss: 0.6906846649944782\n",
            "Value 1490 Mean Loss: 3.7302323430776596\n",
            "dones: tensor(23.)\n",
            "Policy 1491 Mean Loss: -0.007137431530281901\n",
            "Entropy 1491 Mean Loss: 0.690984096378088\n",
            "Value 1491 Mean Loss: 4.4451935440301895\n",
            "dones: tensor(25.)\n",
            "Policy 1492 Mean Loss: -0.009989814134314656\n",
            "Entropy 1492 Mean Loss: 0.6908560320734978\n",
            "Value 1492 Mean Loss: 4.888751432299614\n",
            "dones: tensor(22.)\n",
            "Policy 1493 Mean Loss: -0.007964401855133474\n",
            "Entropy 1493 Mean Loss: 0.6907196193933487\n",
            "Value 1493 Mean Loss: 4.376284137368202\n",
            "dones: tensor(23.)\n",
            "Policy 1494 Mean Loss: -0.0059141539968550205\n",
            "Entropy 1494 Mean Loss: 0.6904850006103516\n",
            "Value 1494 Mean Loss: 4.870550513267517\n",
            "dones: tensor(25.)\n",
            "Policy 1495 Mean Loss: -0.007981844421010464\n",
            "Entropy 1495 Mean Loss: 0.6904285550117493\n",
            "Value 1495 Mean Loss: 4.922667443752289\n",
            "dones: tensor(22.)\n",
            "Policy 1496 Mean Loss: -0.006639948929660022\n",
            "Entropy 1496 Mean Loss: 0.6905390433967113\n",
            "Value 1496 Mean Loss: 4.333164542913437\n",
            "dones: tensor(21.)\n",
            "Policy 1497 Mean Loss: -0.0018616107408888638\n",
            "Entropy 1497 Mean Loss: 0.6904711835086346\n",
            "Value 1497 Mean Loss: 4.335285738110542\n",
            "dones: tensor(23.)\n",
            "Policy 1498 Mean Loss: -0.002351287635974586\n",
            "Entropy 1498 Mean Loss: 0.6906123608350754\n",
            "Value 1498 Mean Loss: 3.974507197737694\n",
            "dones: tensor(20.)\n",
            "Policy 1499 Mean Loss: -0.0026216324768029153\n",
            "Entropy 1499 Mean Loss: 0.6905124932527542\n",
            "Value 1499 Mean Loss: 4.365142047405243\n",
            "dones: tensor(28.)\n",
            "Policy 1500 Mean Loss: -0.00941381073789671\n",
            "Entropy 1500 Mean Loss: 0.6907055377960205\n",
            "Value 1500 Mean Loss: 5.156341940164566\n",
            "dones: tensor(27.)\n",
            "Policy 1501 Mean Loss: -0.003116753767244518\n",
            "Entropy 1501 Mean Loss: 0.6905615739524364\n",
            "Value 1501 Mean Loss: 4.82119357585907\n",
            "dones: tensor(24.)\n",
            "Policy 1502 Mean Loss: -0.00641570461448282\n",
            "Entropy 1502 Mean Loss: 0.6905038841068745\n",
            "Value 1502 Mean Loss: 4.785305500030518\n",
            "dones: tensor(23.)\n",
            "Policy 1503 Mean Loss: -0.0021126336650922894\n",
            "Entropy 1503 Mean Loss: 0.6906464211642742\n",
            "Value 1503 Mean Loss: 4.548049718141556\n",
            "dones: tensor(23.)\n",
            "Policy 1504 Mean Loss: -0.0025487655075266957\n",
            "Entropy 1504 Mean Loss: 0.6906646639108658\n",
            "Value 1504 Mean Loss: 4.139739021658897\n",
            "dones: tensor(24.)\n",
            "Policy 1505 Mean Loss: -0.002916234079748392\n",
            "Entropy 1505 Mean Loss: 0.691030353307724\n",
            "Value 1505 Mean Loss: 4.350256949663162\n",
            "dones: tensor(24.)\n",
            "Policy 1506 Mean Loss: -0.007448373595252633\n",
            "Entropy 1506 Mean Loss: 0.6909687258303165\n",
            "Value 1506 Mean Loss: 4.201042622327805\n",
            "dones: tensor(26.)\n",
            "Policy 1507 Mean Loss: -0.011167468735948205\n",
            "Entropy 1507 Mean Loss: 0.6909071393311024\n",
            "Value 1507 Mean Loss: 4.670959919691086\n",
            "dones: tensor(22.)\n",
            "Policy 1508 Mean Loss: -0.004925159504637122\n",
            "Entropy 1508 Mean Loss: 0.6904608495533466\n",
            "Value 1508 Mean Loss: 4.228212356567383\n",
            "dones: tensor(27.)\n",
            "Policy 1509 Mean Loss: -0.010898862150497735\n",
            "Entropy 1509 Mean Loss: 0.6905784569680691\n",
            "Value 1509 Mean Loss: 4.612992584705353\n",
            "dones: tensor(25.)\n",
            "Policy 1510 Mean Loss: -0.005152347439434379\n",
            "Entropy 1510 Mean Loss: 0.690310638397932\n",
            "Value 1510 Mean Loss: 4.4612061232328415\n",
            "dones: tensor(22.)\n",
            "Policy 1511 Mean Loss: -0.007715782034210861\n",
            "Entropy 1511 Mean Loss: 0.6902147307991982\n",
            "Value 1511 Mean Loss: 3.732085019350052\n",
            "dones: tensor(21.)\n",
            "Policy 1512 Mean Loss: -0.00550783087965101\n",
            "Entropy 1512 Mean Loss: 0.6901730448007584\n",
            "Value 1512 Mean Loss: 3.710928037762642\n",
            "dones: tensor(19.)\n",
            "Policy 1513 Mean Loss: -0.011759474582504481\n",
            "Entropy 1513 Mean Loss: 0.6900430358946323\n",
            "Value 1513 Mean Loss: 3.960191026329994\n",
            "dones: tensor(22.)\n",
            "Policy 1514 Mean Loss: -0.0045968053746037185\n",
            "Entropy 1514 Mean Loss: 0.6898269131779671\n",
            "Value 1514 Mean Loss: 4.27911114692688\n",
            "dones: tensor(24.)\n",
            "Policy 1515 Mean Loss: -0.0039170412928797305\n",
            "Entropy 1515 Mean Loss: 0.6901421397924423\n",
            "Value 1515 Mean Loss: 4.744987979531288\n",
            "dones: tensor(23.)\n",
            "Policy 1516 Mean Loss: -0.005027291481383145\n",
            "Entropy 1516 Mean Loss: 0.6905766390264034\n",
            "Value 1516 Mean Loss: 5.254270315170288\n",
            "dones: tensor(19.)\n",
            "Policy 1517 Mean Loss: -0.005064319469965994\n",
            "Entropy 1517 Mean Loss: 0.6902066133916378\n",
            "Value 1517 Mean Loss: 3.8128769397735596\n",
            "dones: tensor(19.)\n",
            "Policy 1518 Mean Loss: -0.006430258683394641\n",
            "Entropy 1518 Mean Loss: 0.6905482485890388\n",
            "Value 1518 Mean Loss: 4.199865743517876\n",
            "dones: tensor(22.)\n",
            "Policy 1519 Mean Loss: -0.007329314015805721\n",
            "Entropy 1519 Mean Loss: 0.690401516854763\n",
            "Value 1519 Mean Loss: 4.697942346334457\n",
            "dones: tensor(23.)\n",
            "Policy 1520 Mean Loss: -0.0073859968688338995\n",
            "Entropy 1520 Mean Loss: 0.6905970796942711\n",
            "Value 1520 Mean Loss: 4.616201668977737\n",
            "dones: tensor(20.)\n",
            "Policy 1521 Mean Loss: -0.007347331033088267\n",
            "Entropy 1521 Mean Loss: 0.6904248930513859\n",
            "Value 1521 Mean Loss: 4.064873173832893\n",
            "dones: tensor(16.)\n",
            "Policy 1522 Mean Loss: -0.010286865173839033\n",
            "Entropy 1522 Mean Loss: 0.6902101300656796\n",
            "Value 1522 Mean Loss: 5.624035000801086\n",
            "dones: tensor(24.)\n",
            "Policy 1523 Mean Loss: -0.005094694497529417\n",
            "Entropy 1523 Mean Loss: 0.6906780898571014\n",
            "Value 1523 Mean Loss: 5.067598968744278\n",
            "dones: tensor(25.)\n",
            "Policy 1524 Mean Loss: -0.006833044230006635\n",
            "Entropy 1524 Mean Loss: 0.6906145848333836\n",
            "Value 1524 Mean Loss: 4.653159081935883\n",
            "dones: tensor(20.)\n",
            "Policy 1525 Mean Loss: -0.0068312103394418955\n",
            "Entropy 1525 Mean Loss: 0.6905433386564255\n",
            "Value 1525 Mean Loss: 4.2780426144599915\n",
            "dones: tensor(20.)\n",
            "Policy 1526 Mean Loss: -0.010539233568124473\n",
            "Entropy 1526 Mean Loss: 0.6908726431429386\n",
            "Value 1526 Mean Loss: 4.919041335582733\n",
            "dones: tensor(19.)\n",
            "Policy 1527 Mean Loss: -0.005769019713625312\n",
            "Entropy 1527 Mean Loss: 0.6905690170824528\n",
            "Value 1527 Mean Loss: 4.145896628499031\n",
            "dones: tensor(27.)\n",
            "Policy 1528 Mean Loss: -0.009517459897324443\n",
            "Entropy 1528 Mean Loss: 0.6908406168222427\n",
            "Value 1528 Mean Loss: 5.442476719617844\n",
            "dones: tensor(17.)\n",
            "Policy 1529 Mean Loss: -0.010930113261565566\n",
            "Entropy 1529 Mean Loss: 0.6902782469987869\n",
            "Value 1529 Mean Loss: 3.8558689057826996\n",
            "dones: tensor(25.)\n",
            "Policy 1530 Mean Loss: -0.004535078420303762\n",
            "Entropy 1530 Mean Loss: 0.6908706314861774\n",
            "Value 1530 Mean Loss: 5.273985117673874\n",
            "dones: tensor(25.)\n",
            "Policy 1531 Mean Loss: -0.0078121599508449435\n",
            "Entropy 1531 Mean Loss: 0.6907099038362503\n",
            "Value 1531 Mean Loss: 4.751476407051086\n",
            "dones: tensor(24.)\n",
            "Policy 1532 Mean Loss: -0.007121585891582072\n",
            "Entropy 1532 Mean Loss: 0.6905173286795616\n",
            "Value 1532 Mean Loss: 4.600337386131287\n",
            "dones: tensor(23.)\n",
            "Policy 1533 Mean Loss: -0.006010574754327536\n",
            "Entropy 1533 Mean Loss: 0.6906710602343082\n",
            "Value 1533 Mean Loss: 4.663212537765503\n",
            "dones: tensor(24.)\n",
            "Policy 1534 Mean Loss: -0.0038016457692719996\n",
            "Entropy 1534 Mean Loss: 0.6908744610846043\n",
            "Value 1534 Mean Loss: 4.256913512945175\n",
            "dones: tensor(23.)\n",
            "Policy 1535 Mean Loss: -0.006900597596541047\n",
            "Entropy 1535 Mean Loss: 0.6908035017549992\n",
            "Value 1535 Mean Loss: 4.299496039748192\n",
            "dones: tensor(25.)\n",
            "Policy 1536 Mean Loss: -0.005737705854699016\n",
            "Entropy 1536 Mean Loss: 0.6909004487097263\n",
            "Value 1536 Mean Loss: 4.654496192932129\n",
            "dones: tensor(21.)\n",
            "Policy 1537 Mean Loss: -0.003256368392612785\n",
            "Entropy 1537 Mean Loss: 0.6910129450261593\n",
            "Value 1537 Mean Loss: 4.5137762278318405\n",
            "dones: tensor(25.)\n",
            "Policy 1538 Mean Loss: -0.0036786033306270838\n",
            "Entropy 1538 Mean Loss: 0.6910817995667458\n",
            "Value 1538 Mean Loss: 4.2918892949819565\n",
            "dones: tensor(23.)\n",
            "Policy 1539 Mean Loss: -0.00708912403206341\n",
            "Entropy 1539 Mean Loss: 0.6910273395478725\n",
            "Value 1539 Mean Loss: 4.466577336192131\n",
            "dones: tensor(25.)\n",
            "Policy 1540 Mean Loss: -0.003500618156976998\n",
            "Entropy 1540 Mean Loss: 0.6908379383385181\n",
            "Value 1540 Mean Loss: 4.86335876584053\n",
            "dones: tensor(21.)\n",
            "Policy 1541 Mean Loss: -0.007585037761600688\n",
            "Entropy 1541 Mean Loss: 0.6909166388213634\n",
            "Value 1541 Mean Loss: 4.06569941341877\n",
            "dones: tensor(20.)\n",
            "Policy 1542 Mean Loss: -0.0038577198865823448\n",
            "Entropy 1542 Mean Loss: 0.6909852102398872\n",
            "Value 1542 Mean Loss: 3.799637421965599\n",
            "dones: tensor(20.)\n",
            "Policy 1543 Mean Loss: -0.004875649319728836\n",
            "Entropy 1543 Mean Loss: 0.691189706325531\n",
            "Value 1543 Mean Loss: 4.891991883516312\n",
            "dones: tensor(24.)\n",
            "Policy 1544 Mean Loss: -0.0034172204905189574\n",
            "Entropy 1544 Mean Loss: 0.6912512108683586\n",
            "Value 1544 Mean Loss: 5.021877646446228\n",
            "dones: tensor(21.)\n",
            "Policy 1545 Mean Loss: -0.004905294452328235\n",
            "Entropy 1545 Mean Loss: 0.6911893673241138\n",
            "Value 1545 Mean Loss: 5.0119741559028625\n",
            "dones: tensor(23.)\n",
            "Policy 1546 Mean Loss: -0.004124655039049685\n",
            "Entropy 1546 Mean Loss: 0.6911445185542107\n",
            "Value 1546 Mean Loss: 4.244015783071518\n",
            "dones: tensor(25.)\n",
            "Policy 1547 Mean Loss: -0.0073063496965914965\n",
            "Entropy 1547 Mean Loss: 0.6908844709396362\n",
            "Value 1547 Mean Loss: 4.684936538338661\n",
            "dones: tensor(22.)\n",
            "Policy 1548 Mean Loss: -0.004072210809681565\n",
            "Entropy 1548 Mean Loss: 0.690962441265583\n",
            "Value 1548 Mean Loss: 4.3215284794569016\n",
            "dones: tensor(23.)\n",
            "Policy 1549 Mean Loss: -0.004419237840920687\n",
            "Entropy 1549 Mean Loss: 0.6908511593937874\n",
            "Value 1549 Mean Loss: 4.173606440424919\n",
            "dones: tensor(23.)\n",
            "Policy 1550 Mean Loss: -0.0091013343189843\n",
            "Entropy 1550 Mean Loss: 0.691012866795063\n",
            "Value 1550 Mean Loss: 5.0043579041957855\n",
            "dones: tensor(21.)\n",
            "Policy 1551 Mean Loss: -0.007898262876551598\n",
            "Entropy 1551 Mean Loss: 0.6909075640141964\n",
            "Value 1551 Mean Loss: 4.203379243612289\n",
            "dones: tensor(23.)\n",
            "Policy 1552 Mean Loss: -0.0031394066172651947\n",
            "Entropy 1552 Mean Loss: 0.6908009313046932\n",
            "Value 1552 Mean Loss: 4.642829149961472\n",
            "dones: tensor(23.)\n",
            "Policy 1553 Mean Loss: -0.007972307736054063\n",
            "Entropy 1553 Mean Loss: 0.690660510212183\n",
            "Value 1553 Mean Loss: 4.252807825803757\n",
            "dones: tensor(23.)\n",
            "Policy 1554 Mean Loss: -0.005101613933220506\n",
            "Entropy 1554 Mean Loss: 0.6906388476490974\n",
            "Value 1554 Mean Loss: 4.253868952393532\n",
            "dones: tensor(25.)\n",
            "Policy 1555 Mean Loss: -0.003933694330044091\n",
            "Entropy 1555 Mean Loss: 0.6905204467475414\n",
            "Value 1555 Mean Loss: 4.563736915588379\n",
            "dones: tensor(23.)\n",
            "Policy 1556 Mean Loss: -0.006788920727558434\n",
            "Entropy 1556 Mean Loss: 0.6905663944780827\n",
            "Value 1556 Mean Loss: 4.800692066550255\n",
            "dones: tensor(29.)\n",
            "Policy 1557 Mean Loss: -0.0051292152784299105\n",
            "Entropy 1557 Mean Loss: 0.6908217631280422\n",
            "Value 1557 Mean Loss: 4.950685441493988\n",
            "dones: tensor(22.)\n",
            "Policy 1558 Mean Loss: -0.007518068247009069\n",
            "Entropy 1558 Mean Loss: 0.690356757491827\n",
            "Value 1558 Mean Loss: 4.417183995246887\n",
            "dones: tensor(21.)\n",
            "Policy 1559 Mean Loss: -0.011927175510209054\n",
            "Entropy 1559 Mean Loss: 0.6905684508383274\n",
            "Value 1559 Mean Loss: 4.067408129572868\n",
            "dones: tensor(23.)\n",
            "Policy 1560 Mean Loss: -0.010191684239543974\n",
            "Entropy 1560 Mean Loss: 0.6906020231544971\n",
            "Value 1560 Mean Loss: 4.043836265802383\n",
            "dones: tensor(21.)\n",
            "Policy 1561 Mean Loss: -0.0027985068736597896\n",
            "Entropy 1561 Mean Loss: 0.6904467567801476\n",
            "Value 1561 Mean Loss: 4.366820797324181\n",
            "dones: tensor(26.)\n",
            "Policy 1562 Mean Loss: -0.008224124787375331\n",
            "Entropy 1562 Mean Loss: 0.6905064545571804\n",
            "Value 1562 Mean Loss: 5.1063172817230225\n",
            "dones: tensor(21.)\n",
            "Policy 1563 Mean Loss: -0.007714025676250458\n",
            "Entropy 1563 Mean Loss: 0.6903784722089767\n",
            "Value 1563 Mean Loss: 4.872100830078125\n",
            "dones: tensor(28.)\n",
            "Policy 1564 Mean Loss: -0.004294725426007062\n",
            "Entropy 1564 Mean Loss: 0.6908056177198887\n",
            "Value 1564 Mean Loss: 4.657826811075211\n",
            "dones: tensor(21.)\n",
            "Policy 1565 Mean Loss: 0.0007961505907587707\n",
            "Entropy 1565 Mean Loss: 0.6906460039317608\n",
            "Value 1565 Mean Loss: 4.177970081567764\n",
            "dones: tensor(24.)\n",
            "Policy 1566 Mean Loss: -0.0035369520192034543\n",
            "Entropy 1566 Mean Loss: 0.6905201114714146\n",
            "Value 1566 Mean Loss: 4.5977848172187805\n",
            "dones: tensor(22.)\n",
            "Policy 1567 Mean Loss: -0.006915204809047282\n",
            "Entropy 1567 Mean Loss: 0.6909025758504868\n",
            "Value 1567 Mean Loss: 5.288659989833832\n",
            "dones: tensor(24.)\n",
            "Policy 1568 Mean Loss: -0.007462328125257045\n",
            "Entropy 1568 Mean Loss: 0.6909295357763767\n",
            "Value 1568 Mean Loss: 4.40224814414978\n",
            "dones: tensor(26.)\n",
            "Policy 1569 Mean Loss: -0.010471565095940605\n",
            "Entropy 1569 Mean Loss: 0.6909416764974594\n",
            "Value 1569 Mean Loss: 4.634762018918991\n",
            "dones: tensor(21.)\n",
            "Policy 1570 Mean Loss: -0.0042073363438248634\n",
            "Entropy 1570 Mean Loss: 0.6904917433857918\n",
            "Value 1570 Mean Loss: 4.13963121175766\n",
            "dones: tensor(20.)\n",
            "Policy 1571 Mean Loss: -0.010914567159488797\n",
            "Entropy 1571 Mean Loss: 0.6906187161803246\n",
            "Value 1571 Mean Loss: 4.0540521293878555\n",
            "dones: tensor(20.)\n",
            "Policy 1572 Mean Loss: -0.005392607417888939\n",
            "Entropy 1572 Mean Loss: 0.690735723823309\n",
            "Value 1572 Mean Loss: 4.051547810435295\n",
            "dones: tensor(23.)\n",
            "Policy 1573 Mean Loss: -0.004221524577587843\n",
            "Entropy 1573 Mean Loss: 0.6908538565039635\n",
            "Value 1573 Mean Loss: 4.503630921244621\n",
            "dones: tensor(27.)\n",
            "Policy 1574 Mean Loss: -0.004599493113346398\n",
            "Entropy 1574 Mean Loss: 0.6910446025431156\n",
            "Value 1574 Mean Loss: 4.650952994823456\n",
            "dones: tensor(24.)\n",
            "Policy 1575 Mean Loss: -0.006173079775180668\n",
            "Entropy 1575 Mean Loss: 0.6909968852996826\n",
            "Value 1575 Mean Loss: 4.880795359611511\n",
            "dones: tensor(21.)\n",
            "Policy 1576 Mean Loss: -0.00797101779608056\n",
            "Entropy 1576 Mean Loss: 0.6906401701271534\n",
            "Value 1576 Mean Loss: 3.866188168525696\n",
            "dones: tensor(18.)\n",
            "Policy 1577 Mean Loss: -0.007086725905537605\n",
            "Entropy 1577 Mean Loss: 0.6902984008193016\n",
            "Value 1577 Mean Loss: 4.209063529968262\n",
            "dones: tensor(20.)\n",
            "Policy 1578 Mean Loss: -0.003442455898039043\n",
            "Entropy 1578 Mean Loss: 0.690504178404808\n",
            "Value 1578 Mean Loss: 4.01243469119072\n",
            "dones: tensor(23.)\n",
            "Policy 1579 Mean Loss: -0.0055058482103049755\n",
            "Entropy 1579 Mean Loss: 0.6906513385474682\n",
            "Value 1579 Mean Loss: 4.5535169541835785\n",
            "dones: tensor(28.)\n",
            "Policy 1580 Mean Loss: -0.012116973288357258\n",
            "Entropy 1580 Mean Loss: 0.690850555896759\n",
            "Value 1580 Mean Loss: 5.430902540683746\n",
            "dones: tensor(23.)\n",
            "Policy 1581 Mean Loss: -0.006131846748758107\n",
            "Entropy 1581 Mean Loss: 0.6907797530293465\n",
            "Value 1581 Mean Loss: 4.40872985124588\n",
            "dones: tensor(17.)\n",
            "Policy 1582 Mean Loss: -0.008839272428303957\n",
            "Entropy 1582 Mean Loss: 0.6906262710690498\n",
            "Value 1582 Mean Loss: 3.9649529457092285\n",
            "dones: tensor(14.)\n",
            "Policy 1583 Mean Loss: -0.008994646603241563\n",
            "Entropy 1583 Mean Loss: 0.6905244924128056\n",
            "Value 1583 Mean Loss: 6.180674910545349\n",
            "dones: tensor(23.)\n",
            "Policy 1584 Mean Loss: -0.007349798805080354\n",
            "Entropy 1584 Mean Loss: 0.6906175538897514\n",
            "Value 1584 Mean Loss: 4.678063213825226\n",
            "dones: tensor(24.)\n",
            "Policy 1585 Mean Loss: -0.0064567484660074115\n",
            "Entropy 1585 Mean Loss: 0.6906076893210411\n",
            "Value 1585 Mean Loss: 5.384543538093567\n",
            "dones: tensor(22.)\n",
            "Policy 1586 Mean Loss: -0.00874994054902345\n",
            "Entropy 1586 Mean Loss: 0.6906294040381908\n",
            "Value 1586 Mean Loss: 4.386942222714424\n",
            "dones: tensor(19.)\n",
            "Policy 1587 Mean Loss: -0.009394766471814364\n",
            "Entropy 1587 Mean Loss: 0.6902399361133575\n",
            "Value 1587 Mean Loss: 4.545277625322342\n",
            "dones: tensor(28.)\n",
            "Policy 1588 Mean Loss: -0.007334248046390712\n",
            "Entropy 1588 Mean Loss: 0.6906059496104717\n",
            "Value 1588 Mean Loss: 5.098415791988373\n",
            "dones: tensor(23.)\n",
            "Policy 1589 Mean Loss: -0.010717902739997953\n",
            "Entropy 1589 Mean Loss: 0.6905742362141609\n",
            "Value 1589 Mean Loss: 4.792710915207863\n",
            "dones: tensor(21.)\n",
            "Policy 1590 Mean Loss: -0.0051709835533984005\n",
            "Entropy 1590 Mean Loss: 0.69066521525383\n",
            "Value 1590 Mean Loss: 5.205901861190796\n",
            "dones: tensor(22.)\n",
            "Policy 1591 Mean Loss: -0.008104065200313926\n",
            "Entropy 1591 Mean Loss: 0.6908954568207264\n",
            "Value 1591 Mean Loss: 4.578216090798378\n",
            "dones: tensor(25.)\n",
            "Policy 1592 Mean Loss: -0.004481755138840526\n",
            "Entropy 1592 Mean Loss: 0.690971776843071\n",
            "Value 1592 Mean Loss: 5.34119525551796\n",
            "dones: tensor(20.)\n",
            "Policy 1593 Mean Loss: -0.007860454206820577\n",
            "Entropy 1593 Mean Loss: 0.690688032656908\n",
            "Value 1593 Mean Loss: 4.767908066511154\n",
            "dones: tensor(21.)\n",
            "Policy 1594 Mean Loss: -0.004978471377398819\n",
            "Entropy 1594 Mean Loss: 0.6909508407115936\n",
            "Value 1594 Mean Loss: 4.815505638718605\n",
            "dones: tensor(26.)\n",
            "Policy 1595 Mean Loss: -0.005032945569837466\n",
            "Entropy 1595 Mean Loss: 0.6911661699414253\n",
            "Value 1595 Mean Loss: 4.981796711683273\n",
            "dones: tensor(25.)\n",
            "Policy 1596 Mean Loss: -0.008637595281470567\n",
            "Entropy 1596 Mean Loss: 0.6911109909415245\n",
            "Value 1596 Mean Loss: 4.920951247215271\n",
            "dones: tensor(24.)\n",
            "Policy 1597 Mean Loss: -0.0017586880130693316\n",
            "Entropy 1597 Mean Loss: 0.6909163519740105\n",
            "Value 1597 Mean Loss: 4.7802727818489075\n",
            "dones: tensor(24.)\n",
            "Policy 1598 Mean Loss: -0.005511229916010052\n",
            "Entropy 1598 Mean Loss: 0.6909429430961609\n",
            "Value 1598 Mean Loss: 4.524739861488342\n",
            "dones: tensor(28.)\n",
            "Policy 1599 Mean Loss: -0.00703015987528488\n",
            "Entropy 1599 Mean Loss: 0.691016785800457\n",
            "Value 1599 Mean Loss: 5.002200245857239\n",
            "dones: tensor(18.)\n",
            "Policy 1600 Mean Loss: -0.004177709110081196\n",
            "Entropy 1600 Mean Loss: 0.690800242125988\n",
            "Value 1600 Mean Loss: 4.239815220236778\n",
            "dones: tensor(23.)\n",
            "Policy 1601 Mean Loss: -0.0062793741235509515\n",
            "Entropy 1601 Mean Loss: 0.6908697299659252\n",
            "Value 1601 Mean Loss: 4.105588540434837\n",
            "dones: tensor(26.)\n",
            "Policy 1602 Mean Loss: -0.009198217128869146\n",
            "Entropy 1602 Mean Loss: 0.6905063614249229\n",
            "Value 1602 Mean Loss: 4.805863976478577\n",
            "dones: tensor(25.)\n",
            "Policy 1603 Mean Loss: -0.007308644475415349\n",
            "Entropy 1603 Mean Loss: 0.6907079629600048\n",
            "Value 1603 Mean Loss: 4.1932308077812195\n",
            "dones: tensor(23.)\n",
            "Policy 1604 Mean Loss: -0.004518615372944623\n",
            "Entropy 1604 Mean Loss: 0.6906051523983479\n",
            "Value 1604 Mean Loss: 4.3048088401556015\n",
            "dones: tensor(21.)\n",
            "Policy 1605 Mean Loss: -0.009181234752759337\n",
            "Entropy 1605 Mean Loss: 0.69047025218606\n",
            "Value 1605 Mean Loss: 3.9046854823827744\n",
            "dones: tensor(24.)\n",
            "Policy 1606 Mean Loss: -0.002646836976055056\n",
            "Entropy 1606 Mean Loss: 0.6907796114683151\n",
            "Value 1606 Mean Loss: 4.311725482344627\n",
            "dones: tensor(24.)\n",
            "Policy 1607 Mean Loss: -0.008285709714982659\n",
            "Entropy 1607 Mean Loss: 0.6909625567495823\n",
            "Value 1607 Mean Loss: 4.322110503911972\n",
            "dones: tensor(19.)\n",
            "Policy 1608 Mean Loss: -0.01064803940244019\n",
            "Entropy 1608 Mean Loss: 0.6908855363726616\n",
            "Value 1608 Mean Loss: 4.759936034679413\n",
            "dones: tensor(27.)\n",
            "Policy 1609 Mean Loss: -0.008317830739542842\n",
            "Entropy 1609 Mean Loss: 0.6910310909152031\n",
            "Value 1609 Mean Loss: 4.6488610208034515\n",
            "dones: tensor(24.)\n",
            "Policy 1610 Mean Loss: -0.005536500248126686\n",
            "Entropy 1610 Mean Loss: 0.6908803768455982\n",
            "Value 1610 Mean Loss: 4.4115913808345795\n",
            "dones: tensor(23.)\n",
            "Policy 1611 Mean Loss: -0.009264260239433497\n",
            "Entropy 1611 Mean Loss: 0.6906492635607719\n",
            "Value 1611 Mean Loss: 4.674940586090088\n",
            "dones: tensor(21.)\n",
            "Policy 1612 Mean Loss: -0.011297514021862298\n",
            "Entropy 1612 Mean Loss: 0.6904692873358727\n",
            "Value 1612 Mean Loss: 5.745096027851105\n",
            "dones: tensor(24.)\n",
            "Policy 1613 Mean Loss: -0.010242033225949854\n",
            "Entropy 1613 Mean Loss: 0.6906777396798134\n",
            "Value 1613 Mean Loss: 4.074528530240059\n",
            "dones: tensor(24.)\n",
            "Policy 1614 Mean Loss: -0.004135586612392217\n",
            "Entropy 1614 Mean Loss: 0.6907116547226906\n",
            "Value 1614 Mean Loss: 4.329830914735794\n",
            "dones: tensor(22.)\n",
            "Policy 1615 Mean Loss: -0.0055297904764302075\n",
            "Entropy 1615 Mean Loss: 0.6907137520611286\n",
            "Value 1615 Mean Loss: 4.412747740745544\n",
            "dones: tensor(20.)\n",
            "Policy 1616 Mean Loss: -0.01369852281641215\n",
            "Entropy 1616 Mean Loss: 0.6907827146351337\n",
            "Value 1616 Mean Loss: 4.630492717027664\n",
            "dones: tensor(22.)\n",
            "Policy 1617 Mean Loss: -0.0071059001493267715\n",
            "Entropy 1617 Mean Loss: 0.6907201409339905\n",
            "Value 1617 Mean Loss: 4.586678177118301\n",
            "dones: tensor(22.)\n",
            "Policy 1618 Mean Loss: -0.008315544691868126\n",
            "Entropy 1618 Mean Loss: 0.6907980777323246\n",
            "Value 1618 Mean Loss: 4.3001948446035385\n",
            "dones: tensor(22.)\n",
            "Policy 1619 Mean Loss: -0.003688886237796396\n",
            "Entropy 1619 Mean Loss: 0.6908674947917461\n",
            "Value 1619 Mean Loss: 4.807788282632828\n",
            "dones: tensor(19.)\n",
            "Policy 1620 Mean Loss: -0.00893829733831808\n",
            "Entropy 1620 Mean Loss: 0.6907196156680584\n",
            "Value 1620 Mean Loss: 3.974275588989258\n",
            "dones: tensor(24.)\n",
            "Policy 1621 Mean Loss: -0.006228376179933548\n",
            "Entropy 1621 Mean Loss: 0.6908205784857273\n",
            "Value 1621 Mean Loss: 5.360213816165924\n",
            "dones: tensor(24.)\n",
            "Policy 1622 Mean Loss: -0.00863201031461358\n",
            "Entropy 1622 Mean Loss: 0.6906638629734516\n",
            "Value 1622 Mean Loss: 4.913510829210281\n",
            "dones: tensor(28.)\n",
            "Policy 1623 Mean Loss: -0.0033428440801799297\n",
            "Entropy 1623 Mean Loss: 0.6909567527472973\n",
            "Value 1623 Mean Loss: 4.768828749656677\n",
            "dones: tensor(24.)\n",
            "Policy 1624 Mean Loss: -0.0064453124068677425\n",
            "Entropy 1624 Mean Loss: 0.6910409890115261\n",
            "Value 1624 Mean Loss: 4.501350611448288\n",
            "dones: tensor(26.)\n",
            "Policy 1625 Mean Loss: -0.0027502041193656623\n",
            "Entropy 1625 Mean Loss: 0.6910916939377785\n",
            "Value 1625 Mean Loss: 4.865453541278839\n",
            "dones: tensor(21.)\n",
            "Policy 1626 Mean Loss: -0.006755697540938854\n",
            "Entropy 1626 Mean Loss: 0.6908309608697891\n",
            "Value 1626 Mean Loss: 4.040575489401817\n",
            "dones: tensor(24.)\n",
            "Policy 1627 Mean Loss: -0.005246274231467396\n",
            "Entropy 1627 Mean Loss: 0.6908903494477272\n",
            "Value 1627 Mean Loss: 4.142341196537018\n",
            "dones: tensor(26.)\n",
            "Policy 1628 Mean Loss: -0.007751278462819755\n",
            "Entropy 1628 Mean Loss: 0.6908555924892426\n",
            "Value 1628 Mean Loss: 4.608691930770874\n",
            "dones: tensor(22.)\n",
            "Policy 1629 Mean Loss: -0.008475416572764516\n",
            "Entropy 1629 Mean Loss: 0.6908552162349224\n",
            "Value 1629 Mean Loss: 4.364053636789322\n",
            "dones: tensor(22.)\n",
            "Policy 1630 Mean Loss: -0.010330264107324183\n",
            "Entropy 1630 Mean Loss: 0.6907335333526134\n",
            "Value 1630 Mean Loss: 3.8714578598737717\n",
            "dones: tensor(23.)\n",
            "Policy 1631 Mean Loss: -0.009614640614017844\n",
            "Entropy 1631 Mean Loss: 0.6907676830887794\n",
            "Value 1631 Mean Loss: 4.225042894482613\n",
            "dones: tensor(18.)\n",
            "Policy 1632 Mean Loss: -0.004374620213638991\n",
            "Entropy 1632 Mean Loss: 0.6906451620161533\n",
            "Value 1632 Mean Loss: 3.7466631084680557\n",
            "dones: tensor(20.)\n",
            "Policy 1633 Mean Loss: -0.005888960382435471\n",
            "Entropy 1633 Mean Loss: 0.6906704269349575\n",
            "Value 1633 Mean Loss: 3.816960036754608\n",
            "dones: tensor(19.)\n",
            "Policy 1634 Mean Loss: -0.004726440645754337\n",
            "Entropy 1634 Mean Loss: 0.6908918395638466\n",
            "Value 1634 Mean Loss: 4.699894681572914\n",
            "dones: tensor(21.)\n",
            "Policy 1635 Mean Loss: -0.010075998899992555\n",
            "Entropy 1635 Mean Loss: 0.6908634565770626\n",
            "Value 1635 Mean Loss: 5.053687006235123\n",
            "dones: tensor(24.)\n",
            "Policy 1636 Mean Loss: -0.003361601149663329\n",
            "Entropy 1636 Mean Loss: 0.6911491081118584\n",
            "Value 1636 Mean Loss: 4.741210430860519\n",
            "dones: tensor(23.)\n",
            "Policy 1637 Mean Loss: -0.0027645238442346454\n",
            "Entropy 1637 Mean Loss: 0.6908868476748466\n",
            "Value 1637 Mean Loss: 4.28323794901371\n",
            "dones: tensor(22.)\n",
            "Policy 1638 Mean Loss: -0.005618827883154154\n",
            "Entropy 1638 Mean Loss: 0.6909804195165634\n",
            "Value 1638 Mean Loss: 4.011917844414711\n",
            "dones: tensor(21.)\n",
            "Policy 1639 Mean Loss: -0.0043719151872210205\n",
            "Entropy 1639 Mean Loss: 0.6907325014472008\n",
            "Value 1639 Mean Loss: 4.57942733168602\n",
            "dones: tensor(23.)\n",
            "Policy 1640 Mean Loss: -0.007248056877870113\n",
            "Entropy 1640 Mean Loss: 0.6907908096909523\n",
            "Value 1640 Mean Loss: 4.628848746418953\n",
            "dones: tensor(22.)\n",
            "Policy 1641 Mean Loss: -0.006643592671025544\n",
            "Entropy 1641 Mean Loss: 0.6907849609851837\n",
            "Value 1641 Mean Loss: 4.562668278813362\n",
            "dones: tensor(24.)\n",
            "Policy 1642 Mean Loss: -0.004709073400590569\n",
            "Entropy 1642 Mean Loss: 0.6910376474261284\n",
            "Value 1642 Mean Loss: 5.070732593536377\n",
            "dones: tensor(16.)\n",
            "Policy 1643 Mean Loss: -0.0073430214542895555\n",
            "Entropy 1643 Mean Loss: 0.6903969310224056\n",
            "Value 1643 Mean Loss: 4.072178229689598\n",
            "dones: tensor(17.)\n",
            "Policy 1644 Mean Loss: -0.002589092415291816\n",
            "Entropy 1644 Mean Loss: 0.6908256895840168\n",
            "Value 1644 Mean Loss: 4.362284645438194\n",
            "dones: tensor(20.)\n",
            "Policy 1645 Mean Loss: -0.009511767071671784\n",
            "Entropy 1645 Mean Loss: 0.6905864849686623\n",
            "Value 1645 Mean Loss: 4.367765367031097\n",
            "dones: tensor(24.)\n",
            "Policy 1646 Mean Loss: -0.005404425028245896\n",
            "Entropy 1646 Mean Loss: 0.6911216489970684\n",
            "Value 1646 Mean Loss: 4.771197333931923\n",
            "dones: tensor(22.)\n",
            "Policy 1647 Mean Loss: -0.008814658154733479\n",
            "Entropy 1647 Mean Loss: 0.690872672945261\n",
            "Value 1647 Mean Loss: 4.779155373573303\n",
            "dones: tensor(21.)\n",
            "Policy 1648 Mean Loss: -0.0064164159703068435\n",
            "Entropy 1648 Mean Loss: 0.69059619307518\n",
            "Value 1648 Mean Loss: 4.517864227294922\n",
            "dones: tensor(22.)\n",
            "Policy 1649 Mean Loss: -0.005433927464764565\n",
            "Entropy 1649 Mean Loss: 0.6907315105199814\n",
            "Value 1649 Mean Loss: 4.473829850554466\n",
            "dones: tensor(20.)\n",
            "Policy 1650 Mean Loss: -0.006646102876402438\n",
            "Entropy 1650 Mean Loss: 0.6909413449466228\n",
            "Value 1650 Mean Loss: 4.172577455639839\n",
            "dones: tensor(23.)\n",
            "Policy 1651 Mean Loss: -0.004088750807568431\n",
            "Entropy 1651 Mean Loss: 0.6907010823488235\n",
            "Value 1651 Mean Loss: 4.543330192565918\n",
            "dones: tensor(24.)\n",
            "Policy 1652 Mean Loss: 0.0012296951026655734\n",
            "Entropy 1652 Mean Loss: 0.6909557580947876\n",
            "Value 1652 Mean Loss: 4.78438064455986\n",
            "dones: tensor(22.)\n",
            "Policy 1653 Mean Loss: -0.009747291158419102\n",
            "Entropy 1653 Mean Loss: 0.6908229179680347\n",
            "Value 1653 Mean Loss: 4.0782460719347\n",
            "dones: tensor(22.)\n",
            "Policy 1654 Mean Loss: -0.004796461958903819\n",
            "Entropy 1654 Mean Loss: 0.6910417154431343\n",
            "Value 1654 Mean Loss: 4.371867462992668\n",
            "dones: tensor(24.)\n",
            "Policy 1655 Mean Loss: -0.00695429474581033\n",
            "Entropy 1655 Mean Loss: 0.6908441558480263\n",
            "Value 1655 Mean Loss: 4.724740356206894\n",
            "dones: tensor(24.)\n",
            "Policy 1656 Mean Loss: -0.006620601227041334\n",
            "Entropy 1656 Mean Loss: 0.6908862851560116\n",
            "Value 1656 Mean Loss: 4.7725570499897\n",
            "dones: tensor(25.)\n",
            "Policy 1657 Mean Loss: -0.009797661157790571\n",
            "Entropy 1657 Mean Loss: 0.6908034235239029\n",
            "Value 1657 Mean Loss: 4.713626116514206\n",
            "dones: tensor(26.)\n",
            "Policy 1658 Mean Loss: -0.0032930264715105295\n",
            "Entropy 1658 Mean Loss: 0.6909066177904606\n",
            "Value 1658 Mean Loss: 4.584719330072403\n",
            "dones: tensor(23.)\n",
            "Policy 1659 Mean Loss: -0.006115741096436977\n",
            "Entropy 1659 Mean Loss: 0.6907673254609108\n",
            "Value 1659 Mean Loss: 4.011517196893692\n",
            "dones: tensor(26.)\n",
            "Policy 1660 Mean Loss: -0.004585223650792614\n",
            "Entropy 1660 Mean Loss: 0.6911795884370804\n",
            "Value 1660 Mean Loss: 4.596677511930466\n",
            "dones: tensor(19.)\n",
            "Policy 1661 Mean Loss: -0.005605406826362014\n",
            "Entropy 1661 Mean Loss: 0.6907686553895473\n",
            "Value 1661 Mean Loss: 4.380974322557449\n",
            "dones: tensor(20.)\n",
            "Policy 1662 Mean Loss: -0.006916102371178567\n",
            "Entropy 1662 Mean Loss: 0.690719485282898\n",
            "Value 1662 Mean Loss: 4.160996302962303\n",
            "dones: tensor(20.)\n",
            "Policy 1663 Mean Loss: -0.0034396580304019153\n",
            "Entropy 1663 Mean Loss: 0.6909388452768326\n",
            "Value 1663 Mean Loss: 4.809916198253632\n",
            "dones: tensor(18.)\n",
            "Policy 1664 Mean Loss: -0.005868235428351909\n",
            "Entropy 1664 Mean Loss: 0.6907224729657173\n",
            "Value 1664 Mean Loss: 4.194254547357559\n",
            "dones: tensor(18.)\n",
            "Policy 1665 Mean Loss: -0.006900601787492633\n",
            "Entropy 1665 Mean Loss: 0.6906327679753304\n",
            "Value 1665 Mean Loss: 3.8348372131586075\n",
            "dones: tensor(28.)\n",
            "Policy 1666 Mean Loss: -0.006613306875806302\n",
            "Entropy 1666 Mean Loss: 0.6912277154624462\n",
            "Value 1666 Mean Loss: 5.16720986366272\n",
            "dones: tensor(17.)\n",
            "Policy 1667 Mean Loss: -0.007448514632415026\n",
            "Entropy 1667 Mean Loss: 0.6907820701599121\n",
            "Value 1667 Mean Loss: 3.4726081490516663\n",
            "dones: tensor(23.)\n",
            "Policy 1668 Mean Loss: -0.003348780097439885\n",
            "Entropy 1668 Mean Loss: 0.6910141967236996\n",
            "Value 1668 Mean Loss: 4.292148485779762\n",
            "dones: tensor(22.)\n",
            "Policy 1669 Mean Loss: -0.005968799989204854\n",
            "Entropy 1669 Mean Loss: 0.6907181553542614\n",
            "Value 1669 Mean Loss: 4.408458828926086\n",
            "dones: tensor(17.)\n",
            "Policy 1670 Mean Loss: -0.003609862644225359\n",
            "Entropy 1670 Mean Loss: 0.6907899603247643\n",
            "Value 1670 Mean Loss: 4.370115771889687\n",
            "dones: tensor(18.)\n",
            "Policy 1671 Mean Loss: -0.004218096029944718\n",
            "Entropy 1671 Mean Loss: 0.6909105256199837\n",
            "Value 1671 Mean Loss: 4.37755474448204\n",
            "dones: tensor(21.)\n",
            "Policy 1672 Mean Loss: -0.00572909030597657\n",
            "Entropy 1672 Mean Loss: 0.6907954774796963\n",
            "Value 1672 Mean Loss: 3.7907611280679703\n",
            "dones: tensor(22.)\n",
            "Policy 1673 Mean Loss: -0.007861790363676846\n",
            "Entropy 1673 Mean Loss: 0.6907918229699135\n",
            "Value 1673 Mean Loss: 4.909596234560013\n",
            "dones: tensor(25.)\n",
            "Policy 1674 Mean Loss: -0.008670923241879791\n",
            "Entropy 1674 Mean Loss: 0.6909206248819828\n",
            "Value 1674 Mean Loss: 4.580891370773315\n",
            "dones: tensor(21.)\n",
            "Policy 1675 Mean Loss: -0.0001317837741225958\n",
            "Entropy 1675 Mean Loss: 0.690741129219532\n",
            "Value 1675 Mean Loss: 4.266392648220062\n",
            "dones: tensor(25.)\n",
            "Policy 1676 Mean Loss: -0.005271604051813483\n",
            "Entropy 1676 Mean Loss: 0.6907887011766434\n",
            "Value 1676 Mean Loss: 4.801155149936676\n",
            "dones: tensor(23.)\n",
            "Policy 1677 Mean Loss: -0.009301565063651651\n",
            "Entropy 1677 Mean Loss: 0.6905283145606518\n",
            "Value 1677 Mean Loss: 4.828699439764023\n",
            "dones: tensor(26.)\n",
            "Policy 1678 Mean Loss: -0.006492930639069527\n",
            "Entropy 1678 Mean Loss: 0.6905409097671509\n",
            "Value 1678 Mean Loss: 4.832322508096695\n",
            "dones: tensor(23.)\n",
            "Policy 1679 Mean Loss: -0.009052767039975151\n",
            "Entropy 1679 Mean Loss: 0.6902597099542618\n",
            "Value 1679 Mean Loss: 4.155126646161079\n",
            "dones: tensor(23.)\n",
            "Policy 1680 Mean Loss: -0.012172739545349032\n",
            "Entropy 1680 Mean Loss: 0.690072987228632\n",
            "Value 1680 Mean Loss: 4.314075484871864\n",
            "dones: tensor(20.)\n",
            "Policy 1681 Mean Loss: -0.00356813584221527\n",
            "Entropy 1681 Mean Loss: 0.6902189888060093\n",
            "Value 1681 Mean Loss: 4.389747202396393\n",
            "dones: tensor(28.)\n",
            "Policy 1682 Mean Loss: -0.010926900140475482\n",
            "Entropy 1682 Mean Loss: 0.6903878934681416\n",
            "Value 1682 Mean Loss: 5.256725907325745\n",
            "dones: tensor(23.)\n",
            "Policy 1683 Mean Loss: -0.009316244686488062\n",
            "Entropy 1683 Mean Loss: 0.6902588829398155\n",
            "Value 1683 Mean Loss: 4.096849113702774\n",
            "dones: tensor(21.)\n",
            "Policy 1684 Mean Loss: -0.00918615108821541\n",
            "Entropy 1684 Mean Loss: 0.6902127787470818\n",
            "Value 1684 Mean Loss: 4.049167349934578\n",
            "dones: tensor(26.)\n",
            "Policy 1685 Mean Loss: -0.00934728715219535\n",
            "Entropy 1685 Mean Loss: 0.6906243190169334\n",
            "Value 1685 Mean Loss: 4.438318997621536\n",
            "dones: tensor(19.)\n",
            "Policy 1686 Mean Loss: -0.0029888737481087446\n",
            "Entropy 1686 Mean Loss: 0.6904662549495697\n",
            "Value 1686 Mean Loss: 3.978217214345932\n",
            "dones: tensor(25.)\n",
            "Policy 1687 Mean Loss: -0.007802409469150007\n",
            "Entropy 1687 Mean Loss: 0.6905481293797493\n",
            "Value 1687 Mean Loss: 4.3575053215026855\n",
            "dones: tensor(22.)\n",
            "Policy 1688 Mean Loss: -0.010651858465280384\n",
            "Entropy 1688 Mean Loss: 0.6907783895730972\n",
            "Value 1688 Mean Loss: 4.442375257611275\n",
            "dones: tensor(22.)\n",
            "Policy 1689 Mean Loss: -0.004842746362555772\n",
            "Entropy 1689 Mean Loss: 0.6907518394291401\n",
            "Value 1689 Mean Loss: 4.462591916322708\n",
            "dones: tensor(23.)\n",
            "Policy 1690 Mean Loss: -0.007098346599377692\n",
            "Entropy 1690 Mean Loss: 0.6905821412801743\n",
            "Value 1690 Mean Loss: 4.1513380110263824\n",
            "dones: tensor(22.)\n",
            "Policy 1691 Mean Loss: -0.008109443297144026\n",
            "Entropy 1691 Mean Loss: 0.6907679997384548\n",
            "Value 1691 Mean Loss: 4.543881386518478\n",
            "dones: tensor(24.)\n",
            "Policy 1692 Mean Loss: -0.008001458481885493\n",
            "Entropy 1692 Mean Loss: 0.6908132284879684\n",
            "Value 1692 Mean Loss: 4.685022056102753\n",
            "dones: tensor(18.)\n",
            "Policy 1693 Mean Loss: -0.005998858599923551\n",
            "Entropy 1693 Mean Loss: 0.6905029267072678\n",
            "Value 1693 Mean Loss: 4.310880213975906\n",
            "dones: tensor(21.)\n",
            "Policy 1694 Mean Loss: -0.007394099433440715\n",
            "Entropy 1694 Mean Loss: 0.6907204203307629\n",
            "Value 1694 Mean Loss: 4.552563741803169\n",
            "dones: tensor(20.)\n",
            "Policy 1695 Mean Loss: -0.006589683587662876\n",
            "Entropy 1695 Mean Loss: 0.6905976608395576\n",
            "Value 1695 Mean Loss: 4.124015793204308\n",
            "dones: tensor(23.)\n",
            "Policy 1696 Mean Loss: -0.005347468890249729\n",
            "Entropy 1696 Mean Loss: 0.6908491067588329\n",
            "Value 1696 Mean Loss: 4.47197750210762\n",
            "dones: tensor(23.)\n",
            "Policy 1697 Mean Loss: -0.007006886240560561\n",
            "Entropy 1697 Mean Loss: 0.6909354105591774\n",
            "Value 1697 Mean Loss: 4.339762657880783\n",
            "dones: tensor(21.)\n",
            "Policy 1698 Mean Loss: -0.005897918133996427\n",
            "Entropy 1698 Mean Loss: 0.690925769507885\n",
            "Value 1698 Mean Loss: 4.626584410667419\n",
            "dones: tensor(24.)\n",
            "Policy 1699 Mean Loss: -0.008796578622423112\n",
            "Entropy 1699 Mean Loss: 0.6911862157285213\n",
            "Value 1699 Mean Loss: 4.300826758146286\n",
            "dones: tensor(20.)\n",
            "Policy 1700 Mean Loss: -0.003337786882184446\n",
            "Entropy 1700 Mean Loss: 0.6908479183912277\n",
            "Value 1700 Mean Loss: 4.332948923110962\n",
            "dones: tensor(22.)\n",
            "Policy 1701 Mean Loss: -0.003906512749381363\n",
            "Entropy 1701 Mean Loss: 0.6910220459103584\n",
            "Value 1701 Mean Loss: 3.7099754065275192\n",
            "dones: tensor(24.)\n",
            "Policy 1702 Mean Loss: -0.0035817630705423653\n",
            "Entropy 1702 Mean Loss: 0.691034521907568\n",
            "Value 1702 Mean Loss: 4.760245770215988\n",
            "dones: tensor(21.)\n",
            "Policy 1703 Mean Loss: -0.008982093539088964\n",
            "Entropy 1703 Mean Loss: 0.6908988989889622\n",
            "Value 1703 Mean Loss: 3.983728215098381\n",
            "dones: tensor(21.)\n",
            "Policy 1704 Mean Loss: -0.004644642525818199\n",
            "Entropy 1704 Mean Loss: 0.690928477793932\n",
            "Value 1704 Mean Loss: 4.599619835615158\n",
            "dones: tensor(26.)\n",
            "Policy 1705 Mean Loss: -0.0031666479189880192\n",
            "Entropy 1705 Mean Loss: 0.6911431588232517\n",
            "Value 1705 Mean Loss: 4.825749546289444\n",
            "dones: tensor(21.)\n",
            "Policy 1706 Mean Loss: -0.007321379031054676\n",
            "Entropy 1706 Mean Loss: 0.6911015249788761\n",
            "Value 1706 Mean Loss: 5.056488752365112\n",
            "dones: tensor(27.)\n",
            "Policy 1707 Mean Loss: -0.008627190429251641\n",
            "Entropy 1707 Mean Loss: 0.6912917159497738\n",
            "Value 1707 Mean Loss: 4.84513521194458\n",
            "dones: tensor(25.)\n",
            "Policy 1708 Mean Loss: -0.008155253017321229\n",
            "Entropy 1708 Mean Loss: 0.6909369714558125\n",
            "Value 1708 Mean Loss: 4.548558548092842\n",
            "dones: tensor(24.)\n",
            "Policy 1709 Mean Loss: -0.008643090492114425\n",
            "Entropy 1709 Mean Loss: 0.691033273935318\n",
            "Value 1709 Mean Loss: 4.901240408420563\n",
            "dones: tensor(26.)\n",
            "Policy 1710 Mean Loss: -0.002806501928716898\n",
            "Entropy 1710 Mean Loss: 0.6912103928625584\n",
            "Value 1710 Mean Loss: 5.166913062334061\n",
            "dones: tensor(19.)\n",
            "Policy 1711 Mean Loss: -0.0060279922327026725\n",
            "Entropy 1711 Mean Loss: 0.6908980123698711\n",
            "Value 1711 Mean Loss: 3.7243731170892715\n",
            "dones: tensor(21.)\n",
            "Policy 1712 Mean Loss: -0.00610924739157781\n",
            "Entropy 1712 Mean Loss: 0.690823819488287\n",
            "Value 1712 Mean Loss: 3.933691531419754\n",
            "dones: tensor(23.)\n",
            "Policy 1713 Mean Loss: -0.0065943393856287\n",
            "Entropy 1713 Mean Loss: 0.6911138780415058\n",
            "Value 1713 Mean Loss: 4.1328244805336\n",
            "dones: tensor(26.)\n",
            "Policy 1714 Mean Loss: -0.002736165886744857\n",
            "Entropy 1714 Mean Loss: 0.691153958439827\n",
            "Value 1714 Mean Loss: 4.855775237083435\n",
            "dones: tensor(25.)\n",
            "Policy 1715 Mean Loss: -0.0044426885433495045\n",
            "Entropy 1715 Mean Loss: 0.6910407729446888\n",
            "Value 1715 Mean Loss: 4.677611410617828\n",
            "dones: tensor(21.)\n",
            "Policy 1716 Mean Loss: -0.0074033334967680275\n",
            "Entropy 1716 Mean Loss: 0.6907407492399216\n",
            "Value 1716 Mean Loss: 4.485729604959488\n",
            "dones: tensor(22.)\n",
            "Policy 1717 Mean Loss: -0.011344930186169222\n",
            "Entropy 1717 Mean Loss: 0.6907673291862011\n",
            "Value 1717 Mean Loss: 4.384742930531502\n",
            "dones: tensor(22.)\n",
            "Policy 1718 Mean Loss: -0.005493584205396473\n",
            "Entropy 1718 Mean Loss: 0.6909157074987888\n",
            "Value 1718 Mean Loss: 4.088567480444908\n",
            "dones: tensor(27.)\n",
            "Policy 1719 Mean Loss: -0.01158184336964041\n",
            "Entropy 1719 Mean Loss: 0.6909545436501503\n",
            "Value 1719 Mean Loss: 4.931416362524033\n",
            "dones: tensor(24.)\n",
            "Policy 1720 Mean Loss: -0.004183819051831961\n",
            "Entropy 1720 Mean Loss: 0.6908863224089146\n",
            "Value 1720 Mean Loss: 4.810852110385895\n",
            "dones: tensor(21.)\n",
            "Policy 1721 Mean Loss: -0.005895817186683416\n",
            "Entropy 1721 Mean Loss: 0.6905917190015316\n",
            "Value 1721 Mean Loss: 4.79105070233345\n",
            "dones: tensor(29.)\n",
            "Policy 1722 Mean Loss: -7.522007217630744e-05\n",
            "Entropy 1722 Mean Loss: 0.690980289131403\n",
            "Value 1722 Mean Loss: 5.105628699064255\n",
            "dones: tensor(22.)\n",
            "Policy 1723 Mean Loss: -0.005184865673072636\n",
            "Entropy 1723 Mean Loss: 0.6906641386449337\n",
            "Value 1723 Mean Loss: 4.292848125100136\n",
            "dones: tensor(21.)\n",
            "Policy 1724 Mean Loss: -0.004610352450981736\n",
            "Entropy 1724 Mean Loss: 0.6909177601337433\n",
            "Value 1724 Mean Loss: 4.236871898174286\n",
            "dones: tensor(22.)\n",
            "Policy 1725 Mean Loss: -0.006693660165183246\n",
            "Entropy 1725 Mean Loss: 0.6908635348081589\n",
            "Value 1725 Mean Loss: 4.198714911937714\n",
            "dones: tensor(26.)\n",
            "Policy 1726 Mean Loss: -0.010204600635915995\n",
            "Entropy 1726 Mean Loss: 0.6907580457627773\n",
            "Value 1726 Mean Loss: 5.12877956032753\n",
            "dones: tensor(22.)\n",
            "Policy 1727 Mean Loss: -0.014101999811828136\n",
            "Entropy 1727 Mean Loss: 0.6903752908110619\n",
            "Value 1727 Mean Loss: 4.516986191272736\n",
            "dones: tensor(23.)\n",
            "Policy 1728 Mean Loss: -0.002826716285198927\n",
            "Entropy 1728 Mean Loss: 0.690630104392767\n",
            "Value 1728 Mean Loss: 5.2832053899765015\n",
            "dones: tensor(24.)\n",
            "Policy 1729 Mean Loss: -0.008852712519001216\n",
            "Entropy 1729 Mean Loss: 0.690818190574646\n",
            "Value 1729 Mean Loss: 5.234932333230972\n",
            "dones: tensor(23.)\n",
            "Policy 1730 Mean Loss: -0.0070065626641735435\n",
            "Entropy 1730 Mean Loss: 0.6904407925903797\n",
            "Value 1730 Mean Loss: 4.472207501530647\n",
            "dones: tensor(21.)\n",
            "Policy 1731 Mean Loss: -0.006616804050281644\n",
            "Entropy 1731 Mean Loss: 0.6905596479773521\n",
            "Value 1731 Mean Loss: 4.247470706701279\n",
            "dones: tensor(24.)\n",
            "Policy 1732 Mean Loss: -0.00552156928461045\n",
            "Entropy 1732 Mean Loss: 0.6908482387661934\n",
            "Value 1732 Mean Loss: 4.7141935378313065\n",
            "dones: tensor(24.)\n",
            "Policy 1733 Mean Loss: -0.0073291860753670335\n",
            "Entropy 1733 Mean Loss: 0.6907407566905022\n",
            "Value 1733 Mean Loss: 4.670010909438133\n",
            "dones: tensor(24.)\n",
            "Policy 1734 Mean Loss: -0.003076201945077628\n",
            "Entropy 1734 Mean Loss: 0.6909804381430149\n",
            "Value 1734 Mean Loss: 4.882083922624588\n",
            "dones: tensor(23.)\n",
            "Policy 1735 Mean Loss: -0.005912462016567588\n",
            "Entropy 1735 Mean Loss: 0.6909522339701653\n",
            "Value 1735 Mean Loss: 4.741617769002914\n",
            "dones: tensor(23.)\n",
            "Policy 1736 Mean Loss: -0.009876526892185211\n",
            "Entropy 1736 Mean Loss: 0.6906914412975311\n",
            "Value 1736 Mean Loss: 4.506169378757477\n",
            "dones: tensor(23.)\n",
            "Policy 1737 Mean Loss: -0.008109205460641533\n",
            "Entropy 1737 Mean Loss: 0.6904570870101452\n",
            "Value 1737 Mean Loss: 4.83777117729187\n",
            "dones: tensor(28.)\n",
            "Policy 1738 Mean Loss: -0.007173515157774091\n",
            "Entropy 1738 Mean Loss: 0.6906347274780273\n",
            "Value 1738 Mean Loss: 5.547958046197891\n",
            "dones: tensor(23.)\n",
            "Policy 1739 Mean Loss: -0.009818031103350222\n",
            "Entropy 1739 Mean Loss: 0.6907464936375618\n",
            "Value 1739 Mean Loss: 4.613212198019028\n",
            "dones: tensor(20.)\n",
            "Policy 1740 Mean Loss: -0.009769058611709625\n",
            "Entropy 1740 Mean Loss: 0.6906611062586308\n",
            "Value 1740 Mean Loss: 4.374998107552528\n",
            "dones: tensor(21.)\n",
            "Policy 1741 Mean Loss: -0.008959937025792897\n",
            "Entropy 1741 Mean Loss: 0.6905786208808422\n",
            "Value 1741 Mean Loss: 3.8696360737085342\n",
            "dones: tensor(22.)\n",
            "Policy 1742 Mean Loss: -0.00911883485969156\n",
            "Entropy 1742 Mean Loss: 0.6904609762132168\n",
            "Value 1742 Mean Loss: 4.1107285767793655\n",
            "dones: tensor(27.)\n",
            "Policy 1743 Mean Loss: -0.006285543029662222\n",
            "Entropy 1743 Mean Loss: 0.6907467059791088\n",
            "Value 1743 Mean Loss: 4.783131554722786\n",
            "dones: tensor(17.)\n",
            "Policy 1744 Mean Loss: -0.00412848248379305\n",
            "Entropy 1744 Mean Loss: 0.6903136856853962\n",
            "Value 1744 Mean Loss: 3.7459303438663483\n",
            "dones: tensor(24.)\n",
            "Policy 1745 Mean Loss: -0.010352248209528625\n",
            "Entropy 1745 Mean Loss: 0.6904951892793179\n",
            "Value 1745 Mean Loss: 4.538801088929176\n",
            "dones: tensor(22.)\n",
            "Policy 1746 Mean Loss: -0.008848062774632126\n",
            "Entropy 1746 Mean Loss: 0.6903932765126228\n",
            "Value 1746 Mean Loss: 3.8766412287950516\n",
            "dones: tensor(26.)\n",
            "Policy 1747 Mean Loss: -0.00884609716013074\n",
            "Entropy 1747 Mean Loss: 0.6908523440361023\n",
            "Value 1747 Mean Loss: 4.49266891181469\n",
            "dones: tensor(22.)\n",
            "Policy 1748 Mean Loss: -0.004604673304129392\n",
            "Entropy 1748 Mean Loss: 0.6903669945895672\n",
            "Value 1748 Mean Loss: 4.755907207727432\n",
            "dones: tensor(21.)\n",
            "Policy 1749 Mean Loss: -0.00710179447196424\n",
            "Entropy 1749 Mean Loss: 0.6904707737267017\n",
            "Value 1749 Mean Loss: 4.304561331868172\n",
            "dones: tensor(23.)\n",
            "Policy 1750 Mean Loss: -0.007748476171400398\n",
            "Entropy 1750 Mean Loss: 0.6904623955488205\n",
            "Value 1750 Mean Loss: 4.263853430747986\n",
            "dones: tensor(25.)\n",
            "Policy 1751 Mean Loss: -0.011994787433650345\n",
            "Entropy 1751 Mean Loss: 0.6906698942184448\n",
            "Value 1751 Mean Loss: 4.249067932367325\n",
            "dones: tensor(23.)\n",
            "Policy 1752 Mean Loss: -0.005763779685366899\n",
            "Entropy 1752 Mean Loss: 0.6905621103942394\n",
            "Value 1752 Mean Loss: 4.340061768889427\n",
            "dones: tensor(24.)\n",
            "Policy 1753 Mean Loss: -0.003100467612966895\n",
            "Entropy 1753 Mean Loss: 0.6906404048204422\n",
            "Value 1753 Mean Loss: 5.0570937395095825\n",
            "dones: tensor(19.)\n",
            "Policy 1754 Mean Loss: -0.007046482583973557\n",
            "Entropy 1754 Mean Loss: 0.6904508732259274\n",
            "Value 1754 Mean Loss: 3.4984587281942368\n",
            "dones: tensor(26.)\n",
            "Policy 1755 Mean Loss: -0.004479314899072051\n",
            "Entropy 1755 Mean Loss: 0.6907166577875614\n",
            "Value 1755 Mean Loss: 4.930706769227982\n",
            "dones: tensor(26.)\n",
            "Policy 1756 Mean Loss: -0.00634646974503994\n",
            "Entropy 1756 Mean Loss: 0.6907771602272987\n",
            "Value 1756 Mean Loss: 4.437785103917122\n",
            "dones: tensor(21.)\n",
            "Policy 1757 Mean Loss: -0.00973016070201993\n",
            "Entropy 1757 Mean Loss: 0.6905074454843998\n",
            "Value 1757 Mean Loss: 4.284528598189354\n",
            "dones: tensor(24.)\n",
            "Policy 1758 Mean Loss: -0.0058476312551647425\n",
            "Entropy 1758 Mean Loss: 0.6906271427869797\n",
            "Value 1758 Mean Loss: 4.704280704259872\n",
            "dones: tensor(26.)\n",
            "Policy 1759 Mean Loss: -0.005468326970003545\n",
            "Entropy 1759 Mean Loss: 0.6905772835016251\n",
            "Value 1759 Mean Loss: 4.61565899848938\n",
            "dones: tensor(20.)\n",
            "Policy 1760 Mean Loss: -0.008770202286541462\n",
            "Entropy 1760 Mean Loss: 0.6903977654874325\n",
            "Value 1760 Mean Loss: 4.508761763572693\n",
            "dones: tensor(21.)\n",
            "Policy 1761 Mean Loss: -0.00023528211750090122\n",
            "Entropy 1761 Mean Loss: 0.6907406561076641\n",
            "Value 1761 Mean Loss: 4.21480593085289\n",
            "dones: tensor(18.)\n",
            "Policy 1762 Mean Loss: -0.005029126303270459\n",
            "Entropy 1762 Mean Loss: 0.6905377209186554\n",
            "Value 1762 Mean Loss: 4.644337743520737\n",
            "dones: tensor(22.)\n",
            "Policy 1763 Mean Loss: -0.0001132393954321742\n",
            "Entropy 1763 Mean Loss: 0.6907329000532627\n",
            "Value 1763 Mean Loss: 4.118774086236954\n",
            "dones: tensor(25.)\n",
            "Policy 1764 Mean Loss: -0.006895954255014658\n",
            "Entropy 1764 Mean Loss: 0.6909796968102455\n",
            "Value 1764 Mean Loss: 4.503436595201492\n",
            "dones: tensor(20.)\n",
            "Policy 1765 Mean Loss: -0.0034178710193373263\n",
            "Entropy 1765 Mean Loss: 0.6907083056867123\n",
            "Value 1765 Mean Loss: 3.943061485886574\n",
            "dones: tensor(21.)\n",
            "Policy 1766 Mean Loss: -0.0033731814473867416\n",
            "Entropy 1766 Mean Loss: 0.6906600520014763\n",
            "Value 1766 Mean Loss: 4.149600490927696\n",
            "dones: tensor(21.)\n",
            "Policy 1767 Mean Loss: -0.007405288342852145\n",
            "Entropy 1767 Mean Loss: 0.6906205862760544\n",
            "Value 1767 Mean Loss: 4.036466985940933\n",
            "dones: tensor(22.)\n",
            "Policy 1768 Mean Loss: -0.010153328999876976\n",
            "Entropy 1768 Mean Loss: 0.6908153332769871\n",
            "Value 1768 Mean Loss: 4.5608837604522705\n",
            "dones: tensor(18.)\n",
            "Policy 1769 Mean Loss: -0.008016229548957199\n",
            "Entropy 1769 Mean Loss: 0.6905405074357986\n",
            "Value 1769 Mean Loss: 4.157436087727547\n",
            "dones: tensor(21.)\n",
            "Policy 1770 Mean Loss: -0.006674281088635325\n",
            "Entropy 1770 Mean Loss: 0.6906940750777721\n",
            "Value 1770 Mean Loss: 4.079094022512436\n",
            "dones: tensor(24.)\n",
            "Policy 1771 Mean Loss: -0.008682704850798473\n",
            "Entropy 1771 Mean Loss: 0.6908207647502422\n",
            "Value 1771 Mean Loss: 3.9823949933052063\n",
            "dones: tensor(23.)\n",
            "Policy 1772 Mean Loss: -0.004828577162697911\n",
            "Entropy 1772 Mean Loss: 0.6908929161727428\n",
            "Value 1772 Mean Loss: 4.309213310480118\n",
            "dones: tensor(23.)\n",
            "Policy 1773 Mean Loss: -0.004815236898139119\n",
            "Entropy 1773 Mean Loss: 0.6908544600009918\n",
            "Value 1773 Mean Loss: 4.535322308540344\n",
            "dones: tensor(25.)\n",
            "Policy 1774 Mean Loss: -0.005895848589716479\n",
            "Entropy 1774 Mean Loss: 0.6908405348658562\n",
            "Value 1774 Mean Loss: 4.827055782079697\n",
            "dones: tensor(22.)\n",
            "Policy 1775 Mean Loss: -0.008093938464298844\n",
            "Entropy 1775 Mean Loss: 0.6906143352389336\n",
            "Value 1775 Mean Loss: 4.198914811015129\n",
            "dones: tensor(26.)\n",
            "Policy 1776 Mean Loss: -0.004407060507219285\n",
            "Entropy 1776 Mean Loss: 0.6909511685371399\n",
            "Value 1776 Mean Loss: 5.142318457365036\n",
            "dones: tensor(22.)\n",
            "Policy 1777 Mean Loss: -0.0029549316968768835\n",
            "Entropy 1777 Mean Loss: 0.6906883977353573\n",
            "Value 1777 Mean Loss: 4.413001909852028\n",
            "dones: tensor(21.)\n",
            "Policy 1778 Mean Loss: -0.00679992011282593\n",
            "Entropy 1778 Mean Loss: 0.6906966529786587\n",
            "Value 1778 Mean Loss: 4.608258455991745\n",
            "dones: tensor(23.)\n",
            "Policy 1779 Mean Loss: -0.008536637353245169\n",
            "Entropy 1779 Mean Loss: 0.6905967891216278\n",
            "Value 1779 Mean Loss: 4.289620578289032\n",
            "dones: tensor(21.)\n",
            "Policy 1780 Mean Loss: -0.010634633246809244\n",
            "Entropy 1780 Mean Loss: 0.690436664968729\n",
            "Value 1780 Mean Loss: 4.566913545131683\n",
            "dones: tensor(24.)\n",
            "Policy 1781 Mean Loss: -0.010004865936934948\n",
            "Entropy 1781 Mean Loss: 0.6907528527081013\n",
            "Value 1781 Mean Loss: 4.521474719047546\n",
            "dones: tensor(25.)\n",
            "Policy 1782 Mean Loss: -0.00343522394541651\n",
            "Entropy 1782 Mean Loss: 0.6907264813780785\n",
            "Value 1782 Mean Loss: 4.206260114908218\n",
            "dones: tensor(20.)\n",
            "Policy 1783 Mean Loss: -0.0016500501078553498\n",
            "Entropy 1783 Mean Loss: 0.6904711611568928\n",
            "Value 1783 Mean Loss: 3.9116993248462677\n",
            "dones: tensor(25.)\n",
            "Policy 1784 Mean Loss: -0.0039045624434947968\n",
            "Entropy 1784 Mean Loss: 0.6907773390412331\n",
            "Value 1784 Mean Loss: 4.507925316691399\n",
            "dones: tensor(24.)\n",
            "Policy 1785 Mean Loss: -0.01129281212342903\n",
            "Entropy 1785 Mean Loss: 0.6906135715544224\n",
            "Value 1785 Mean Loss: 4.779843032360077\n",
            "dones: tensor(25.)\n",
            "Policy 1786 Mean Loss: -0.0031566983088850975\n",
            "Entropy 1786 Mean Loss: 0.6907384283840656\n",
            "Value 1786 Mean Loss: 4.303133636713028\n",
            "dones: tensor(19.)\n",
            "Policy 1787 Mean Loss: -0.007054158952087164\n",
            "Entropy 1787 Mean Loss: 0.6904493570327759\n",
            "Value 1787 Mean Loss: 4.088575020432472\n",
            "dones: tensor(26.)\n",
            "Policy 1788 Mean Loss: -0.006278826214838773\n",
            "Entropy 1788 Mean Loss: 0.690875131636858\n",
            "Value 1788 Mean Loss: 4.326577380299568\n",
            "dones: tensor(25.)\n",
            "Policy 1789 Mean Loss: -0.005623855860903859\n",
            "Entropy 1789 Mean Loss: 0.690717313438654\n",
            "Value 1789 Mean Loss: 4.445248484611511\n",
            "dones: tensor(20.)\n",
            "Policy 1790 Mean Loss: -0.010774087742902339\n",
            "Entropy 1790 Mean Loss: 0.6905161999166012\n",
            "Value 1790 Mean Loss: 4.617652460932732\n",
            "dones: tensor(25.)\n",
            "Policy 1791 Mean Loss: -0.006950988958124071\n",
            "Entropy 1791 Mean Loss: 0.6906562633812428\n",
            "Value 1791 Mean Loss: 4.553023815155029\n",
            "dones: tensor(24.)\n",
            "Policy 1792 Mean Loss: -0.010581990936771035\n",
            "Entropy 1792 Mean Loss: 0.6907503046095371\n",
            "Value 1792 Mean Loss: 3.8745601177215576\n",
            "dones: tensor(28.)\n",
            "Policy 1793 Mean Loss: -0.006785970297642052\n",
            "Entropy 1793 Mean Loss: 0.6909137479960918\n",
            "Value 1793 Mean Loss: 4.77172327041626\n",
            "dones: tensor(24.)\n",
            "Policy 1794 Mean Loss: -0.011627322586718947\n",
            "Entropy 1794 Mean Loss: 0.6905256807804108\n",
            "Value 1794 Mean Loss: 4.975004732608795\n",
            "dones: tensor(17.)\n",
            "Policy 1795 Mean Loss: -0.011546191642992198\n",
            "Entropy 1795 Mean Loss: 0.6902013793587685\n",
            "Value 1795 Mean Loss: 4.1002532839775085\n",
            "dones: tensor(21.)\n",
            "Policy 1796 Mean Loss: -0.004328140814322978\n",
            "Entropy 1796 Mean Loss: 0.6903472952544689\n",
            "Value 1796 Mean Loss: 4.299637869000435\n",
            "dones: tensor(22.)\n",
            "Policy 1797 Mean Loss: -0.01153108710423112\n",
            "Entropy 1797 Mean Loss: 0.6903410702943802\n",
            "Value 1797 Mean Loss: 4.456515043973923\n",
            "dones: tensor(27.)\n",
            "Policy 1798 Mean Loss: -0.004689218243584037\n",
            "Entropy 1798 Mean Loss: 0.6903627626597881\n",
            "Value 1798 Mean Loss: 4.930029511451721\n",
            "dones: tensor(23.)\n",
            "Policy 1799 Mean Loss: -0.007717057189438492\n",
            "Entropy 1799 Mean Loss: 0.6902516186237335\n",
            "Value 1799 Mean Loss: 4.501310095191002\n",
            "dones: tensor(24.)\n",
            "Policy 1800 Mean Loss: -0.010817415721248835\n",
            "Entropy 1800 Mean Loss: 0.6904127635061741\n",
            "Value 1800 Mean Loss: 4.612579584121704\n",
            "dones: tensor(26.)\n",
            "Policy 1801 Mean Loss: -0.010869727120734751\n",
            "Entropy 1801 Mean Loss: 0.6904073990881443\n",
            "Value 1801 Mean Loss: 4.634797632694244\n",
            "dones: tensor(22.)\n",
            "Policy 1802 Mean Loss: -0.007819997204933316\n",
            "Entropy 1802 Mean Loss: 0.6902637295424938\n",
            "Value 1802 Mean Loss: 3.7962782084941864\n",
            "dones: tensor(21.)\n",
            "Policy 1803 Mean Loss: -0.000806107243988663\n",
            "Entropy 1803 Mean Loss: 0.6903311349451542\n",
            "Value 1803 Mean Loss: 3.9155113846063614\n",
            "dones: tensor(21.)\n",
            "Policy 1804 Mean Loss: -0.008561270835343748\n",
            "Entropy 1804 Mean Loss: 0.6902845092117786\n",
            "Value 1804 Mean Loss: 4.089549615979195\n",
            "dones: tensor(21.)\n",
            "Policy 1805 Mean Loss: -0.011896374460775405\n",
            "Entropy 1805 Mean Loss: 0.6906438320875168\n",
            "Value 1805 Mean Loss: 4.557414889335632\n",
            "dones: tensor(25.)\n",
            "Policy 1806 Mean Loss: -0.008419865276664495\n",
            "Entropy 1806 Mean Loss: 0.6908607110381126\n",
            "Value 1806 Mean Loss: 4.409126311540604\n",
            "dones: tensor(23.)\n",
            "Policy 1807 Mean Loss: -0.013130765117239207\n",
            "Entropy 1807 Mean Loss: 0.6905469447374344\n",
            "Value 1807 Mean Loss: 4.436580374836922\n",
            "dones: tensor(25.)\n",
            "Policy 1808 Mean Loss: -0.010240187519229949\n",
            "Entropy 1808 Mean Loss: 0.6908242031931877\n",
            "Value 1808 Mean Loss: 4.511486321687698\n",
            "dones: tensor(24.)\n",
            "Policy 1809 Mean Loss: -0.00925770349567756\n",
            "Entropy 1809 Mean Loss: 0.6906063742935658\n",
            "Value 1809 Mean Loss: 4.146095857024193\n",
            "dones: tensor(25.)\n",
            "Policy 1810 Mean Loss: -0.004853077698498964\n",
            "Entropy 1810 Mean Loss: 0.6908282786607742\n",
            "Value 1810 Mean Loss: 4.69991347193718\n",
            "dones: tensor(25.)\n",
            "Policy 1811 Mean Loss: -0.007791828888002783\n",
            "Entropy 1811 Mean Loss: 0.6908602491021156\n",
            "Value 1811 Mean Loss: 4.7221710085868835\n",
            "dones: tensor(25.)\n",
            "Policy 1812 Mean Loss: -0.010487069375813007\n",
            "Entropy 1812 Mean Loss: 0.6905203424394131\n",
            "Value 1812 Mean Loss: 5.266507208347321\n",
            "dones: tensor(26.)\n",
            "Policy 1813 Mean Loss: -0.008159026328939945\n",
            "Entropy 1813 Mean Loss: 0.6908581890165806\n",
            "Value 1813 Mean Loss: 5.071572124958038\n",
            "dones: tensor(26.)\n",
            "Policy 1814 Mean Loss: -0.011304038809612393\n",
            "Entropy 1814 Mean Loss: 0.6906537897884846\n",
            "Value 1814 Mean Loss: 4.644824340939522\n",
            "dones: tensor(24.)\n",
            "Policy 1815 Mean Loss: -0.008163570368196815\n",
            "Entropy 1815 Mean Loss: 0.6906978897750378\n",
            "Value 1815 Mean Loss: 4.325587570667267\n",
            "dones: tensor(22.)\n",
            "Policy 1816 Mean Loss: -0.006271426216699183\n",
            "Entropy 1816 Mean Loss: 0.6905955672264099\n",
            "Value 1816 Mean Loss: 4.199863538146019\n",
            "dones: tensor(17.)\n",
            "Policy 1817 Mean Loss: -0.004450893145985901\n",
            "Entropy 1817 Mean Loss: 0.6904399506747723\n",
            "Value 1817 Mean Loss: 3.537663385272026\n",
            "dones: tensor(19.)\n",
            "Policy 1818 Mean Loss: -0.0014100524131208658\n",
            "Entropy 1818 Mean Loss: 0.6906217224895954\n",
            "Value 1818 Mean Loss: 4.235877156257629\n",
            "dones: tensor(23.)\n",
            "Policy 1819 Mean Loss: -0.01032445125747472\n",
            "Entropy 1819 Mean Loss: 0.6907394602894783\n",
            "Value 1819 Mean Loss: 4.565741777420044\n",
            "dones: tensor(23.)\n",
            "Policy 1820 Mean Loss: -0.008618791471235454\n",
            "Entropy 1820 Mean Loss: 0.6907286755740643\n",
            "Value 1820 Mean Loss: 4.950644791126251\n",
            "dones: tensor(21.)\n",
            "Policy 1821 Mean Loss: -0.003469046961981803\n",
            "Entropy 1821 Mean Loss: 0.6903210952877998\n",
            "Value 1821 Mean Loss: 4.083276376128197\n",
            "dones: tensor(22.)\n",
            "Policy 1822 Mean Loss: -0.004585416114423424\n",
            "Entropy 1822 Mean Loss: 0.6907112896442413\n",
            "Value 1822 Mean Loss: 4.435874864459038\n",
            "dones: tensor(23.)\n",
            "Policy 1823 Mean Loss: -0.007223669497761875\n",
            "Entropy 1823 Mean Loss: 0.6907673999667168\n",
            "Value 1823 Mean Loss: 4.576563984155655\n",
            "dones: tensor(20.)\n",
            "Policy 1824 Mean Loss: -0.0015261028311215341\n",
            "Entropy 1824 Mean Loss: 0.6907411515712738\n",
            "Value 1824 Mean Loss: 4.624416083097458\n",
            "dones: tensor(22.)\n",
            "Policy 1825 Mean Loss: -0.00788338779238984\n",
            "Entropy 1825 Mean Loss: 0.690926618874073\n",
            "Value 1825 Mean Loss: 5.065914750099182\n",
            "dones: tensor(20.)\n",
            "Policy 1826 Mean Loss: -0.011226531816646457\n",
            "Entropy 1826 Mean Loss: 0.6905210353434086\n",
            "Value 1826 Mean Loss: 3.77447946369648\n",
            "dones: tensor(27.)\n",
            "Policy 1827 Mean Loss: -0.01620976033154875\n",
            "Entropy 1827 Mean Loss: 0.6906992681324482\n",
            "Value 1827 Mean Loss: 5.294758200645447\n",
            "dones: tensor(25.)\n",
            "Policy 1828 Mean Loss: -0.002264127688249573\n",
            "Entropy 1828 Mean Loss: 0.6909082569181919\n",
            "Value 1828 Mean Loss: 4.674210220575333\n",
            "dones: tensor(21.)\n",
            "Policy 1829 Mean Loss: -0.005790571914985776\n",
            "Entropy 1829 Mean Loss: 0.6907636150717735\n",
            "Value 1829 Mean Loss: 4.855673000216484\n",
            "dones: tensor(25.)\n",
            "Policy 1830 Mean Loss: -0.006734933005645871\n",
            "Entropy 1830 Mean Loss: 0.6907286122441292\n",
            "Value 1830 Mean Loss: 4.112601205706596\n",
            "dones: tensor(25.)\n",
            "Policy 1831 Mean Loss: -0.00479557691141963\n",
            "Entropy 1831 Mean Loss: 0.6906385496258736\n",
            "Value 1831 Mean Loss: 4.9245263040065765\n",
            "dones: tensor(23.)\n",
            "Policy 1832 Mean Loss: -0.013054622861091048\n",
            "Entropy 1832 Mean Loss: 0.6908274851739407\n",
            "Value 1832 Mean Loss: 4.656704023480415\n",
            "dones: tensor(25.)\n",
            "Policy 1833 Mean Loss: -0.009115463122725487\n",
            "Entropy 1833 Mean Loss: 0.6908894143998623\n",
            "Value 1833 Mean Loss: 4.570486903190613\n",
            "dones: tensor(22.)\n",
            "Policy 1834 Mean Loss: -0.009742039546836168\n",
            "Entropy 1834 Mean Loss: 0.6906324736773968\n",
            "Value 1834 Mean Loss: 4.751162678003311\n",
            "dones: tensor(24.)\n",
            "Policy 1835 Mean Loss: -0.0067346636787988245\n",
            "Entropy 1835 Mean Loss: 0.6908930167555809\n",
            "Value 1835 Mean Loss: 5.123415023088455\n",
            "dones: tensor(26.)\n",
            "Policy 1836 Mean Loss: -0.004742402816191316\n",
            "Entropy 1836 Mean Loss: 0.6907244697213173\n",
            "Value 1836 Mean Loss: 4.55305652320385\n",
            "dones: tensor(24.)\n",
            "Policy 1837 Mean Loss: -0.01068091654451564\n",
            "Entropy 1837 Mean Loss: 0.6907020024955273\n",
            "Value 1837 Mean Loss: 4.4851717203855515\n",
            "dones: tensor(19.)\n",
            "Policy 1838 Mean Loss: -0.007525289838667959\n",
            "Entropy 1838 Mean Loss: 0.6903189793229103\n",
            "Value 1838 Mean Loss: 4.01724536716938\n",
            "dones: tensor(19.)\n",
            "Policy 1839 Mean Loss: -0.010717906465288252\n",
            "Entropy 1839 Mean Loss: 0.6904428564012051\n",
            "Value 1839 Mean Loss: 4.187767565250397\n",
            "dones: tensor(21.)\n",
            "Policy 1840 Mean Loss: -0.005641429394017905\n",
            "Entropy 1840 Mean Loss: 0.6906098611652851\n",
            "Value 1840 Mean Loss: 4.514872387051582\n",
            "dones: tensor(23.)\n",
            "Policy 1841 Mean Loss: -0.006471893924754113\n",
            "Entropy 1841 Mean Loss: 0.690652322024107\n",
            "Value 1841 Mean Loss: 4.3291007578372955\n",
            "dones: tensor(25.)\n",
            "Policy 1842 Mean Loss: -0.009518506529275328\n",
            "Entropy 1842 Mean Loss: 0.6909767389297485\n",
            "Value 1842 Mean Loss: 4.917561039328575\n",
            "dones: tensor(22.)\n",
            "Policy 1843 Mean Loss: -0.007718984677921981\n",
            "Entropy 1843 Mean Loss: 0.6907673217356205\n",
            "Value 1843 Mean Loss: 4.581115886569023\n",
            "dones: tensor(26.)\n",
            "Policy 1844 Mean Loss: -0.002477856120094657\n",
            "Entropy 1844 Mean Loss: 0.6907303333282471\n",
            "Value 1844 Mean Loss: 5.181778430938721\n",
            "dones: tensor(27.)\n",
            "Policy 1845 Mean Loss: -0.009959505405277014\n",
            "Entropy 1845 Mean Loss: 0.6909348219633102\n",
            "Value 1845 Mean Loss: 4.97468401491642\n",
            "dones: tensor(21.)\n",
            "Policy 1846 Mean Loss: -0.009835713251959532\n",
            "Entropy 1846 Mean Loss: 0.6907265186309814\n",
            "Value 1846 Mean Loss: 4.58937680721283\n",
            "dones: tensor(27.)\n",
            "Policy 1847 Mean Loss: -0.00757696118671447\n",
            "Entropy 1847 Mean Loss: 0.6911221444606781\n",
            "Value 1847 Mean Loss: 5.043558031320572\n",
            "dones: tensor(27.)\n",
            "Policy 1848 Mean Loss: -0.006016674800775945\n",
            "Entropy 1848 Mean Loss: 0.6909697353839874\n",
            "Value 1848 Mean Loss: 4.808997362852097\n",
            "dones: tensor(25.)\n",
            "Policy 1849 Mean Loss: -0.002495541761163622\n",
            "Entropy 1849 Mean Loss: 0.691050685942173\n",
            "Value 1849 Mean Loss: 4.9064424484968185\n",
            "dones: tensor(22.)\n",
            "Policy 1850 Mean Loss: -0.002184408891480416\n",
            "Entropy 1850 Mean Loss: 0.6907102838158607\n",
            "Value 1850 Mean Loss: 4.148825109004974\n",
            "dones: tensor(24.)\n",
            "Policy 1851 Mean Loss: -0.0067619807086884975\n",
            "Entropy 1851 Mean Loss: 0.6908424012362957\n",
            "Value 1851 Mean Loss: 4.431333854794502\n",
            "dones: tensor(19.)\n",
            "Policy 1852 Mean Loss: -0.0040323499706573784\n",
            "Entropy 1852 Mean Loss: 0.6905868761241436\n",
            "Value 1852 Mean Loss: 4.000400498509407\n",
            "dones: tensor(23.)\n",
            "Policy 1853 Mean Loss: -0.00903868384193629\n",
            "Entropy 1853 Mean Loss: 0.6907638385891914\n",
            "Value 1853 Mean Loss: 4.438130244612694\n",
            "dones: tensor(23.)\n",
            "Policy 1854 Mean Loss: -0.0042526263277977705\n",
            "Entropy 1854 Mean Loss: 0.6905475668609142\n",
            "Value 1854 Mean Loss: 4.180250361561775\n",
            "dones: tensor(26.)\n",
            "Policy 1855 Mean Loss: -0.005158240732271224\n",
            "Entropy 1855 Mean Loss: 0.6909347251057625\n",
            "Value 1855 Mean Loss: 4.274514123797417\n",
            "dones: tensor(21.)\n",
            "Policy 1856 Mean Loss: -0.008193309302441776\n",
            "Entropy 1856 Mean Loss: 0.6908037699759007\n",
            "Value 1856 Mean Loss: 5.087609589099884\n",
            "dones: tensor(20.)\n",
            "Policy 1857 Mean Loss: -0.008389820344746113\n",
            "Entropy 1857 Mean Loss: 0.6903269775211811\n",
            "Value 1857 Mean Loss: 4.31889021396637\n",
            "dones: tensor(21.)\n",
            "Policy 1858 Mean Loss: -0.0073736056219786406\n",
            "Entropy 1858 Mean Loss: 0.6906225793063641\n",
            "Value 1858 Mean Loss: 4.242068991065025\n",
            "dones: tensor(20.)\n",
            "Policy 1859 Mean Loss: -0.006813825573772192\n",
            "Entropy 1859 Mean Loss: 0.6908192038536072\n",
            "Value 1859 Mean Loss: 4.222079649567604\n",
            "dones: tensor(24.)\n",
            "Policy 1860 Mean Loss: -0.0036249483819119632\n",
            "Entropy 1860 Mean Loss: 0.6907980851829052\n",
            "Value 1860 Mean Loss: 4.804444223642349\n",
            "dones: tensor(24.)\n",
            "Policy 1861 Mean Loss: -0.005202811327762902\n",
            "Entropy 1861 Mean Loss: 0.6907462887465954\n",
            "Value 1861 Mean Loss: 5.483531713485718\n",
            "dones: tensor(25.)\n",
            "Policy 1862 Mean Loss: -0.0023161426943261176\n",
            "Entropy 1862 Mean Loss: 0.6909363642334938\n",
            "Value 1862 Mean Loss: 4.87470480799675\n",
            "dones: tensor(20.)\n",
            "Policy 1863 Mean Loss: -0.004024857305921614\n",
            "Entropy 1863 Mean Loss: 0.6907055974006653\n",
            "Value 1863 Mean Loss: 4.04002870619297\n",
            "dones: tensor(20.)\n",
            "Policy 1864 Mean Loss: -0.0073877774411812425\n",
            "Entropy 1864 Mean Loss: 0.6907199360430241\n",
            "Value 1864 Mean Loss: 4.25130258500576\n",
            "dones: tensor(23.)\n",
            "Policy 1865 Mean Loss: -0.004994795774109662\n",
            "Entropy 1865 Mean Loss: 0.6907990612089634\n",
            "Value 1865 Mean Loss: 4.46973092854023\n",
            "dones: tensor(25.)\n",
            "Policy 1866 Mean Loss: -0.0086525987717323\n",
            "Entropy 1866 Mean Loss: 0.690825417637825\n",
            "Value 1866 Mean Loss: 5.00056529045105\n",
            "dones: tensor(25.)\n",
            "Policy 1867 Mean Loss: -0.007265771273523569\n",
            "Entropy 1867 Mean Loss: 0.6907981038093567\n",
            "Value 1867 Mean Loss: 4.449523210525513\n",
            "dones: tensor(20.)\n",
            "Policy 1868 Mean Loss: -0.005338465154636651\n",
            "Entropy 1868 Mean Loss: 0.6906168796122074\n",
            "Value 1868 Mean Loss: 3.916985332965851\n",
            "dones: tensor(22.)\n",
            "Policy 1869 Mean Loss: -0.007208912924397737\n",
            "Entropy 1869 Mean Loss: 0.69064000248909\n",
            "Value 1869 Mean Loss: 4.65188792347908\n",
            "dones: tensor(16.)\n",
            "Policy 1870 Mean Loss: -0.011236828286200762\n",
            "Entropy 1870 Mean Loss: 0.6906396634876728\n",
            "Value 1870 Mean Loss: 3.8441427648067474\n",
            "dones: tensor(21.)\n",
            "Policy 1871 Mean Loss: -0.00819244293961674\n",
            "Entropy 1871 Mean Loss: 0.6906461119651794\n",
            "Value 1871 Mean Loss: 4.950888156890869\n",
            "dones: tensor(24.)\n",
            "Policy 1872 Mean Loss: -0.006134704570285976\n",
            "Entropy 1872 Mean Loss: 0.690766341984272\n",
            "Value 1872 Mean Loss: 4.93397518992424\n",
            "dones: tensor(20.)\n",
            "Policy 1873 Mean Loss: -0.004436672606971115\n",
            "Entropy 1873 Mean Loss: 0.6908314079046249\n",
            "Value 1873 Mean Loss: 4.263283729553223\n",
            "dones: tensor(22.)\n",
            "Policy 1874 Mean Loss: -0.003463991917669773\n",
            "Entropy 1874 Mean Loss: 0.6910006627440453\n",
            "Value 1874 Mean Loss: 4.281584799289703\n",
            "dones: tensor(18.)\n",
            "Policy 1875 Mean Loss: -0.0036845497088506818\n",
            "Entropy 1875 Mean Loss: 0.690592173486948\n",
            "Value 1875 Mean Loss: 3.9924321323633194\n",
            "dones: tensor(18.)\n",
            "Policy 1876 Mean Loss: -0.005736716790124774\n",
            "Entropy 1876 Mean Loss: 0.6905842125415802\n",
            "Value 1876 Mean Loss: 4.03161558508873\n",
            "dones: tensor(21.)\n",
            "Policy 1877 Mean Loss: -0.009511696174740791\n",
            "Entropy 1877 Mean Loss: 0.6907552108168602\n",
            "Value 1877 Mean Loss: 4.232717737555504\n",
            "dones: tensor(27.)\n",
            "Policy 1878 Mean Loss: -0.0012780780089087784\n",
            "Entropy 1878 Mean Loss: 0.6911739818751812\n",
            "Value 1878 Mean Loss: 4.5743280202150345\n",
            "dones: tensor(17.)\n",
            "Policy 1879 Mean Loss: -0.0058509263035375625\n",
            "Entropy 1879 Mean Loss: 0.6908378936350346\n",
            "Value 1879 Mean Loss: 5.013893812894821\n",
            "dones: tensor(24.)\n",
            "Policy 1880 Mean Loss: -0.010762086894828826\n",
            "Entropy 1880 Mean Loss: 0.690842617303133\n",
            "Value 1880 Mean Loss: 4.548773750662804\n",
            "dones: tensor(22.)\n",
            "Policy 1881 Mean Loss: -0.005448915355373174\n",
            "Entropy 1881 Mean Loss: 0.6911028921604156\n",
            "Value 1881 Mean Loss: 4.511282920837402\n",
            "dones: tensor(21.)\n",
            "Policy 1882 Mean Loss: -0.00931026233593002\n",
            "Entropy 1882 Mean Loss: 0.6905983686447144\n",
            "Value 1882 Mean Loss: 4.229164898395538\n",
            "dones: tensor(24.)\n",
            "Policy 1883 Mean Loss: -0.003238905221223831\n",
            "Entropy 1883 Mean Loss: 0.6906974837183952\n",
            "Value 1883 Mean Loss: 4.706770420074463\n",
            "dones: tensor(24.)\n",
            "Policy 1884 Mean Loss: -0.0014910056488588452\n",
            "Entropy 1884 Mean Loss: 0.6911461688578129\n",
            "Value 1884 Mean Loss: 5.431858986616135\n",
            "dones: tensor(24.)\n",
            "Policy 1885 Mean Loss: -0.008277450338937342\n",
            "Entropy 1885 Mean Loss: 0.6908290535211563\n",
            "Value 1885 Mean Loss: 4.358650162816048\n",
            "dones: tensor(22.)\n",
            "Policy 1886 Mean Loss: -0.00475427380297333\n",
            "Entropy 1886 Mean Loss: 0.6911063194274902\n",
            "Value 1886 Mean Loss: 4.716921508312225\n",
            "dones: tensor(20.)\n",
            "Policy 1887 Mean Loss: -0.007727290620096028\n",
            "Entropy 1887 Mean Loss: 0.6908676698803902\n",
            "Value 1887 Mean Loss: 4.935758143663406\n",
            "dones: tensor(23.)\n",
            "Policy 1888 Mean Loss: -0.007435774547047913\n",
            "Entropy 1888 Mean Loss: 0.6912212111055851\n",
            "Value 1888 Mean Loss: 6.138185918331146\n",
            "dones: tensor(21.)\n",
            "Policy 1889 Mean Loss: -0.0054306479869410396\n",
            "Entropy 1889 Mean Loss: 0.6909259669482708\n",
            "Value 1889 Mean Loss: 4.969731628894806\n",
            "dones: tensor(23.)\n",
            "Policy 1890 Mean Loss: -0.004227957921102643\n",
            "Entropy 1890 Mean Loss: 0.6908894218504429\n",
            "Value 1890 Mean Loss: 4.614994660019875\n",
            "dones: tensor(19.)\n",
            "Policy 1891 Mean Loss: -0.00826638488797471\n",
            "Entropy 1891 Mean Loss: 0.6906620301306248\n",
            "Value 1891 Mean Loss: 4.55890591442585\n",
            "dones: tensor(22.)\n",
            "Policy 1892 Mean Loss: -0.008589353587012738\n",
            "Entropy 1892 Mean Loss: 0.6910946741700172\n",
            "Value 1892 Mean Loss: 4.262835547327995\n",
            "dones: tensor(23.)\n",
            "Policy 1893 Mean Loss: -0.005675564054399729\n",
            "Entropy 1893 Mean Loss: 0.6909895315766335\n",
            "Value 1893 Mean Loss: 5.139981001615524\n",
            "dones: tensor(22.)\n",
            "Policy 1894 Mean Loss: -0.004959249868988991\n",
            "Entropy 1894 Mean Loss: 0.6909236460924149\n",
            "Value 1894 Mean Loss: 4.796971261501312\n",
            "dones: tensor(23.)\n",
            "Policy 1895 Mean Loss: -0.005830132402479649\n",
            "Entropy 1895 Mean Loss: 0.690973948687315\n",
            "Value 1895 Mean Loss: 5.307116001844406\n",
            "dones: tensor(19.)\n",
            "Policy 1896 Mean Loss: -0.0069323065399657935\n",
            "Entropy 1896 Mean Loss: 0.6907141990959644\n",
            "Value 1896 Mean Loss: 4.021014302968979\n",
            "dones: tensor(22.)\n",
            "Policy 1897 Mean Loss: -0.0015889882342889905\n",
            "Entropy 1897 Mean Loss: 0.6909441202878952\n",
            "Value 1897 Mean Loss: 4.064724087715149\n",
            "dones: tensor(24.)\n",
            "Policy 1898 Mean Loss: -0.007977522618602961\n",
            "Entropy 1898 Mean Loss: 0.6908847615122795\n",
            "Value 1898 Mean Loss: 4.648943051695824\n",
            "dones: tensor(19.)\n",
            "Policy 1899 Mean Loss: -0.007516686804592609\n",
            "Entropy 1899 Mean Loss: 0.6908661834895611\n",
            "Value 1899 Mean Loss: 3.7810960710048676\n",
            "dones: tensor(21.)\n",
            "Policy 1900 Mean Loss: -0.008010646502953023\n",
            "Entropy 1900 Mean Loss: 0.690836101770401\n",
            "Value 1900 Mean Loss: 4.113930657505989\n",
            "dones: tensor(23.)\n",
            "Policy 1901 Mean Loss: -0.00985617161495611\n",
            "Entropy 1901 Mean Loss: 0.6910043656826019\n",
            "Value 1901 Mean Loss: 4.577555164694786\n",
            "dones: tensor(22.)\n",
            "Policy 1902 Mean Loss: -0.005204975430388004\n",
            "Entropy 1902 Mean Loss: 0.690939150750637\n",
            "Value 1902 Mean Loss: 4.2965754717588425\n",
            "dones: tensor(26.)\n",
            "Policy 1903 Mean Loss: -0.00875353452283889\n",
            "Entropy 1903 Mean Loss: 0.6909737847745419\n",
            "Value 1903 Mean Loss: 4.828093647956848\n",
            "dones: tensor(17.)\n",
            "Policy 1904 Mean Loss: -0.0023252550163306296\n",
            "Entropy 1904 Mean Loss: 0.690867468714714\n",
            "Value 1904 Mean Loss: 4.518922209739685\n",
            "dones: tensor(22.)\n",
            "Policy 1905 Mean Loss: -0.0033683351357467473\n",
            "Entropy 1905 Mean Loss: 0.6908112540841103\n",
            "Value 1905 Mean Loss: 4.490453273057938\n",
            "dones: tensor(21.)\n",
            "Policy 1906 Mean Loss: -0.006615909282118082\n",
            "Entropy 1906 Mean Loss: 0.6908674091100693\n",
            "Value 1906 Mean Loss: 4.594256490468979\n",
            "dones: tensor(22.)\n",
            "Policy 1907 Mean Loss: -0.00907448079669848\n",
            "Entropy 1907 Mean Loss: 0.6909930557012558\n",
            "Value 1907 Mean Loss: 5.2097271382808685\n",
            "dones: tensor(20.)\n",
            "Policy 1908 Mean Loss: -0.0026631999062374234\n",
            "Entropy 1908 Mean Loss: 0.690900020301342\n",
            "Value 1908 Mean Loss: 4.835407614707947\n",
            "dones: tensor(22.)\n",
            "Policy 1909 Mean Loss: -0.007037195027805865\n",
            "Entropy 1909 Mean Loss: 0.6910737827420235\n",
            "Value 1909 Mean Loss: 4.385579347610474\n",
            "dones: tensor(24.)\n",
            "Policy 1910 Mean Loss: -0.010587894998025149\n",
            "Entropy 1910 Mean Loss: 0.6909594424068928\n",
            "Value 1910 Mean Loss: 4.883246660232544\n",
            "dones: tensor(27.)\n",
            "Policy 1911 Mean Loss: -0.006702912272885442\n",
            "Entropy 1911 Mean Loss: 0.6909661814570427\n",
            "Value 1911 Mean Loss: 5.138231992721558\n",
            "dones: tensor(19.)\n",
            "Policy 1912 Mean Loss: -0.003836549643892795\n",
            "Entropy 1912 Mean Loss: 0.6906504854559898\n",
            "Value 1912 Mean Loss: 4.349429428577423\n",
            "dones: tensor(22.)\n",
            "Policy 1913 Mean Loss: -0.007235272438265383\n",
            "Entropy 1913 Mean Loss: 0.6907365173101425\n",
            "Value 1913 Mean Loss: 4.254336476325989\n",
            "dones: tensor(24.)\n",
            "Policy 1914 Mean Loss: -0.005832206807099283\n",
            "Entropy 1914 Mean Loss: 0.6911759711802006\n",
            "Value 1914 Mean Loss: 4.850626617670059\n",
            "dones: tensor(19.)\n",
            "Policy 1915 Mean Loss: -0.009823333355598152\n",
            "Entropy 1915 Mean Loss: 0.6907360777258873\n",
            "Value 1915 Mean Loss: 4.606926292181015\n",
            "dones: tensor(24.)\n",
            "Policy 1916 Mean Loss: -0.006103479187004268\n",
            "Entropy 1916 Mean Loss: 0.6908934526145458\n",
            "Value 1916 Mean Loss: 4.847539901733398\n",
            "dones: tensor(22.)\n",
            "Policy 1917 Mean Loss: -0.013039571524132043\n",
            "Entropy 1917 Mean Loss: 0.6907548978924751\n",
            "Value 1917 Mean Loss: 4.602813899517059\n",
            "dones: tensor(25.)\n",
            "Policy 1918 Mean Loss: -0.010803717013914138\n",
            "Entropy 1918 Mean Loss: 0.6909838877618313\n",
            "Value 1918 Mean Loss: 4.614974647760391\n",
            "dones: tensor(21.)\n",
            "Policy 1919 Mean Loss: -0.008063612971454859\n",
            "Entropy 1919 Mean Loss: 0.6906749904155731\n",
            "Value 1919 Mean Loss: 3.987885683774948\n",
            "dones: tensor(17.)\n",
            "Policy 1920 Mean Loss: -0.00658995151752606\n",
            "Entropy 1920 Mean Loss: 0.6906229555606842\n",
            "Value 1920 Mean Loss: 3.598740130662918\n",
            "dones: tensor(27.)\n",
            "Policy 1921 Mean Loss: -0.009057834860868752\n",
            "Entropy 1921 Mean Loss: 0.690723642706871\n",
            "Value 1921 Mean Loss: 5.48575896024704\n",
            "dones: tensor(25.)\n",
            "Policy 1922 Mean Loss: -0.00558723701396957\n",
            "Entropy 1922 Mean Loss: 0.6910530142486095\n",
            "Value 1922 Mean Loss: 4.6863714158535\n",
            "dones: tensor(25.)\n",
            "Policy 1923 Mean Loss: -0.008114161784760654\n",
            "Entropy 1923 Mean Loss: 0.6910245195031166\n",
            "Value 1923 Mean Loss: 4.571140259504318\n",
            "dones: tensor(16.)\n",
            "Policy 1924 Mean Loss: -0.0014236075803637505\n",
            "Entropy 1924 Mean Loss: 0.6905804425477982\n",
            "Value 1924 Mean Loss: 5.115563213825226\n",
            "dones: tensor(22.)\n",
            "Policy 1925 Mean Loss: -0.009531922522000968\n",
            "Entropy 1925 Mean Loss: 0.6907861568033695\n",
            "Value 1925 Mean Loss: 5.073434084653854\n",
            "dones: tensor(27.)\n",
            "Policy 1926 Mean Loss: -0.008649176801554859\n",
            "Entropy 1926 Mean Loss: 0.6911669932305813\n",
            "Value 1926 Mean Loss: 4.835114508867264\n",
            "dones: tensor(21.)\n",
            "Policy 1927 Mean Loss: -0.00574547506403178\n",
            "Entropy 1927 Mean Loss: 0.6907865516841412\n",
            "Value 1927 Mean Loss: 3.747189685702324\n",
            "dones: tensor(21.)\n",
            "Policy 1928 Mean Loss: -0.004571922589093447\n",
            "Entropy 1928 Mean Loss: 0.6909220740199089\n",
            "Value 1928 Mean Loss: 4.154163971543312\n",
            "dones: tensor(22.)\n",
            "Policy 1929 Mean Loss: -0.005338688613846898\n",
            "Entropy 1929 Mean Loss: 0.6909471675753593\n",
            "Value 1929 Mean Loss: 4.64076654613018\n",
            "dones: tensor(20.)\n",
            "Policy 1930 Mean Loss: -0.002988830005051568\n",
            "Entropy 1930 Mean Loss: 0.6909583993256092\n",
            "Value 1930 Mean Loss: 4.572842210531235\n",
            "dones: tensor(16.)\n",
            "Policy 1931 Mean Loss: -0.004589749325532466\n",
            "Entropy 1931 Mean Loss: 0.6907624267041683\n",
            "Value 1931 Mean Loss: 5.042637377977371\n",
            "dones: tensor(17.)\n",
            "Policy 1932 Mean Loss: -0.0043955566943623126\n",
            "Entropy 1932 Mean Loss: 0.6907055862247944\n",
            "Value 1932 Mean Loss: 4.328252017498016\n",
            "dones: tensor(27.)\n",
            "Policy 1933 Mean Loss: -0.007774344237986952\n",
            "Entropy 1933 Mean Loss: 0.6912365965545177\n",
            "Value 1933 Mean Loss: 4.710501968860626\n",
            "dones: tensor(28.)\n",
            "Policy 1934 Mean Loss: -0.008711508358828723\n",
            "Entropy 1934 Mean Loss: 0.6908852867782116\n",
            "Value 1934 Mean Loss: 5.572557806968689\n",
            "dones: tensor(19.)\n",
            "Policy 1935 Mean Loss: -0.007023538026260212\n",
            "Entropy 1935 Mean Loss: 0.6909054964780807\n",
            "Value 1935 Mean Loss: 4.3044377863407135\n",
            "dones: tensor(24.)\n",
            "Policy 1936 Mean Loss: -0.007604379905387759\n",
            "Entropy 1936 Mean Loss: 0.6909933350980282\n",
            "Value 1936 Mean Loss: 4.491095840930939\n",
            "dones: tensor(23.)\n",
            "Policy 1937 Mean Loss: -0.002232610248029232\n",
            "Entropy 1937 Mean Loss: 0.6910617128014565\n",
            "Value 1937 Mean Loss: 4.380621686577797\n",
            "dones: tensor(23.)\n",
            "Policy 1938 Mean Loss: -0.007180787972174585\n",
            "Entropy 1938 Mean Loss: 0.6909208595752716\n",
            "Value 1938 Mean Loss: 4.384501859545708\n",
            "dones: tensor(21.)\n",
            "Policy 1939 Mean Loss: -0.011849116475787014\n",
            "Entropy 1939 Mean Loss: 0.6907629184424877\n",
            "Value 1939 Mean Loss: 4.884288430213928\n",
            "dones: tensor(27.)\n",
            "Policy 1940 Mean Loss: -0.009172713733278215\n",
            "Entropy 1940 Mean Loss: 0.6910024993121624\n",
            "Value 1940 Mean Loss: 4.946490406990051\n",
            "dones: tensor(23.)\n",
            "Policy 1941 Mean Loss: -0.009492905548540875\n",
            "Entropy 1941 Mean Loss: 0.6909397281706333\n",
            "Value 1941 Mean Loss: 4.432584226131439\n",
            "dones: tensor(24.)\n",
            "Policy 1942 Mean Loss: -0.00792538357200101\n",
            "Entropy 1942 Mean Loss: 0.6909770332276821\n",
            "Value 1942 Mean Loss: 4.578783601522446\n",
            "dones: tensor(22.)\n",
            "Policy 1943 Mean Loss: -0.012738800549414009\n",
            "Entropy 1943 Mean Loss: 0.6907529942691326\n",
            "Value 1943 Mean Loss: 4.102763012051582\n",
            "dones: tensor(18.)\n",
            "Policy 1944 Mean Loss: -0.010011038975790143\n",
            "Entropy 1944 Mean Loss: 0.6904732584953308\n",
            "Value 1944 Mean Loss: 4.3601366728544235\n",
            "dones: tensor(19.)\n",
            "Policy 1945 Mean Loss: -0.008880213717930019\n",
            "Entropy 1945 Mean Loss: 0.6906787529587746\n",
            "Value 1945 Mean Loss: 4.799994349479675\n",
            "dones: tensor(23.)\n",
            "Policy 1946 Mean Loss: -0.011218426108825952\n",
            "Entropy 1946 Mean Loss: 0.6906961798667908\n",
            "Value 1946 Mean Loss: 4.8108658492565155\n",
            "dones: tensor(21.)\n",
            "Policy 1947 Mean Loss: -0.0004966538981534541\n",
            "Entropy 1947 Mean Loss: 0.6907311230897903\n",
            "Value 1947 Mean Loss: 4.543891757726669\n",
            "dones: tensor(21.)\n",
            "Policy 1948 Mean Loss: -0.011516008409671485\n",
            "Entropy 1948 Mean Loss: 0.6907071098685265\n",
            "Value 1948 Mean Loss: 4.620818689465523\n",
            "dones: tensor(20.)\n",
            "Policy 1949 Mean Loss: -0.005556581367272884\n",
            "Entropy 1949 Mean Loss: 0.6908887848258018\n",
            "Value 1949 Mean Loss: 4.466290205717087\n",
            "dones: tensor(22.)\n",
            "Policy 1950 Mean Loss: -0.009511667652986944\n",
            "Entropy 1950 Mean Loss: 0.6907378248870373\n",
            "Value 1950 Mean Loss: 4.465326756238937\n",
            "dones: tensor(22.)\n",
            "Policy 1951 Mean Loss: -0.006628799543250352\n",
            "Entropy 1951 Mean Loss: 0.6908853575587273\n",
            "Value 1951 Mean Loss: 4.8054307997226715\n",
            "dones: tensor(24.)\n",
            "Policy 1952 Mean Loss: -0.011123011936433613\n",
            "Entropy 1952 Mean Loss: 0.6908856257796288\n",
            "Value 1952 Mean Loss: 4.624285072088242\n",
            "dones: tensor(19.)\n",
            "Policy 1953 Mean Loss: -0.0053126049460843205\n",
            "Entropy 1953 Mean Loss: 0.6908336840569973\n",
            "Value 1953 Mean Loss: 4.678765416145325\n",
            "dones: tensor(26.)\n",
            "Policy 1954 Mean Loss: -0.009338637348264456\n",
            "Entropy 1954 Mean Loss: 0.6909075975418091\n",
            "Value 1954 Mean Loss: 4.83444282412529\n",
            "dones: tensor(24.)\n",
            "Policy 1955 Mean Loss: -0.010530929313972592\n",
            "Entropy 1955 Mean Loss: 0.6909249946475029\n",
            "Value 1955 Mean Loss: 5.013232380151749\n",
            "dones: tensor(22.)\n",
            "Policy 1956 Mean Loss: -0.008199021336622536\n",
            "Entropy 1956 Mean Loss: 0.6908192411065102\n",
            "Value 1956 Mean Loss: 4.324439063668251\n",
            "dones: tensor(30.)\n",
            "Policy 1957 Mean Loss: -0.005908336723223329\n",
            "Entropy 1957 Mean Loss: 0.6909330897033215\n",
            "Value 1957 Mean Loss: 5.242930620908737\n",
            "dones: tensor(21.)\n",
            "Policy 1958 Mean Loss: -0.00902372831478715\n",
            "Entropy 1958 Mean Loss: 0.6906010136008263\n",
            "Value 1958 Mean Loss: 5.4797050058841705\n",
            "dones: tensor(24.)\n",
            "Policy 1959 Mean Loss: -0.0072869653813540936\n",
            "Entropy 1959 Mean Loss: 0.6908550336956978\n",
            "Value 1959 Mean Loss: 5.146594971418381\n",
            "dones: tensor(23.)\n",
            "Policy 1960 Mean Loss: -0.0066208840580657125\n",
            "Entropy 1960 Mean Loss: 0.6908944249153137\n",
            "Value 1960 Mean Loss: 4.83452570438385\n",
            "dones: tensor(18.)\n",
            "Policy 1961 Mean Loss: -0.010802138363942504\n",
            "Entropy 1961 Mean Loss: 0.6905729882419109\n",
            "Value 1961 Mean Loss: 4.046317249536514\n",
            "dones: tensor(19.)\n",
            "Policy 1962 Mean Loss: -0.005880769109353423\n",
            "Entropy 1962 Mean Loss: 0.6907401122152805\n",
            "Value 1962 Mean Loss: 4.424148738384247\n",
            "dones: tensor(24.)\n",
            "Policy 1963 Mean Loss: -0.006319304229691625\n",
            "Entropy 1963 Mean Loss: 0.6908975206315517\n",
            "Value 1963 Mean Loss: 4.6033163368701935\n",
            "dones: tensor(22.)\n",
            "Policy 1964 Mean Loss: -0.007735489576589316\n",
            "Entropy 1964 Mean Loss: 0.6909890659153461\n",
            "Value 1964 Mean Loss: 5.033713608980179\n",
            "dones: tensor(21.)\n",
            "Policy 1965 Mean Loss: -0.005936119589023292\n",
            "Entropy 1965 Mean Loss: 0.6906807236373425\n",
            "Value 1965 Mean Loss: 4.208664357662201\n",
            "dones: tensor(21.)\n",
            "Policy 1966 Mean Loss: -0.004460700845811516\n",
            "Entropy 1966 Mean Loss: 0.6908561736345291\n",
            "Value 1966 Mean Loss: 4.056990668177605\n",
            "dones: tensor(24.)\n",
            "Policy 1967 Mean Loss: -0.005826288717798889\n",
            "Entropy 1967 Mean Loss: 0.690864522010088\n",
            "Value 1967 Mean Loss: 4.69520828127861\n",
            "dones: tensor(22.)\n",
            "Policy 1968 Mean Loss: -0.008354787132702768\n",
            "Entropy 1968 Mean Loss: 0.6909782402217388\n",
            "Value 1968 Mean Loss: 4.236768126487732\n",
            "dones: tensor(23.)\n",
            "Policy 1969 Mean Loss: -0.004955626791343093\n",
            "Entropy 1969 Mean Loss: 0.6909705922007561\n",
            "Value 1969 Mean Loss: 5.109833061695099\n",
            "dones: tensor(21.)\n",
            "Policy 1970 Mean Loss: -0.004688264802098274\n",
            "Entropy 1970 Mean Loss: 0.690769862383604\n",
            "Value 1970 Mean Loss: 4.929685741662979\n",
            "dones: tensor(25.)\n",
            "Policy 1971 Mean Loss: -0.004199222195893526\n",
            "Entropy 1971 Mean Loss: 0.691138569265604\n",
            "Value 1971 Mean Loss: 5.249308168888092\n",
            "dones: tensor(20.)\n",
            "Policy 1972 Mean Loss: -0.006608290132135153\n",
            "Entropy 1972 Mean Loss: 0.690810289233923\n",
            "Value 1972 Mean Loss: 4.707262918353081\n",
            "dones: tensor(24.)\n",
            "Policy 1973 Mean Loss: -0.008876000181771815\n",
            "Entropy 1973 Mean Loss: 0.6908450536429882\n",
            "Value 1973 Mean Loss: 5.048571795225143\n",
            "dones: tensor(24.)\n",
            "Policy 1974 Mean Loss: -0.0052346364536788315\n",
            "Entropy 1974 Mean Loss: 0.6911726295948029\n",
            "Value 1974 Mean Loss: 4.876357346773148\n",
            "dones: tensor(22.)\n",
            "Policy 1975 Mean Loss: -0.007329191546887159\n",
            "Entropy 1975 Mean Loss: 0.6906667351722717\n",
            "Value 1975 Mean Loss: 3.9727230966091156\n",
            "dones: tensor(22.)\n",
            "Policy 1976 Mean Loss: -0.0085503701120615\n",
            "Entropy 1976 Mean Loss: 0.6907507888972759\n",
            "Value 1976 Mean Loss: 4.003657564520836\n",
            "dones: tensor(26.)\n",
            "Policy 1977 Mean Loss: -0.0048401946551166475\n",
            "Entropy 1977 Mean Loss: 0.6910567842423916\n",
            "Value 1977 Mean Loss: 4.803642630577087\n",
            "dones: tensor(20.)\n",
            "Policy 1978 Mean Loss: -0.009350118285510689\n",
            "Entropy 1978 Mean Loss: 0.6907613910734653\n",
            "Value 1978 Mean Loss: 4.3910753428936005\n",
            "dones: tensor(22.)\n",
            "Policy 1979 Mean Loss: -0.00855551875429228\n",
            "Entropy 1979 Mean Loss: 0.6909070648252964\n",
            "Value 1979 Mean Loss: 4.551143944263458\n",
            "dones: tensor(22.)\n",
            "Policy 1980 Mean Loss: -0.00792979629477486\n",
            "Entropy 1980 Mean Loss: 0.6907815113663673\n",
            "Value 1980 Mean Loss: 4.445658043026924\n",
            "dones: tensor(23.)\n",
            "Policy 1981 Mean Loss: -0.004908860311843455\n",
            "Entropy 1981 Mean Loss: 0.690863024443388\n",
            "Value 1981 Mean Loss: 4.2717639952898026\n",
            "dones: tensor(27.)\n",
            "Policy 1982 Mean Loss: -0.005864821665454656\n",
            "Entropy 1982 Mean Loss: 0.691033910959959\n",
            "Value 1982 Mean Loss: 4.963031858205795\n",
            "dones: tensor(23.)\n",
            "Policy 1983 Mean Loss: -0.005902627017349005\n",
            "Entropy 1983 Mean Loss: 0.690995242446661\n",
            "Value 1983 Mean Loss: 4.506413757801056\n",
            "dones: tensor(22.)\n",
            "Policy 1984 Mean Loss: -0.008513011678587645\n",
            "Entropy 1984 Mean Loss: 0.6907471790909767\n",
            "Value 1984 Mean Loss: 4.353232741355896\n",
            "dones: tensor(25.)\n",
            "Policy 1985 Mean Loss: -0.009111539751756936\n",
            "Entropy 1985 Mean Loss: 0.6909347511827946\n",
            "Value 1985 Mean Loss: 4.799720048904419\n",
            "dones: tensor(25.)\n",
            "Policy 1986 Mean Loss: -0.005212778691202402\n",
            "Entropy 1986 Mean Loss: 0.6909182779490948\n",
            "Value 1986 Mean Loss: 4.902531951665878\n",
            "dones: tensor(21.)\n",
            "Policy 1987 Mean Loss: -0.007212085241917521\n",
            "Entropy 1987 Mean Loss: 0.6906947456300259\n",
            "Value 1987 Mean Loss: 4.233656093478203\n",
            "dones: tensor(22.)\n",
            "Policy 1988 Mean Loss: -0.004251409962307662\n",
            "Entropy 1988 Mean Loss: 0.6907683461904526\n",
            "Value 1988 Mean Loss: 4.256009742617607\n",
            "dones: tensor(27.)\n",
            "Policy 1989 Mean Loss: -0.012526175240054727\n",
            "Entropy 1989 Mean Loss: 0.6909821145236492\n",
            "Value 1989 Mean Loss: 5.241552025079727\n",
            "dones: tensor(19.)\n",
            "Policy 1990 Mean Loss: -0.004100362712051719\n",
            "Entropy 1990 Mean Loss: 0.6908835582435131\n",
            "Value 1990 Mean Loss: 4.518512517213821\n",
            "dones: tensor(25.)\n",
            "Policy 1991 Mean Loss: -0.012562581687234342\n",
            "Entropy 1991 Mean Loss: 0.69092658162117\n",
            "Value 1991 Mean Loss: 4.236652433872223\n",
            "dones: tensor(25.)\n",
            "Policy 1992 Mean Loss: -0.009323794045485556\n",
            "Entropy 1992 Mean Loss: 0.6909896992146969\n",
            "Value 1992 Mean Loss: 4.7075022757053375\n",
            "dones: tensor(22.)\n",
            "Policy 1993 Mean Loss: -0.006358783633913845\n",
            "Entropy 1993 Mean Loss: 0.690986905246973\n",
            "Value 1993 Mean Loss: 4.630753755569458\n",
            "dones: tensor(22.)\n",
            "Policy 1994 Mean Loss: -0.008667963615152985\n",
            "Entropy 1994 Mean Loss: 0.6907858699560165\n",
            "Value 1994 Mean Loss: 4.521284133195877\n",
            "dones: tensor(22.)\n",
            "Policy 1995 Mean Loss: -0.005975711741484702\n",
            "Entropy 1995 Mean Loss: 0.6909532509744167\n",
            "Value 1995 Mean Loss: 5.84567654132843\n",
            "dones: tensor(19.)\n",
            "Policy 1996 Mean Loss: -0.005849884124472737\n",
            "Entropy 1996 Mean Loss: 0.690880112349987\n",
            "Value 1996 Mean Loss: 3.944429725408554\n",
            "dones: tensor(16.)\n",
            "Policy 1997 Mean Loss: -0.0024729384458623827\n",
            "Entropy 1997 Mean Loss: 0.6907191313803196\n",
            "Value 1997 Mean Loss: 3.7959145307540894\n",
            "dones: tensor(23.)\n",
            "Policy 1998 Mean Loss: -0.0070589748211205006\n",
            "Entropy 1998 Mean Loss: 0.690753236413002\n",
            "Value 1998 Mean Loss: 4.459775060415268\n",
            "dones: tensor(21.)\n",
            "Policy 1999 Mean Loss: -0.0050762982573360205\n",
            "Entropy 1999 Mean Loss: 0.6908545568585396\n",
            "Value 1999 Mean Loss: 4.353813990950584\n",
            "dones: tensor(17.)\n",
            "Policy 2000 Mean Loss: -0.006628371425904334\n",
            "Entropy 2000 Mean Loss: 0.6907715201377869\n",
            "Value 2000 Mean Loss: 3.8838772922754288\n",
            "Agent state saved to agent.pth\n"
          ]
        }
      ],
      "source": [
        "# Hper parameters\n",
        "\n",
        "initial_learning_rate = 0.1\n",
        "env_id = \"CartPole-v1\" # going to use \"CartPole-v1\"\n",
        "clipping_coef = 0.1\n",
        "num_envs = 4\n",
        "rollouts = 2000\n",
        "middle_layer_size = 64 # Define the size of the middle layer\n",
        "batch_size = 128 # Define a batch size for reshaping\n",
        "num_epochs = 4\n",
        "num_mini_batches = 4\n",
        "clipping_coef = 0.2\n",
        "\n",
        "gamma = 0.9\n",
        "\n",
        "# Conventional Vectorized Environment wrapper\n",
        "def make_env(env_id, seed=None): # Added seed parameter\n",
        "    def _init():\n",
        "        env = gym.make(env_id)\n",
        "        if seed is not None: # Set seed if provided\n",
        "            env.seed(seed)\n",
        "            env.action_space.seed(seed)\n",
        "            env.observation_space.seed(seed)\n",
        "        # Optional: Add wrappers here if needed\n",
        "        return env\n",
        "    return _init\n",
        "\n",
        "# Initialize info dictionary or maybe a list of dictionaries where each entry contains the mean reward, loss, number of steps, learning rate\n",
        "info = []\n",
        "\n",
        "# Agent definition\n",
        "\n",
        "class Agent(nn.Module):\n",
        "  def __init__(self, observation_space_shape, action_space_size, middle_layer_size) -> None:\n",
        "      super().__init__()\n",
        "\n",
        "      # Actor/Policy\n",
        "      self.actor = nn.Sequential(\n",
        "          nn.Linear(observation_space_shape, middle_layer_size),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(middle_layer_size, action_space_size),\n",
        "          nn.Softmax(dim=-1)\n",
        "          ) # Added dim=-1 to softmax\n",
        "\n",
        "      # Critic/Advantage NN //might need another activation function at the end.\n",
        "      self.critic = nn.Sequential(\n",
        "          nn.Linear(observation_space_shape, middle_layer_size),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(middle_layer_size, 1), # Output size of 1 for the value function\n",
        "          )\n",
        "\n",
        "\n",
        "  def predict(self, x, deterministic=False):\n",
        "    action_probs = self.actor(x)\n",
        "    if deterministic:\n",
        "        action = torch.argmax(action_probs, dim=-1)\n",
        "        log_prob = None  # Log probability is not well-defined for argmax\n",
        "        entropy = None   # Entropy is not well-defined for argmax\n",
        "    else:\n",
        "        act_dist = Categorical(action_probs)\n",
        "        action = act_dist.sample()\n",
        "        log_prob = act_dist.log_prob(action)\n",
        "        entropy = act_dist.entropy() # Calculate entropy\n",
        "\n",
        "    value_logits = self.critic(x)\n",
        "\n",
        "    # return entropy, probabilies, and sampled action\n",
        "    return (entropy, log_prob, action, value_logits) # Return entropy, probabilities, and a sampled action\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\": # Corrected __main__\n",
        "\n",
        "  # initilizattion\n",
        "  envs = gym.vector.AsyncVectorEnv([make_env(env_id, seed=(i**2)) for i in range(num_envs)]) # Pass individual seeds\n",
        "\n",
        "  # Get observation and action space dimensions\n",
        "  observation_space_shape = envs.single_observation_space.shape[0] # Assuming flat observation space\n",
        "  action_space_size = envs.single_action_space.n # Assuming discrete action space\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  #initialize the Agent\n",
        "  agent = Agent(observation_space_shape, action_space_size, middle_layer_size).to(device) # Pass dimensions and move to device\n",
        "\n",
        "  #initialize the optimizer\n",
        "  optimizer = optim.Adam(agent.parameters(), lr=2.5e-4, eps=1e-5)\n",
        "\n",
        "  # Initialize tensors with appropriate shapes\n",
        "  obs = torch.zeros((batch_size, num_envs, observation_space_shape)).to(device)\n",
        "  actions = torch.zeros((batch_size, num_envs)).to(device)\n",
        "  logprobs = torch.zeros((batch_size, num_envs)).to(device)\n",
        "  rewards = torch.zeros((batch_size, num_envs)).to(device)\n",
        "  dones = torch.zeros((batch_size, num_envs)).to(device)\n",
        "  pred_values = torch.zeros((batch_size, num_envs)).to(device)\n",
        "\n",
        "  # init actual values and advantages tensor\n",
        "  actual_values = torch.zeros_like(rewards).to(device)\n",
        "  advantages = torch.zeros_like(rewards).to(device)\n",
        "\n",
        "\n",
        "  # initializes the observation, done, the time, and the step\n",
        "  start_time = time.time()\n",
        "  global_step = 0\n",
        "\n",
        "  # define training regime\n",
        "  for i in range(int(rollouts)): # Cast steps to int\n",
        "    # Learning rate annealing\n",
        "    frac = 1.0 - (i / rollouts)\n",
        "    lr_now = 2.5e-4 * frac # Anneal from initial learning rate\n",
        "    optimizer.param_groups[0]['lr'] = lr_now\n",
        "\n",
        "\n",
        "    step = 0 # Initialize step counter for batch\n",
        "    next_obs = torch.Tensor(envs.reset()).to(device) # Corrected envs.reset()\n",
        "    next_done =  torch.zeros((num_envs,)).to(device)\n",
        "\n",
        "    for step in range(int(batch_size)):\n",
        "      # get actions, observations, rewards, and dones\n",
        "      with torch.no_grad(): # Added no_grad for inference\n",
        "          _, log_prob, action, values_ = agent.predict(next_obs) # Renamed values to values_ to avoid conflict\n",
        "\n",
        "      # Move data to tensors\n",
        "      next_obs_np, rewards_np, next_done_np, infos =  envs.step(action.cpu().numpy()) # env step and move action to cpu\n",
        "\n",
        "      # Moves things that were on the cpu onto the gpu\n",
        "      next_obs = torch.Tensor(next_obs_np).to(device)\n",
        "      next_done = torch.Tensor(next_done_np).to(device)\n",
        "      reward = torch.Tensor(rewards_np).to(device)\n",
        "\n",
        "      # Store data in tensors at the current step\n",
        "      obs[step] = next_obs\n",
        "      actions[step] = action\n",
        "      logprobs[step] = log_prob.detach()\n",
        "      rewards[step] = reward\n",
        "      dones[step] = next_done\n",
        "      pred_values[step] = values_.squeeze(-1).detach() # Remove the last dimension of size 1\n",
        "\n",
        "      global_step += num_envs # Update global step\n",
        "\n",
        "    # calculate actual values at each time step'\n",
        "    print(\"dones:\", dones.sum().cpu())\n",
        "\n",
        "    with torch.no_grad(): # Calculate advantages outside the gradient tape\n",
        "        for t in reversed(range(batch_size)):\n",
        "          if t == batch_size - 1:\n",
        "              # For the last step, if the environment is not done, use the value of the next state (from the agent's prediction)\n",
        "              # Otherwise, the actual value is just the reward at this step\n",
        "              nextnonterminal = 1.0 - next_done\n",
        "              next_value = agent.critic(next_obs).squeeze(-1).detach() # bootstrap next value since it doesn't exsist\n",
        "          else:\n",
        "              # For other steps, if the environment at the next step is not done, use the value of the next state from the stored values\n",
        "              # Otherwise, the actual value is just the reward at this step\n",
        "              nextnonterminal = 1.0 - dones[t+1]\n",
        "              next_value = actual_values[t+1]\n",
        "          actual_values[t] = rewards[t] + gamma * next_value * nextnonterminal\n",
        "        advantages = actual_values - pred_values.detach() # Detach pred_values here\n",
        "\n",
        "\n",
        "    # Actually training the agent neural net\n",
        "\n",
        "    # flattening the tensors for ease\n",
        "    b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n",
        "    b_logprobs = logprobs.reshape(-1)\n",
        "    b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n",
        "    b_advantages = advantages.reshape(-1)\n",
        "    b_actual_values = actual_values.reshape(-1)\n",
        "    b_pred_values = pred_values.reshape(-1)\n",
        "\n",
        "    # creates storage to see loss over time\n",
        "    Policy_loss_array = [] # Initialize list to store losses for the current rollout\n",
        "    Entropy_loss_array = [] # Initialize list to store losses for the current rollout\n",
        "    Value_loss_array = [] # Initialize list to store losses for the current rollout\n",
        "\n",
        "    # Iterates over the same batch a couple times for efficiency\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      #seperates into minibatches\n",
        "      indices = np.arange(batch_size * num_envs)   # creates indicies\n",
        "      np.random.shuffle(indices)        # shuffles indicies\n",
        "      minibatch_indices = np.array_split(indices, num_mini_batches)\n",
        "\n",
        "      #iterates over the minibatches\n",
        "      for current_minibatch_indices in minibatch_indices: # Corrected indexing for minibatch_indices\n",
        "\n",
        "        # init mini_batch\n",
        "        mb_obs = b_obs[current_minibatch_indices]\n",
        "        mb_log_probs = b_logprobs[current_minibatch_indices]\n",
        "        mb_actions = b_actions[current_minibatch_indices] # Corrected indexing for mb_actions\n",
        "        mb_advantages = b_advantages[current_minibatch_indices]\n",
        "        mb_actual_values = b_actual_values[current_minibatch_indices]\n",
        "        mb_pred_values = b_pred_values[current_minibatch_indices].detach() # Detach old predicted values for clipping\n",
        "\n",
        "\n",
        "        # get new logprobs(but don't overwrite), values, and entropy\n",
        "        mb_new_entropy, mb_new_log_probs, _, mb_new_values_ = agent.predict(mb_obs) # note: may need to be flattened\n",
        "\n",
        "        # value optimization\n",
        "        unclipped_value_loss = (mb_actual_values - mb_new_values_.squeeze(-1)) ** 2\n",
        "\n",
        "        clipped_predicted_values = mb_pred_values + torch.clamp(mb_new_values_.squeeze()- mb_pred_values, -clipping_coef, clipping_coef)\n",
        "        clipped_value_Loss = (mb_actual_values - clipped_predicted_values ) ** 2\n",
        "\n",
        "        value_loss = torch.max(unclipped_value_loss, clipped_value_Loss).mean()\n",
        "\n",
        "        # policy optimization\n",
        "\n",
        "        # Normalize advantages\n",
        "        mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8) # Add a small epsilon for numerical stability\n",
        "\n",
        "        # calculate ratios\n",
        "        unclipped_ratio = (mb_new_log_probs - mb_log_probs).exp()\n",
        "        clipped_ratio = torch.clamp(unclipped_ratio, 1 - clipping_coef, 1 + clipping_coef)\n",
        "\n",
        "        # calculate loss\n",
        "        policy_loss = torch.max(-mb_advantages*unclipped_ratio, -mb_advantages*clipped_ratio).mean()\n",
        "\n",
        "        # calculates entropy\n",
        "        entropy_loss = mb_new_entropy.mean()\n",
        "\n",
        "        #calculates total loss\n",
        "\n",
        "        loss = (policy_loss*2) - (entropy_loss*0.01) + (value_loss * 0.15)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(agent.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "        Policy_loss_array.append(policy_loss.item()) # Append mini-batch loss to list\n",
        "        Entropy_loss_array.append(entropy_loss.item()) # Append mini-batch loss to list\n",
        "        Value_loss_array.append(value_loss.item()) # Append mini-batch loss to list\n",
        "\n",
        "    # Calculate and print mean loss for the current rollout\n",
        "    mean_policy_loss = np.mean(Policy_loss_array)\n",
        "    mean_entropy_loss = np.mean(Entropy_loss_array)\n",
        "    mean_value_loss = np.mean(Value_loss_array)\n",
        "\n",
        "    print(f\"Policy {i+1} Mean Loss: {mean_policy_loss}\")\n",
        "    print(f\"Entropy {i+1} Mean Loss: {mean_entropy_loss}\")\n",
        "    print(f\"Value {i+1} Mean Loss: {mean_value_loss}\")\n",
        "\n",
        "\n",
        "  envs.close() # Close the environment\n",
        "\n",
        "  # Save the agent's state dictionary\n",
        "  torch.save(agent.state_dict(), \"agent.pth\")\n",
        "  print(\"Agent state saved to agent.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zo2bN-hrJ5yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc48b610",
        "outputId": "ddd45126-c420-4fef-f339-7db27d38d3cf"
      },
      "source": [
        "# Set up evaluation environment\n",
        "eval_env = gym.make(env_id, render_mode='rgb_array') # Use render_mode for video recording\n",
        "\n",
        "# Optional: Wrap the environment to record video\n",
        "# You might need to install 'moviepy' and 'ffmpeg' for this.\n",
        "# !pip install moviepy ffmpeg\n",
        "from gym.wrappers.record_video import RecordVideo\n",
        "\n",
        "# Create a directory to save videos\n",
        "video_folder = \"./eval_videos\"\n",
        "os.makedirs(video_folder, exist_ok=True)\n",
        "\n",
        "eval_env = RecordVideo(eval_env, video_folder)\n",
        "\n",
        "# Load the trained agent's state (assuming agent is still in memory or saved)\n",
        "# If you saved the agent, you would load it here:\n",
        "try:\n",
        "    agent.load_state_dict(torch.load(\"agent.pth\"))\n",
        "    print(\"Agent state loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Agent state file not found. Please run the training cell first.\")\n",
        "    # Optionally, handle this case by exiting or using an untrained agent\n",
        "    # For now, we'll continue with the current agent instance (likely untrained if file not found)\n",
        "\n",
        "\n",
        "# Set agent to evaluation mode\n",
        "agent.eval()\n",
        "\n",
        "# Run evaluation episodes\n",
        "num_eval_episodes = 10 # Number of episodes for evaluation\n",
        "episode_rewards = []\n",
        "\n",
        "for episode in range(num_eval_episodes):\n",
        "    obs = eval_env.reset() # Correctly unpack observation and info\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        with torch.no_grad(): # Use no_grad for inference\n",
        "            # Convert observation to tensor and move to device\n",
        "            obs_tensor = torch.Tensor(obs).unsqueeze(0).to(device) # Add batch dimension\n",
        "\n",
        "            # Get action from the agent (use predict for single environment inference)\n",
        "            _, _, action, _ = agent.predict(obs_tensor)\n",
        "\n",
        "            # Remove batch dimension and move action to cpu for environment step\n",
        "            # For a single discrete action, get the scalar value\n",
        "            action_np = action.squeeze(0).cpu().numpy().item()\n",
        "\n",
        "\n",
        "        # Step the environment\n",
        "        obs, reward, terminated, truncated = eval_env.step(action_np) # Correctly unpack all 5 values\n",
        "        episode_reward += reward\n",
        "        done = terminated # Consider either terminated or truncated as done for episode termination\n",
        "\n",
        "\n",
        "    episode_rewards.append(episode_reward)\n",
        "    print(f\"Evaluation Episode {episode + 1}: Reward = {episode_reward}\")\n",
        "\n",
        "# Close the evaluation environment\n",
        "# Attempt to close the underlying environment directly as a workaround for potential wrapper close issues\n",
        "eval_env.env.close()\n",
        "\n",
        "\n",
        "# Calculate and print mean reward\n",
        "mean_eval_reward = np.mean(episode_rewards)\n",
        "print(f\"\\nMean Evaluation Reward over {num_eval_episodes} episodes: {mean_eval_reward}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gym/wrappers/record_video.py:78: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/eval_videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent state loaded successfully.\n",
            "Evaluation Episode 1: Reward = 19.0\n",
            "Evaluation Episode 2: Reward = 40.0\n",
            "Evaluation Episode 3: Reward = 11.0\n",
            "Evaluation Episode 4: Reward = 16.0\n",
            "Evaluation Episode 5: Reward = 15.0\n",
            "Evaluation Episode 6: Reward = 30.0\n",
            "Evaluation Episode 7: Reward = 11.0\n",
            "Evaluation Episode 8: Reward = 63.0\n",
            "Evaluation Episode 9: Reward = 17.0\n",
            "Evaluation Episode 10: Reward = 27.0\n",
            "\n",
            "Mean Evaluation Reward over 10 episodes: 24.9\n"
          ]
        }
      ]
    }
  ]
}